2025-10-24 23:11:27,899 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:11:45,065 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:11:45,088 - __main__ - INFO - Using GPU: NVIDIA GeForce RTX 3070
2025-10-24 23:11:45,088 - __main__ - INFO - GPU Memory: 8.6 GB
2025-10-24 23:11:45,088 - __main__ - INFO - Collecting data for oil price prediction...
2025-10-24 23:11:45,094 - data.oil_data_pipeline - INFO - BigQuery client initialized successfully
2025-10-24 23:11:45,094 - data.oil_data_pipeline - INFO - Collecting data from 2024-10-24 to 2025-10-24
2025-10-24 23:11:45,094 - data.oil_data_pipeline - INFO - Collecting oil price data...
2025-10-24 23:11:46,261 - data.oil_data_pipeline - INFO - Collected 252 records for CL=F
2025-10-24 23:11:46,554 - data.oil_data_pipeline - INFO - Collected 252 records for BZ=F
2025-10-24 23:11:46,825 - data.oil_data_pipeline - INFO - Collected 252 records for NG=F
2025-10-24 23:11:46,826 - data.oil_data_pipeline - INFO - Collecting financial market data...
2025-10-24 23:11:47,101 - data.oil_data_pipeline - INFO - Collected 250 records for ^GSPC
2025-10-24 23:11:47,380 - data.oil_data_pipeline - INFO - Collected 250 records for ^DJI
2025-10-24 23:11:47,659 - data.oil_data_pipeline - INFO - Collected 250 records for ^IXIC
2025-10-24 23:11:47,934 - data.oil_data_pipeline - INFO - Collected 258 records for EURUSD=X
2025-10-24 23:11:48,225 - data.oil_data_pipeline - INFO - Collected 258 records for GBPUSD=X
2025-10-24 23:11:48,494 - data.oil_data_pipeline - INFO - Collected 258 records for USDJPY=X
2025-10-24 23:11:48,825 - data.oil_data_pipeline - INFO - Collected 250 records for XLE
2025-10-24 23:11:49,144 - data.oil_data_pipeline - INFO - Collected 250 records for VDE
2025-10-24 23:11:49,475 - data.oil_data_pipeline - INFO - Collected 250 records for IYE
2025-10-24 23:11:49,478 - data.oil_data_pipeline - INFO - Collecting GDELT news data from BigQuery...
2025-10-24 23:11:50,643 - data.oil_data_pipeline - ERROR - GDELT BigQuery error: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/outstanding-map-449312-a0/jobs?prettyPrint=false: Access Denied: Project outstanding-map-449312-a0: User does not have bigquery.jobs.create permission in project outstanding-map-449312-a0.

Location: None
Job ID: fee2f795-e872-49c0-bc91-dcfc9a513d1e

2025-10-24 23:11:50,644 - data.oil_data_pipeline - INFO - Falling back to local news data
2025-10-24 23:11:50,644 - data.oil_data_pipeline - WARNING - Creating fallback news data
2025-10-24 23:11:50,648 - data.oil_data_pipeline - WARNING - Failed to load fallback news data: time data "Fri, 24 Oct 2025 06:00:00 -0400" doesn't match format "%a, %d %b %Y %H:%M:%S GMT", at position 5. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
2025-10-24 23:11:50,649 - data.oil_data_pipeline - INFO - Creating news-to-price time mapping...
2025-10-24 23:12:13,549 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:12:13,575 - __main__ - INFO - Using GPU: NVIDIA GeForce RTX 3070
2025-10-24 23:12:13,575 - __main__ - INFO - GPU Memory: 8.6 GB
2025-10-24 23:12:13,575 - __main__ - INFO - Collecting data for oil price prediction...
2025-10-24 23:12:13,583 - data.oil_data_pipeline - INFO - BigQuery client initialized successfully
2025-10-24 23:12:13,583 - data.oil_data_pipeline - INFO - Collecting data from 2024-10-24 to 2025-10-24
2025-10-24 23:12:13,583 - data.oil_data_pipeline - INFO - Collecting oil price data...
2025-10-24 23:12:14,782 - data.oil_data_pipeline - INFO - Collected 252 records for CL=F
2025-10-24 23:12:15,071 - data.oil_data_pipeline - INFO - Collected 252 records for BZ=F
2025-10-24 23:12:15,367 - data.oil_data_pipeline - INFO - Collected 252 records for NG=F
2025-10-24 23:12:15,368 - data.oil_data_pipeline - INFO - Collecting financial market data...
2025-10-24 23:12:15,642 - data.oil_data_pipeline - INFO - Collected 250 records for ^GSPC
2025-10-24 23:12:15,929 - data.oil_data_pipeline - INFO - Collected 250 records for ^DJI
2025-10-24 23:12:16,207 - data.oil_data_pipeline - INFO - Collected 250 records for ^IXIC
2025-10-24 23:12:16,490 - data.oil_data_pipeline - INFO - Collected 258 records for EURUSD=X
2025-10-24 23:12:16,811 - data.oil_data_pipeline - INFO - Collected 258 records for GBPUSD=X
2025-10-24 23:12:17,086 - data.oil_data_pipeline - INFO - Collected 258 records for USDJPY=X
2025-10-24 23:12:17,410 - data.oil_data_pipeline - INFO - Collected 250 records for XLE
2025-10-24 23:12:17,716 - data.oil_data_pipeline - INFO - Collected 250 records for VDE
2025-10-24 23:12:18,052 - data.oil_data_pipeline - INFO - Collected 250 records for IYE
2025-10-24 23:12:18,056 - data.oil_data_pipeline - INFO - Collecting GDELT news data from BigQuery...
2025-10-24 23:12:19,250 - data.oil_data_pipeline - ERROR - GDELT BigQuery error: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/outstanding-map-449312-a0/jobs?prettyPrint=false: Access Denied: Project outstanding-map-449312-a0: User does not have bigquery.jobs.create permission in project outstanding-map-449312-a0.

Location: None
Job ID: b96cc99f-7515-40ef-ba9e-b4ffbb9aa567

2025-10-24 23:12:19,250 - data.oil_data_pipeline - INFO - Falling back to local news data
2025-10-24 23:12:19,250 - data.oil_data_pipeline - WARNING - Creating fallback news data
2025-10-24 23:12:19,255 - data.oil_data_pipeline - WARNING - Failed to load fallback news data: time data "Fri, 24 Oct 2025 06:00:00 -0400" doesn't match format "%a, %d %b %Y %H:%M:%S GMT", at position 5. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
2025-10-24 23:12:19,256 - data.oil_data_pipeline - INFO - Creating news-to-price time mapping...
2025-10-24 23:13:25,427 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:13:25,450 - __main__ - INFO - Using GPU: NVIDIA GeForce RTX 3070
2025-10-24 23:13:25,450 - __main__ - INFO - GPU Memory: 8.6 GB
2025-10-24 23:13:25,450 - __main__ - INFO - Collecting data for oil price prediction...
2025-10-24 23:13:25,456 - data.oil_data_pipeline - INFO - BigQuery client initialized successfully
2025-10-24 23:13:25,456 - data.oil_data_pipeline - INFO - Collecting data from 2024-10-24 to 2025-10-24
2025-10-24 23:13:25,456 - data.oil_data_pipeline - INFO - Collecting oil price data...
2025-10-24 23:13:25,937 - data.oil_data_pipeline - INFO - Collected 252 records for CL=F
2025-10-24 23:13:26,009 - data.oil_data_pipeline - INFO - Collected 252 records for BZ=F
2025-10-24 23:13:26,072 - data.oil_data_pipeline - INFO - Collected 252 records for NG=F
2025-10-24 23:13:26,073 - data.oil_data_pipeline - INFO - Collecting financial market data...
2025-10-24 23:13:26,134 - data.oil_data_pipeline - INFO - Collected 250 records for ^GSPC
2025-10-24 23:13:26,202 - data.oil_data_pipeline - INFO - Collected 250 records for ^DJI
2025-10-24 23:13:26,264 - data.oil_data_pipeline - INFO - Collected 250 records for ^IXIC
2025-10-24 23:13:26,341 - data.oil_data_pipeline - INFO - Collected 258 records for EURUSD=X
2025-10-24 23:13:26,497 - data.oil_data_pipeline - INFO - Collected 258 records for GBPUSD=X
2025-10-24 23:13:26,568 - data.oil_data_pipeline - INFO - Collected 258 records for USDJPY=X
2025-10-24 23:13:26,667 - data.oil_data_pipeline - INFO - Collected 250 records for XLE
2025-10-24 23:13:26,764 - data.oil_data_pipeline - INFO - Collected 250 records for VDE
2025-10-24 23:13:26,854 - data.oil_data_pipeline - INFO - Collected 250 records for IYE
2025-10-24 23:13:26,858 - data.oil_data_pipeline - INFO - Collecting GDELT news data from BigQuery...
2025-10-24 23:13:28,048 - data.oil_data_pipeline - ERROR - GDELT BigQuery error: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/outstanding-map-449312-a0/jobs?prettyPrint=false: Access Denied: Project outstanding-map-449312-a0: User does not have bigquery.jobs.create permission in project outstanding-map-449312-a0.

Location: None
Job ID: f4b26bdb-6a73-4cfc-9367-830cad61bed5

2025-10-24 23:13:28,049 - data.oil_data_pipeline - INFO - Falling back to local news data
2025-10-24 23:13:28,049 - data.oil_data_pipeline - WARNING - Creating fallback news data
2025-10-24 23:13:28,055 - data.oil_data_pipeline - WARNING - Failed to load fallback news data: time data "Fri, 24 Oct 2025 06:00:00 -0400" doesn't match format "%a, %d %b %Y %H:%M:%S GMT", at position 5. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
2025-10-24 23:13:28,056 - data.oil_data_pipeline - INFO - Creating news-to-price time mapping...
2025-10-24 23:13:51,561 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:13:51,585 - __main__ - INFO - Using GPU: NVIDIA GeForce RTX 3070
2025-10-24 23:13:51,585 - __main__ - INFO - GPU Memory: 8.6 GB
2025-10-24 23:13:51,585 - __main__ - INFO - Collecting data for oil price prediction...
2025-10-24 23:13:51,591 - data.oil_data_pipeline - INFO - BigQuery client initialized successfully
2025-10-24 23:13:51,591 - data.oil_data_pipeline - INFO - Collecting data from 2024-10-24 to 2025-10-24
2025-10-24 23:13:51,591 - data.oil_data_pipeline - INFO - Collecting oil price data...
2025-10-24 23:13:51,953 - data.oil_data_pipeline - INFO - Collected 252 records for CL=F
2025-10-24 23:13:52,017 - data.oil_data_pipeline - INFO - Collected 252 records for BZ=F
2025-10-24 23:13:52,081 - data.oil_data_pipeline - INFO - Collected 252 records for NG=F
2025-10-24 23:13:52,081 - data.oil_data_pipeline - INFO - Collecting financial market data...
2025-10-24 23:13:52,142 - data.oil_data_pipeline - INFO - Collected 250 records for ^GSPC
2025-10-24 23:13:52,204 - data.oil_data_pipeline - INFO - Collected 250 records for ^DJI
2025-10-24 23:13:52,265 - data.oil_data_pipeline - INFO - Collected 250 records for ^IXIC
2025-10-24 23:13:52,413 - data.oil_data_pipeline - INFO - Collected 258 records for EURUSD=X
2025-10-24 23:13:52,479 - data.oil_data_pipeline - INFO - Collected 258 records for GBPUSD=X
2025-10-24 23:13:52,538 - data.oil_data_pipeline - INFO - Collected 258 records for USDJPY=X
2025-10-24 23:13:52,633 - data.oil_data_pipeline - INFO - Collected 250 records for XLE
2025-10-24 23:13:52,763 - data.oil_data_pipeline - INFO - Collected 250 records for VDE
2025-10-24 23:13:52,859 - data.oil_data_pipeline - INFO - Collected 250 records for IYE
2025-10-24 23:13:52,863 - data.oil_data_pipeline - INFO - Collecting GDELT news data from BigQuery...
2025-10-24 23:13:54,261 - data.oil_data_pipeline - ERROR - GDELT BigQuery error: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/outstanding-map-449312-a0/jobs?prettyPrint=false: Access Denied: Project outstanding-map-449312-a0: User does not have bigquery.jobs.create permission in project outstanding-map-449312-a0.

Location: None
Job ID: 57f63c87-7cc4-4172-bf50-d7e15c4c5bed

2025-10-24 23:13:54,261 - data.oil_data_pipeline - INFO - Falling back to local news data
2025-10-24 23:13:54,261 - data.oil_data_pipeline - WARNING - Creating fallback news data
2025-10-24 23:13:54,268 - data.oil_data_pipeline - WARNING - Failed to load fallback news data: time data "Fri, 24 Oct 2025 06:00:00 -0400" doesn't match format "%a, %d %b %Y %H:%M:%S GMT", at position 5. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
2025-10-24 23:13:54,269 - data.oil_data_pipeline - INFO - Creating news-to-price time mapping...
2025-10-24 23:13:55,692 - data.oil_data_pipeline - INFO - Created 567 news-to-price mappings
2025-10-24 23:13:55,692 - data.oil_data_pipeline - INFO - Data collection complete: 3697 total records
2025-10-24 23:13:55,693 - __main__ - INFO - Data collection complete: 3697 total records
2025-10-24 23:13:55,693 - __main__ - INFO - Starting GPU training...
2025-10-24 23:13:55,693 - data.oil_data_pipeline - INFO - Processing 567 mapped news events
2025-10-24 23:13:55,795 - data.oil_data_pipeline - INFO - Processed 567 training samples from mapped events
2025-10-24 23:13:55,795 - data.oil_data_pipeline - INFO - Oil price dataset created with 567 samples
2025-10-24 23:13:55,795 - data.oil_data_pipeline - INFO - Processing 567 mapped news events
2025-10-24 23:13:55,870 - data.oil_data_pipeline - INFO - Processed 567 training samples from mapped events
2025-10-24 23:13:55,870 - data.oil_data_pipeline - INFO - Oil price dataset created with 567 samples
2025-10-24 23:13:55,887 - models.oil_price_model - INFO - Oil Price Model initialized with 619,751 parameters
2025-10-24 23:13:56,013 - __main__ - INFO - Model initialized with 619,751 parameters
2025-10-24 23:14:20,324 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:14:20,348 - __main__ - INFO - Using GPU: NVIDIA GeForce RTX 3070
2025-10-24 23:14:20,348 - __main__ - INFO - GPU Memory: 8.6 GB
2025-10-24 23:14:20,349 - __main__ - INFO - Collecting data for oil price prediction...
2025-10-24 23:14:20,355 - data.oil_data_pipeline - INFO - BigQuery client initialized successfully
2025-10-24 23:14:20,355 - data.oil_data_pipeline - INFO - Collecting data from 2024-10-24 to 2025-10-24
2025-10-24 23:14:20,355 - data.oil_data_pipeline - INFO - Collecting oil price data...
2025-10-24 23:14:20,896 - data.oil_data_pipeline - INFO - Collected 252 records for CL=F
2025-10-24 23:14:20,965 - data.oil_data_pipeline - INFO - Collected 252 records for BZ=F
2025-10-24 23:14:21,028 - data.oil_data_pipeline - INFO - Collected 252 records for NG=F
2025-10-24 23:14:21,029 - data.oil_data_pipeline - INFO - Collecting financial market data...
2025-10-24 23:14:21,099 - data.oil_data_pipeline - INFO - Collected 250 records for ^GSPC
2025-10-24 23:14:21,164 - data.oil_data_pipeline - INFO - Collected 250 records for ^DJI
2025-10-24 23:14:21,235 - data.oil_data_pipeline - INFO - Collected 250 records for ^IXIC
2025-10-24 23:14:21,298 - data.oil_data_pipeline - INFO - Collected 258 records for EURUSD=X
2025-10-24 23:14:21,364 - data.oil_data_pipeline - INFO - Collected 258 records for GBPUSD=X
2025-10-24 23:14:21,426 - data.oil_data_pipeline - INFO - Collected 258 records for USDJPY=X
2025-10-24 23:14:21,532 - data.oil_data_pipeline - INFO - Collected 250 records for XLE
2025-10-24 23:14:21,615 - data.oil_data_pipeline - INFO - Collected 250 records for VDE
2025-10-24 23:14:21,785 - data.oil_data_pipeline - INFO - Collected 250 records for IYE
2025-10-24 23:14:21,788 - data.oil_data_pipeline - INFO - Collecting GDELT news data from BigQuery...
2025-10-24 23:14:22,946 - data.oil_data_pipeline - ERROR - GDELT BigQuery error: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/outstanding-map-449312-a0/jobs?prettyPrint=false: Access Denied: Project outstanding-map-449312-a0: User does not have bigquery.jobs.create permission in project outstanding-map-449312-a0.

Location: None
Job ID: dcaeb0c9-29fb-4753-b77a-b272e9341623

2025-10-24 23:14:22,947 - data.oil_data_pipeline - INFO - Falling back to local news data
2025-10-24 23:14:22,947 - data.oil_data_pipeline - WARNING - Creating fallback news data
2025-10-24 23:14:22,952 - data.oil_data_pipeline - WARNING - Failed to load fallback news data: time data "Fri, 24 Oct 2025 06:00:00 -0400" doesn't match format "%a, %d %b %Y %H:%M:%S GMT", at position 5. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
2025-10-24 23:14:22,952 - data.oil_data_pipeline - INFO - Creating news-to-price time mapping...
2025-10-24 23:14:24,132 - data.oil_data_pipeline - INFO - Created 567 news-to-price mappings
2025-10-24 23:14:24,133 - data.oil_data_pipeline - INFO - Data collection complete: 3697 total records
2025-10-24 23:14:24,133 - __main__ - INFO - Data collection complete: 3697 total records
2025-10-24 23:14:24,133 - __main__ - INFO - Starting GPU training...
2025-10-24 23:14:24,133 - data.oil_data_pipeline - INFO - Processing 567 mapped news events
2025-10-24 23:14:24,208 - data.oil_data_pipeline - INFO - Processed 567 training samples from mapped events
2025-10-24 23:14:24,208 - data.oil_data_pipeline - INFO - Oil price dataset created with 567 samples
2025-10-24 23:14:24,208 - data.oil_data_pipeline - INFO - Processing 567 mapped news events
2025-10-24 23:14:24,290 - data.oil_data_pipeline - INFO - Processed 567 training samples from mapped events
2025-10-24 23:14:24,291 - data.oil_data_pipeline - INFO - Oil price dataset created with 567 samples
2025-10-24 23:14:24,296 - models.oil_price_model - INFO - Oil Price Model initialized with 619,751 parameters
2025-10-24 23:14:24,390 - __main__ - INFO - Model initialized with 619,751 parameters
2025-10-24 23:15:52,025 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:15:52,051 - __main__ - INFO - Using GPU: NVIDIA GeForce RTX 3070
2025-10-24 23:15:52,051 - __main__ - INFO - GPU Memory: 8.6 GB
2025-10-24 23:15:52,051 - __main__ - INFO - Collecting data for oil price prediction...
2025-10-24 23:15:52,057 - data.oil_data_pipeline - INFO - BigQuery client initialized successfully
2025-10-24 23:15:52,057 - data.oil_data_pipeline - INFO - Collecting data from 2020-10-25 to 2025-10-24
2025-10-24 23:15:52,058 - data.oil_data_pipeline - INFO - Collecting oil price data...
2025-10-24 23:15:52,687 - data.oil_data_pipeline - INFO - Collected 1257 records for CL=F
2025-10-24 23:15:52,843 - data.oil_data_pipeline - INFO - Collected 1258 records for BZ=F
2025-10-24 23:15:53,024 - data.oil_data_pipeline - INFO - Collected 1258 records for NG=F
2025-10-24 23:15:53,025 - data.oil_data_pipeline - INFO - Collecting financial market data...
2025-10-24 23:15:53,149 - data.oil_data_pipeline - INFO - Collected 1255 records for ^GSPC
2025-10-24 23:15:53,334 - data.oil_data_pipeline - INFO - Collected 1255 records for ^DJI
2025-10-24 23:15:53,510 - data.oil_data_pipeline - INFO - Collected 1255 records for ^IXIC
2025-10-24 23:15:53,704 - data.oil_data_pipeline - INFO - Collected 1301 records for EURUSD=X
2025-10-24 23:15:53,891 - data.oil_data_pipeline - INFO - Collected 1301 records for GBPUSD=X
2025-10-24 23:15:54,022 - data.oil_data_pipeline - INFO - Collected 1301 records for USDJPY=X
2025-10-24 23:15:54,241 - data.oil_data_pipeline - INFO - Collected 1255 records for XLE
2025-10-24 23:15:54,453 - data.oil_data_pipeline - INFO - Collected 1255 records for VDE
2025-10-24 23:15:54,663 - data.oil_data_pipeline - INFO - Collected 1255 records for IYE
2025-10-24 23:15:54,674 - data.oil_data_pipeline - INFO - Collecting GDELT news data from BigQuery...
2025-10-24 23:15:56,149 - data.oil_data_pipeline - ERROR - GDELT BigQuery error: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/outstanding-map-449312-a0/jobs?prettyPrint=false: Access Denied: Project outstanding-map-449312-a0: User does not have bigquery.jobs.create permission in project outstanding-map-449312-a0.

Location: None
Job ID: d3f27105-ffb8-4067-b475-73fc3a059685

2025-10-24 23:15:56,149 - data.oil_data_pipeline - INFO - Falling back to local news data
2025-10-24 23:15:56,149 - data.oil_data_pipeline - WARNING - Creating comprehensive fallback news data
2025-10-24 23:15:56,154 - data.oil_data_pipeline - WARNING - Failed to load fallback news data: time data "Fri, 24 Oct 2025 06:00:00 -0400" doesn't match format "%a, %d %b %Y %H:%M:%S GMT", at position 5. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
2025-10-24 23:15:56,155 - data.oil_data_pipeline - INFO - Created 150 comprehensive news events
2025-10-24 23:15:56,155 - data.oil_data_pipeline - INFO - Creating news-to-price time mapping...
2025-10-24 23:16:00,813 - data.oil_data_pipeline - INFO - Created 787 news-to-price mappings
2025-10-24 23:16:00,813 - data.oil_data_pipeline - INFO - Data collection complete: 16143 total records
2025-10-24 23:16:00,814 - __main__ - INFO - Data collection complete: 16143 total records
2025-10-24 23:16:00,814 - __main__ - INFO - Starting GPU training...
2025-10-24 23:16:00,814 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:16:00,904 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:16:00,904 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:16:00,904 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:16:00,998 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:16:00,999 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:16:01,003 - models.oil_price_model - INFO - Oil Price Model initialized with 619,751 parameters
2025-10-24 23:16:01,100 - __main__ - INFO - Model initialized with 619,751 parameters
2025-10-24 23:16:19,732 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:16:19,756 - __main__ - INFO - Using GPU: NVIDIA GeForce RTX 3070
2025-10-24 23:16:19,756 - __main__ - INFO - GPU Memory: 8.6 GB
2025-10-24 23:16:19,756 - __main__ - INFO - Collecting data for oil price prediction...
2025-10-24 23:16:19,763 - data.oil_data_pipeline - INFO - BigQuery client initialized successfully
2025-10-24 23:16:19,763 - data.oil_data_pipeline - INFO - Collecting data from 2020-10-25 to 2025-10-24
2025-10-24 23:16:19,763 - data.oil_data_pipeline - INFO - Collecting oil price data...
2025-10-24 23:16:20,313 - data.oil_data_pipeline - INFO - Collected 1257 records for CL=F
2025-10-24 23:16:20,421 - data.oil_data_pipeline - INFO - Collected 1258 records for BZ=F
2025-10-24 23:16:20,497 - data.oil_data_pipeline - INFO - Collected 1258 records for NG=F
2025-10-24 23:16:20,497 - data.oil_data_pipeline - INFO - Collecting financial market data...
2025-10-24 23:16:20,623 - data.oil_data_pipeline - INFO - Collected 1255 records for ^GSPC
2025-10-24 23:16:20,766 - data.oil_data_pipeline - INFO - Collected 1255 records for ^DJI
2025-10-24 23:16:20,842 - data.oil_data_pipeline - INFO - Collected 1255 records for ^IXIC
2025-10-24 23:16:20,956 - data.oil_data_pipeline - INFO - Collected 1301 records for EURUSD=X
2025-10-24 23:16:21,046 - data.oil_data_pipeline - INFO - Collected 1301 records for GBPUSD=X
2025-10-24 23:16:21,129 - data.oil_data_pipeline - INFO - Collected 1301 records for USDJPY=X
2025-10-24 23:16:21,244 - data.oil_data_pipeline - INFO - Collected 1255 records for XLE
2025-10-24 23:16:21,348 - data.oil_data_pipeline - INFO - Collected 1255 records for VDE
2025-10-24 23:16:21,476 - data.oil_data_pipeline - INFO - Collected 1255 records for IYE
2025-10-24 23:16:21,487 - data.oil_data_pipeline - INFO - Collecting GDELT news data from BigQuery...
2025-10-24 23:16:22,647 - data.oil_data_pipeline - ERROR - GDELT BigQuery error: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/outstanding-map-449312-a0/jobs?prettyPrint=false: Access Denied: Project outstanding-map-449312-a0: User does not have bigquery.jobs.create permission in project outstanding-map-449312-a0.

Location: None
Job ID: cc3eb3df-d4d1-4c2d-b065-8439abe52839

2025-10-24 23:16:22,648 - data.oil_data_pipeline - INFO - Falling back to local news data
2025-10-24 23:16:22,648 - data.oil_data_pipeline - WARNING - Creating comprehensive fallback news data
2025-10-24 23:16:22,653 - data.oil_data_pipeline - WARNING - Failed to load fallback news data: time data "Fri, 24 Oct 2025 06:00:00 -0400" doesn't match format "%a, %d %b %Y %H:%M:%S GMT", at position 5. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
2025-10-24 23:16:22,654 - data.oil_data_pipeline - INFO - Created 150 comprehensive news events
2025-10-24 23:16:22,654 - data.oil_data_pipeline - INFO - Creating news-to-price time mapping...
2025-10-24 23:16:27,690 - data.oil_data_pipeline - INFO - Created 787 news-to-price mappings
2025-10-24 23:16:27,690 - data.oil_data_pipeline - INFO - Data collection complete: 16143 total records
2025-10-24 23:16:27,690 - __main__ - INFO - Data collection complete: 16143 total records
2025-10-24 23:16:27,690 - __main__ - INFO - Starting GPU training...
2025-10-24 23:16:27,691 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:16:27,795 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:16:27,795 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:16:27,795 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:16:27,907 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:16:27,907 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:16:27,915 - models.oil_price_model - INFO - Oil Price Model initialized with 615,911 parameters
2025-10-24 23:16:28,040 - __main__ - INFO - Model initialized with 615,911 parameters
2025-10-24 23:16:53,644 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:16:53,669 - __main__ - INFO - Using GPU: NVIDIA GeForce RTX 3070
2025-10-24 23:16:53,670 - __main__ - INFO - GPU Memory: 8.6 GB
2025-10-24 23:16:53,670 - __main__ - INFO - Collecting data for oil price prediction...
2025-10-24 23:16:53,677 - data.oil_data_pipeline - INFO - BigQuery client initialized successfully
2025-10-24 23:16:53,677 - data.oil_data_pipeline - INFO - Collecting data from 2020-10-25 to 2025-10-24
2025-10-24 23:16:53,677 - data.oil_data_pipeline - INFO - Collecting oil price data...
2025-10-24 23:16:54,225 - data.oil_data_pipeline - INFO - Collected 1257 records for CL=F
2025-10-24 23:16:54,302 - data.oil_data_pipeline - INFO - Collected 1258 records for BZ=F
2025-10-24 23:16:54,379 - data.oil_data_pipeline - INFO - Collected 1258 records for NG=F
2025-10-24 23:16:54,379 - data.oil_data_pipeline - INFO - Collecting financial market data...
2025-10-24 23:16:54,455 - data.oil_data_pipeline - INFO - Collected 1255 records for ^GSPC
2025-10-24 23:16:54,530 - data.oil_data_pipeline - INFO - Collected 1255 records for ^DJI
2025-10-24 23:16:54,603 - data.oil_data_pipeline - INFO - Collected 1255 records for ^IXIC
2025-10-24 23:16:54,748 - data.oil_data_pipeline - INFO - Collected 1301 records for EURUSD=X
2025-10-24 23:16:54,840 - data.oil_data_pipeline - INFO - Collected 1301 records for GBPUSD=X
2025-10-24 23:16:54,922 - data.oil_data_pipeline - INFO - Collected 1301 records for USDJPY=X
2025-10-24 23:16:55,077 - data.oil_data_pipeline - INFO - Collected 1255 records for XLE
2025-10-24 23:16:55,189 - data.oil_data_pipeline - INFO - Collected 1255 records for VDE
2025-10-24 23:16:55,308 - data.oil_data_pipeline - INFO - Collected 1255 records for IYE
2025-10-24 23:16:55,319 - data.oil_data_pipeline - INFO - Collecting GDELT news data from BigQuery...
2025-10-24 23:16:56,551 - data.oil_data_pipeline - ERROR - GDELT BigQuery error: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/outstanding-map-449312-a0/jobs?prettyPrint=false: Access Denied: Project outstanding-map-449312-a0: User does not have bigquery.jobs.create permission in project outstanding-map-449312-a0.

Location: None
Job ID: dabbf5fc-2692-4b2c-b429-486c41ac0c17

2025-10-24 23:16:56,551 - data.oil_data_pipeline - INFO - Falling back to local news data
2025-10-24 23:16:56,551 - data.oil_data_pipeline - WARNING - Creating comprehensive fallback news data
2025-10-24 23:16:56,556 - data.oil_data_pipeline - WARNING - Failed to load fallback news data: time data "Fri, 24 Oct 2025 06:00:00 -0400" doesn't match format "%a, %d %b %Y %H:%M:%S GMT", at position 5. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
2025-10-24 23:16:56,557 - data.oil_data_pipeline - INFO - Created 150 comprehensive news events
2025-10-24 23:16:56,558 - data.oil_data_pipeline - INFO - Creating news-to-price time mapping...
2025-10-24 23:17:00,936 - data.oil_data_pipeline - INFO - Created 787 news-to-price mappings
2025-10-24 23:17:00,936 - data.oil_data_pipeline - INFO - Data collection complete: 16143 total records
2025-10-24 23:17:00,936 - __main__ - INFO - Data collection complete: 16143 total records
2025-10-24 23:17:00,936 - __main__ - INFO - Starting GPU training...
2025-10-24 23:17:00,936 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:17:01,028 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:17:01,029 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:17:01,029 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:17:01,123 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:17:01,123 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:17:01,127 - models.oil_price_model - INFO - Oil Price Model initialized with 614,556 parameters
2025-10-24 23:17:01,229 - __main__ - INFO - Model initialized with 614,556 parameters
2025-10-24 23:17:20,214 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:17:20,238 - __main__ - INFO - Using GPU: NVIDIA GeForce RTX 3070
2025-10-24 23:17:20,239 - __main__ - INFO - GPU Memory: 8.6 GB
2025-10-24 23:17:20,239 - __main__ - INFO - Collecting data for oil price prediction...
2025-10-24 23:17:20,245 - data.oil_data_pipeline - INFO - BigQuery client initialized successfully
2025-10-24 23:17:20,245 - data.oil_data_pipeline - INFO - Collecting data from 2020-10-25 to 2025-10-24
2025-10-24 23:17:20,245 - data.oil_data_pipeline - INFO - Collecting oil price data...
2025-10-24 23:17:20,719 - data.oil_data_pipeline - INFO - Collected 1257 records for CL=F
2025-10-24 23:17:20,801 - data.oil_data_pipeline - INFO - Collected 1258 records for BZ=F
2025-10-24 23:17:20,879 - data.oil_data_pipeline - INFO - Collected 1258 records for NG=F
2025-10-24 23:17:20,879 - data.oil_data_pipeline - INFO - Collecting financial market data...
2025-10-24 23:17:20,953 - data.oil_data_pipeline - INFO - Collected 1255 records for ^GSPC
2025-10-24 23:17:21,064 - data.oil_data_pipeline - INFO - Collected 1255 records for ^DJI
2025-10-24 23:17:21,136 - data.oil_data_pipeline - INFO - Collected 1255 records for ^IXIC
2025-10-24 23:17:21,219 - data.oil_data_pipeline - INFO - Collected 1301 records for EURUSD=X
2025-10-24 23:17:21,304 - data.oil_data_pipeline - INFO - Collected 1301 records for GBPUSD=X
2025-10-24 23:17:21,415 - data.oil_data_pipeline - INFO - Collected 1301 records for USDJPY=X
2025-10-24 23:17:21,530 - data.oil_data_pipeline - INFO - Collected 1255 records for XLE
2025-10-24 23:17:21,638 - data.oil_data_pipeline - INFO - Collected 1255 records for VDE
2025-10-24 23:17:21,791 - data.oil_data_pipeline - INFO - Collected 1255 records for IYE
2025-10-24 23:17:21,802 - data.oil_data_pipeline - INFO - Collecting GDELT news data from BigQuery...
2025-10-24 23:17:23,045 - data.oil_data_pipeline - ERROR - GDELT BigQuery error: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/outstanding-map-449312-a0/jobs?prettyPrint=false: Access Denied: Project outstanding-map-449312-a0: User does not have bigquery.jobs.create permission in project outstanding-map-449312-a0.

Location: None
Job ID: cec92512-eba1-431e-9e7e-a6217a6b7439

2025-10-24 23:17:23,045 - data.oil_data_pipeline - INFO - Falling back to local news data
2025-10-24 23:17:23,045 - data.oil_data_pipeline - WARNING - Creating comprehensive fallback news data
2025-10-24 23:17:23,050 - data.oil_data_pipeline - WARNING - Failed to load fallback news data: time data "Fri, 24 Oct 2025 06:00:00 -0400" doesn't match format "%a, %d %b %Y %H:%M:%S GMT", at position 5. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
2025-10-24 23:17:23,051 - data.oil_data_pipeline - INFO - Created 150 comprehensive news events
2025-10-24 23:17:23,052 - data.oil_data_pipeline - INFO - Creating news-to-price time mapping...
2025-10-24 23:17:28,059 - data.oil_data_pipeline - INFO - Created 787 news-to-price mappings
2025-10-24 23:17:28,059 - data.oil_data_pipeline - INFO - Data collection complete: 16143 total records
2025-10-24 23:17:28,059 - __main__ - INFO - Data collection complete: 16143 total records
2025-10-24 23:17:28,059 - __main__ - INFO - Starting GPU training...
2025-10-24 23:17:28,059 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:17:28,159 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:17:28,159 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:17:28,160 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:17:28,263 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:17:28,264 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:17:28,268 - models.oil_price_model - INFO - Oil Price Model initialized with 614,556 parameters
2025-10-24 23:17:28,372 - __main__ - INFO - Model initialized with 614,556 parameters
2025-10-24 23:17:43,913 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:17:43,939 - __main__ - INFO - Using GPU: NVIDIA GeForce RTX 3070
2025-10-24 23:17:43,939 - __main__ - INFO - GPU Memory: 8.6 GB
2025-10-24 23:17:43,939 - __main__ - INFO - Collecting data for oil price prediction...
2025-10-24 23:17:43,945 - data.oil_data_pipeline - INFO - BigQuery client initialized successfully
2025-10-24 23:17:43,945 - data.oil_data_pipeline - INFO - Collecting data from 2020-10-25 to 2025-10-24
2025-10-24 23:17:43,945 - data.oil_data_pipeline - INFO - Collecting oil price data...
2025-10-24 23:17:44,620 - data.oil_data_pipeline - INFO - Collected 1257 records for CL=F
2025-10-24 23:17:44,705 - data.oil_data_pipeline - INFO - Collected 1258 records for BZ=F
2025-10-24 23:17:44,783 - data.oil_data_pipeline - INFO - Collected 1258 records for NG=F
2025-10-24 23:17:44,784 - data.oil_data_pipeline - INFO - Collecting financial market data...
2025-10-24 23:17:44,862 - data.oil_data_pipeline - INFO - Collected 1255 records for ^GSPC
2025-10-24 23:17:44,938 - data.oil_data_pipeline - INFO - Collected 1255 records for ^DJI
2025-10-24 23:17:45,018 - data.oil_data_pipeline - INFO - Collected 1255 records for ^IXIC
2025-10-24 23:17:45,110 - data.oil_data_pipeline - INFO - Collected 1301 records for EURUSD=X
2025-10-24 23:17:45,196 - data.oil_data_pipeline - INFO - Collected 1301 records for GBPUSD=X
2025-10-24 23:17:45,276 - data.oil_data_pipeline - INFO - Collected 1301 records for USDJPY=X
2025-10-24 23:17:45,397 - data.oil_data_pipeline - INFO - Collected 1255 records for XLE
2025-10-24 23:17:45,507 - data.oil_data_pipeline - INFO - Collected 1255 records for VDE
2025-10-24 23:17:45,627 - data.oil_data_pipeline - INFO - Collected 1255 records for IYE
2025-10-24 23:17:45,641 - data.oil_data_pipeline - INFO - Collecting GDELT news data from BigQuery...
2025-10-24 23:17:47,355 - data.oil_data_pipeline - ERROR - GDELT BigQuery error: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/outstanding-map-449312-a0/jobs?prettyPrint=false: Access Denied: Project outstanding-map-449312-a0: User does not have bigquery.jobs.create permission in project outstanding-map-449312-a0.

Location: None
Job ID: 8004cb09-3981-4ce8-8da2-1945802b44a9

2025-10-24 23:17:47,355 - data.oil_data_pipeline - INFO - Falling back to local news data
2025-10-24 23:17:47,355 - data.oil_data_pipeline - WARNING - Creating comprehensive fallback news data
2025-10-24 23:17:47,361 - data.oil_data_pipeline - WARNING - Failed to load fallback news data: time data "Fri, 24 Oct 2025 06:00:00 -0400" doesn't match format "%a, %d %b %Y %H:%M:%S GMT", at position 5. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
2025-10-24 23:17:47,362 - data.oil_data_pipeline - INFO - Created 150 comprehensive news events
2025-10-24 23:17:47,363 - data.oil_data_pipeline - INFO - Creating news-to-price time mapping...
2025-10-24 23:17:53,631 - data.oil_data_pipeline - INFO - Created 787 news-to-price mappings
2025-10-24 23:17:53,632 - data.oil_data_pipeline - INFO - Data collection complete: 16143 total records
2025-10-24 23:17:53,632 - __main__ - INFO - Data collection complete: 16143 total records
2025-10-24 23:17:53,632 - __main__ - INFO - Starting GPU training...
2025-10-24 23:17:53,632 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:17:53,761 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:17:53,761 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:17:53,761 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:17:53,895 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:17:53,895 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:17:53,902 - models.oil_price_model - INFO - Oil Price Model initialized with 614,556 parameters
2025-10-24 23:17:54,006 - __main__ - INFO - Model initialized with 614,556 parameters
2025-10-24 23:17:56,105 - __main__ - INFO - Epoch 0, Batch 0/50, Loss: 2668.792480
2025-10-24 23:17:56,309 - __main__ - INFO - Epoch 0, Batch 10/50, Loss: 3507.633057
2025-10-24 23:17:56,456 - __main__ - INFO - Epoch 0, Batch 20/50, Loss: 3267.265381
2025-10-24 23:17:56,604 - __main__ - INFO - Epoch 0, Batch 30/50, Loss: 3109.826904
2025-10-24 23:17:56,753 - __main__ - INFO - Epoch 0, Batch 40/50, Loss: 2682.526123
2025-10-24 23:17:57,132 - __main__ - INFO - Epoch 0: Train Loss: 3377.098774, Val Loss: 3330.512438, LR: 9.76e-05
2025-10-24 23:17:57,146 - __main__ - INFO - Saved best model (Val Loss: 3330.512438)
2025-10-24 23:17:57,163 - __main__ - INFO - Epoch 1, Batch 0/50, Loss: 3081.111084
2025-10-24 23:17:57,312 - __main__ - INFO - Epoch 1, Batch 10/50, Loss: 3012.803223
2025-10-24 23:17:57,466 - __main__ - INFO - Epoch 1, Batch 20/50, Loss: 2523.673340
2025-10-24 23:17:57,614 - __main__ - INFO - Epoch 1, Batch 30/50, Loss: 2781.337158
2025-10-24 23:17:57,754 - __main__ - INFO - Epoch 1, Batch 40/50, Loss: 2324.299316
2025-10-24 23:17:58,138 - __main__ - INFO - Epoch 1: Train Loss: 3116.736611, Val Loss: 2415.857527, LR: 9.05e-05
2025-10-24 23:17:58,147 - __main__ - INFO - Saved best model (Val Loss: 2415.857527)
2025-10-24 23:17:58,162 - __main__ - INFO - Epoch 2, Batch 0/50, Loss: 2390.092285
2025-10-24 23:17:58,308 - __main__ - INFO - Epoch 2, Batch 10/50, Loss: 1385.390869
2025-10-24 23:17:58,453 - __main__ - INFO - Epoch 2, Batch 20/50, Loss: 841.490417
2025-10-24 23:17:58,599 - __main__ - INFO - Epoch 2, Batch 30/50, Loss: 520.803955
2025-10-24 23:17:58,747 - __main__ - INFO - Epoch 2, Batch 40/50, Loss: 664.454041
2025-10-24 23:17:59,136 - __main__ - INFO - Epoch 2: Train Loss: 1006.020119, Val Loss: 254.614132, LR: 7.94e-05
2025-10-24 23:17:59,146 - __main__ - INFO - Saved best model (Val Loss: 254.614132)
2025-10-24 23:17:59,163 - __main__ - INFO - Epoch 3, Batch 0/50, Loss: 298.860657
2025-10-24 23:17:59,310 - __main__ - INFO - Epoch 3, Batch 10/50, Loss: 188.493896
2025-10-24 23:17:59,457 - __main__ - INFO - Epoch 3, Batch 20/50, Loss: 244.951035
2025-10-24 23:17:59,608 - __main__ - INFO - Epoch 3, Batch 30/50, Loss: 397.916229
2025-10-24 23:17:59,757 - __main__ - INFO - Epoch 3, Batch 40/50, Loss: 119.057693
2025-10-24 23:18:00,150 - __main__ - INFO - Epoch 3: Train Loss: 253.534343, Val Loss: 108.532592, LR: 6.55e-05
2025-10-24 23:18:00,166 - __main__ - INFO - Saved best model (Val Loss: 108.532592)
2025-10-24 23:18:00,186 - __main__ - INFO - Epoch 4, Batch 0/50, Loss: 257.923676
2025-10-24 23:18:00,364 - __main__ - INFO - Epoch 4, Batch 10/50, Loss: 146.029221
2025-10-24 23:18:00,511 - __main__ - INFO - Epoch 4, Batch 20/50, Loss: 226.197327
2025-10-24 23:18:00,657 - __main__ - INFO - Epoch 4, Batch 30/50, Loss: 194.461746
2025-10-24 23:18:00,810 - __main__ - INFO - Epoch 4, Batch 40/50, Loss: 231.635666
2025-10-24 23:18:01,199 - __main__ - INFO - Epoch 4: Train Loss: 186.191912, Val Loss: 84.717986, LR: 5.00e-05
2025-10-24 23:18:01,208 - __main__ - INFO - Saved best model (Val Loss: 84.717986)
2025-10-24 23:18:01,223 - __main__ - INFO - Epoch 5, Batch 0/50, Loss: 144.171158
2025-10-24 23:18:01,373 - __main__ - INFO - Epoch 5, Batch 10/50, Loss: 245.313736
2025-10-24 23:18:01,525 - __main__ - INFO - Epoch 5, Batch 20/50, Loss: 155.278564
2025-10-24 23:18:01,692 - __main__ - INFO - Epoch 5, Batch 30/50, Loss: 201.958328
2025-10-24 23:18:01,844 - __main__ - INFO - Epoch 5, Batch 40/50, Loss: 239.720001
2025-10-24 23:18:02,231 - __main__ - INFO - Epoch 5: Train Loss: 171.178959, Val Loss: 76.742522, LR: 3.45e-05
2025-10-24 23:18:02,240 - __main__ - INFO - Saved best model (Val Loss: 76.742522)
2025-10-24 23:18:02,258 - __main__ - INFO - Epoch 6, Batch 0/50, Loss: 188.959732
2025-10-24 23:18:02,417 - __main__ - INFO - Epoch 6, Batch 10/50, Loss: 116.334541
2025-10-24 23:18:02,608 - __main__ - INFO - Epoch 6, Batch 20/50, Loss: 157.365433
2025-10-24 23:18:02,757 - __main__ - INFO - Epoch 6, Batch 30/50, Loss: 113.598633
2025-10-24 23:18:02,911 - __main__ - INFO - Epoch 6, Batch 40/50, Loss: 142.224350
2025-10-24 23:18:03,292 - __main__ - INFO - Epoch 6: Train Loss: 146.138574, Val Loss: 64.472087, LR: 2.06e-05
2025-10-24 23:18:03,302 - __main__ - INFO - Saved best model (Val Loss: 64.472087)
2025-10-24 23:18:03,318 - __main__ - INFO - Epoch 7, Batch 0/50, Loss: 124.923775
2025-10-24 23:18:03,463 - __main__ - INFO - Epoch 7, Batch 10/50, Loss: 96.323463
2025-10-24 23:18:03,615 - __main__ - INFO - Epoch 7, Batch 20/50, Loss: 138.105972
2025-10-24 23:18:03,776 - __main__ - INFO - Epoch 7, Batch 30/50, Loss: 107.990562
2025-10-24 23:18:03,935 - __main__ - INFO - Epoch 7, Batch 40/50, Loss: 133.124878
2025-10-24 23:18:04,319 - __main__ - INFO - Epoch 7: Train Loss: 145.209486, Val Loss: 60.253169, LR: 9.55e-06
2025-10-24 23:18:04,327 - __main__ - INFO - Saved best model (Val Loss: 60.253169)
2025-10-24 23:18:04,343 - __main__ - INFO - Epoch 8, Batch 0/50, Loss: 90.439926
2025-10-24 23:18:04,489 - __main__ - INFO - Epoch 8, Batch 10/50, Loss: 117.227951
2025-10-24 23:18:04,634 - __main__ - INFO - Epoch 8, Batch 20/50, Loss: 133.037918
2025-10-24 23:18:04,776 - __main__ - INFO - Epoch 8, Batch 30/50, Loss: 89.443428
2025-10-24 23:18:04,920 - __main__ - INFO - Epoch 8, Batch 40/50, Loss: 140.939163
2025-10-24 23:18:05,302 - __main__ - INFO - Epoch 8: Train Loss: 135.880849, Val Loss: 58.035844, LR: 2.45e-06
2025-10-24 23:18:05,312 - __main__ - INFO - Saved best model (Val Loss: 58.035844)
2025-10-24 23:18:05,327 - __main__ - INFO - Epoch 9, Batch 0/50, Loss: 126.877998
2025-10-24 23:18:05,470 - __main__ - INFO - Epoch 9, Batch 10/50, Loss: 105.073097
2025-10-24 23:18:05,614 - __main__ - INFO - Epoch 9, Batch 20/50, Loss: 158.111237
2025-10-24 23:18:05,761 - __main__ - INFO - Epoch 9, Batch 30/50, Loss: 119.115936
2025-10-24 23:18:05,915 - __main__ - INFO - Epoch 9, Batch 40/50, Loss: 146.700668
2025-10-24 23:18:06,291 - __main__ - INFO - Epoch 9: Train Loss: 136.560024, Val Loss: 58.878663, LR: 1.00e-04
2025-10-24 23:18:06,307 - __main__ - INFO - Epoch 10, Batch 0/50, Loss: 121.651207
2025-10-24 23:18:06,449 - __main__ - INFO - Epoch 10, Batch 10/50, Loss: 208.400116
2025-10-24 23:18:06,600 - __main__ - INFO - Epoch 10, Batch 20/50, Loss: 173.041977
2025-10-24 23:18:06,745 - __main__ - INFO - Epoch 10, Batch 30/50, Loss: 109.687576
2025-10-24 23:18:06,890 - __main__ - INFO - Epoch 10, Batch 40/50, Loss: 138.859833
2025-10-24 23:18:07,275 - __main__ - INFO - Epoch 10: Train Loss: 125.346662, Val Loss: 46.266408, LR: 9.94e-05
2025-10-24 23:18:07,284 - __main__ - INFO - Saved best model (Val Loss: 46.266408)
2025-10-24 23:18:07,298 - __main__ - INFO - Epoch 11, Batch 0/50, Loss: 152.203384
2025-10-24 23:18:07,452 - __main__ - INFO - Epoch 11, Batch 10/50, Loss: 69.321877
2025-10-24 23:18:07,597 - __main__ - INFO - Epoch 11, Batch 20/50, Loss: 151.456360
2025-10-24 23:18:07,751 - __main__ - INFO - Epoch 11, Batch 30/50, Loss: 141.753540
2025-10-24 23:18:07,910 - __main__ - INFO - Epoch 11, Batch 40/50, Loss: 108.809944
2025-10-24 23:18:08,301 - __main__ - INFO - Epoch 11: Train Loss: 116.793804, Val Loss: 38.618893, LR: 9.76e-05
2025-10-24 23:18:08,311 - __main__ - INFO - Saved best model (Val Loss: 38.618893)
2025-10-24 23:18:08,326 - __main__ - INFO - Epoch 12, Batch 0/50, Loss: 103.644150
2025-10-24 23:18:08,472 - __main__ - INFO - Epoch 12, Batch 10/50, Loss: 81.588554
2025-10-24 23:18:08,621 - __main__ - INFO - Epoch 12, Batch 20/50, Loss: 93.279755
2025-10-24 23:18:08,770 - __main__ - INFO - Epoch 12, Batch 30/50, Loss: 81.018272
2025-10-24 23:18:08,919 - __main__ - INFO - Epoch 12, Batch 40/50, Loss: 82.634598
2025-10-24 23:18:09,290 - __main__ - INFO - Epoch 12: Train Loss: 97.562117, Val Loss: 34.398464, LR: 9.46e-05
2025-10-24 23:18:09,299 - __main__ - INFO - Saved best model (Val Loss: 34.398464)
2025-10-24 23:18:09,314 - __main__ - INFO - Epoch 13, Batch 0/50, Loss: 94.231705
2025-10-24 23:18:09,462 - __main__ - INFO - Epoch 13, Batch 10/50, Loss: 94.981171
2025-10-24 23:18:09,612 - __main__ - INFO - Epoch 13, Batch 20/50, Loss: 92.910866
2025-10-24 23:18:09,764 - __main__ - INFO - Epoch 13, Batch 30/50, Loss: 68.058464
2025-10-24 23:18:09,917 - __main__ - INFO - Epoch 13, Batch 40/50, Loss: 79.230042
2025-10-24 23:18:10,323 - __main__ - INFO - Epoch 13: Train Loss: 95.545775, Val Loss: 33.463190, LR: 9.05e-05
2025-10-24 23:18:10,332 - __main__ - INFO - Saved best model (Val Loss: 33.463190)
2025-10-24 23:18:10,347 - __main__ - INFO - Epoch 14, Batch 0/50, Loss: 76.344620
2025-10-24 23:18:10,500 - __main__ - INFO - Epoch 14, Batch 10/50, Loss: 56.610657
2025-10-24 23:18:10,646 - __main__ - INFO - Epoch 14, Batch 20/50, Loss: 75.672913
2025-10-24 23:18:10,794 - __main__ - INFO - Epoch 14, Batch 30/50, Loss: 66.149223
2025-10-24 23:18:10,944 - __main__ - INFO - Epoch 14, Batch 40/50, Loss: 66.031914
2025-10-24 23:18:11,328 - __main__ - INFO - Epoch 14: Train Loss: 92.972061, Val Loss: 25.432324, LR: 8.54e-05
2025-10-24 23:18:11,337 - __main__ - INFO - Saved best model (Val Loss: 25.432324)
2025-10-24 23:18:11,351 - __main__ - INFO - Epoch 15, Batch 0/50, Loss: 84.778511
2025-10-24 23:18:11,505 - __main__ - INFO - Epoch 15, Batch 10/50, Loss: 58.439110
2025-10-24 23:18:11,652 - __main__ - INFO - Epoch 15, Batch 20/50, Loss: 69.685516
2025-10-24 23:18:11,800 - __main__ - INFO - Epoch 15, Batch 30/50, Loss: 78.941666
2025-10-24 23:18:11,949 - __main__ - INFO - Epoch 15, Batch 40/50, Loss: 100.828072
2025-10-24 23:18:12,331 - __main__ - INFO - Epoch 15: Train Loss: 87.384631, Val Loss: 25.118922, LR: 7.94e-05
2025-10-24 23:18:12,341 - __main__ - INFO - Saved best model (Val Loss: 25.118922)
2025-10-24 23:18:12,359 - __main__ - INFO - Epoch 16, Batch 0/50, Loss: 57.164104
2025-10-24 23:18:12,525 - __main__ - INFO - Epoch 16, Batch 10/50, Loss: 85.389076
2025-10-24 23:18:12,684 - __main__ - INFO - Epoch 16, Batch 20/50, Loss: 108.721748
2025-10-24 23:18:12,836 - __main__ - INFO - Epoch 16, Batch 30/50, Loss: 71.941422
2025-10-24 23:18:12,986 - __main__ - INFO - Epoch 16, Batch 40/50, Loss: 72.557793
2025-10-24 23:18:13,367 - __main__ - INFO - Epoch 16: Train Loss: 81.946777, Val Loss: 21.243915, LR: 7.27e-05
2025-10-24 23:18:13,376 - __main__ - INFO - Saved best model (Val Loss: 21.243915)
2025-10-24 23:18:13,392 - __main__ - INFO - Epoch 17, Batch 0/50, Loss: 73.271057
2025-10-24 23:18:13,537 - __main__ - INFO - Epoch 17, Batch 10/50, Loss: 65.113518
2025-10-24 23:18:13,684 - __main__ - INFO - Epoch 17, Batch 20/50, Loss: 59.898106
2025-10-24 23:18:13,835 - __main__ - INFO - Epoch 17, Batch 30/50, Loss: 90.025085
2025-10-24 23:18:13,982 - __main__ - INFO - Epoch 17, Batch 40/50, Loss: 58.910789
2025-10-24 23:18:14,365 - __main__ - INFO - Epoch 17: Train Loss: 78.534608, Val Loss: 19.841656, LR: 6.55e-05
2025-10-24 23:18:14,374 - __main__ - INFO - Saved best model (Val Loss: 19.841656)
2025-10-24 23:18:14,389 - __main__ - INFO - Epoch 18, Batch 0/50, Loss: 78.891525
2025-10-24 23:18:14,536 - __main__ - INFO - Epoch 18, Batch 10/50, Loss: 65.085739
2025-10-24 23:18:14,701 - __main__ - INFO - Epoch 18, Batch 20/50, Loss: 72.328674
2025-10-24 23:18:14,855 - __main__ - INFO - Epoch 18, Batch 30/50, Loss: 53.114075
2025-10-24 23:18:15,010 - __main__ - INFO - Epoch 18, Batch 40/50, Loss: 51.520496
2025-10-24 23:18:15,391 - __main__ - INFO - Epoch 18: Train Loss: 80.335347, Val Loss: 19.565866, LR: 5.78e-05
2025-10-24 23:18:15,400 - __main__ - INFO - Saved best model (Val Loss: 19.565866)
2025-10-24 23:18:15,416 - __main__ - INFO - Epoch 19, Batch 0/50, Loss: 34.889297
2025-10-24 23:18:15,567 - __main__ - INFO - Epoch 19, Batch 10/50, Loss: 72.063095
2025-10-24 23:18:15,715 - __main__ - INFO - Epoch 19, Batch 20/50, Loss: 59.831779
2025-10-24 23:18:15,865 - __main__ - INFO - Epoch 19, Batch 30/50, Loss: 82.863075
2025-10-24 23:18:16,012 - __main__ - INFO - Epoch 19, Batch 40/50, Loss: 69.950287
2025-10-24 23:18:16,400 - __main__ - INFO - Epoch 19: Train Loss: 74.996088, Val Loss: 19.647990, LR: 5.00e-05
2025-10-24 23:18:16,415 - __main__ - INFO - Epoch 20, Batch 0/50, Loss: 65.913910
2025-10-24 23:18:16,561 - __main__ - INFO - Epoch 20, Batch 10/50, Loss: 69.351875
2025-10-24 23:18:16,714 - __main__ - INFO - Epoch 20, Batch 20/50, Loss: 45.134132
2025-10-24 23:18:16,887 - __main__ - INFO - Epoch 20, Batch 30/50, Loss: 47.990204
2025-10-24 23:18:17,044 - __main__ - INFO - Epoch 20, Batch 40/50, Loss: 56.649731
2025-10-24 23:18:17,447 - __main__ - INFO - Epoch 20: Train Loss: 72.368009, Val Loss: 24.737101, LR: 4.22e-05
2025-10-24 23:18:17,463 - __main__ - INFO - Epoch 21, Batch 0/50, Loss: 58.562336
2025-10-24 23:18:17,617 - __main__ - INFO - Epoch 21, Batch 10/50, Loss: 34.559433
2025-10-24 23:18:17,770 - __main__ - INFO - Epoch 21, Batch 20/50, Loss: 106.536934
2025-10-24 23:18:17,933 - __main__ - INFO - Epoch 21, Batch 30/50, Loss: 40.219978
2025-10-24 23:18:18,081 - __main__ - INFO - Epoch 21, Batch 40/50, Loss: 58.559959
2025-10-24 23:18:18,463 - __main__ - INFO - Epoch 21: Train Loss: 75.924326, Val Loss: 19.584783, LR: 3.45e-05
2025-10-24 23:18:18,477 - __main__ - INFO - Epoch 22, Batch 0/50, Loss: 87.114151
2025-10-24 23:18:18,627 - __main__ - INFO - Epoch 22, Batch 10/50, Loss: 76.117607
2025-10-24 23:18:18,773 - __main__ - INFO - Epoch 22, Batch 20/50, Loss: 45.259159
2025-10-24 23:18:18,929 - __main__ - INFO - Epoch 22, Batch 30/50, Loss: 96.313034
2025-10-24 23:18:19,094 - __main__ - INFO - Epoch 22, Batch 40/50, Loss: 66.413963
2025-10-24 23:18:19,492 - __main__ - INFO - Epoch 22: Train Loss: 74.684474, Val Loss: 18.502345, LR: 2.73e-05
2025-10-24 23:18:19,501 - __main__ - INFO - Saved best model (Val Loss: 18.502345)
2025-10-24 23:18:19,516 - __main__ - INFO - Epoch 23, Batch 0/50, Loss: 59.371052
2025-10-24 23:18:19,669 - __main__ - INFO - Epoch 23, Batch 10/50, Loss: 79.040443
2025-10-24 23:18:19,818 - __main__ - INFO - Epoch 23, Batch 20/50, Loss: 62.157276
2025-10-24 23:18:19,970 - __main__ - INFO - Epoch 23, Batch 30/50, Loss: 66.158203
2025-10-24 23:18:20,117 - __main__ - INFO - Epoch 23, Batch 40/50, Loss: 58.236240
2025-10-24 23:18:20,517 - __main__ - INFO - Epoch 23: Train Loss: 71.808103, Val Loss: 20.646806, LR: 2.06e-05
2025-10-24 23:18:20,533 - __main__ - INFO - Epoch 24, Batch 0/50, Loss: 46.611393
2025-10-24 23:18:20,685 - __main__ - INFO - Epoch 24, Batch 10/50, Loss: 48.740593
2025-10-24 23:18:20,850 - __main__ - INFO - Epoch 24, Batch 20/50, Loss: 57.757267
2025-10-24 23:18:21,000 - __main__ - INFO - Epoch 24, Batch 30/50, Loss: 72.680771
2025-10-24 23:18:21,164 - __main__ - INFO - Epoch 24, Batch 40/50, Loss: 39.012455
2025-10-24 23:18:21,587 - __main__ - INFO - Epoch 24: Train Loss: 68.938362, Val Loss: 18.143161, LR: 1.46e-05
2025-10-24 23:18:21,597 - __main__ - INFO - Saved best model (Val Loss: 18.143161)
2025-10-24 23:18:21,616 - __main__ - INFO - Epoch 25, Batch 0/50, Loss: 55.138180
2025-10-24 23:18:21,775 - __main__ - INFO - Epoch 25, Batch 10/50, Loss: 58.038284
2025-10-24 23:18:21,939 - __main__ - INFO - Epoch 25, Batch 20/50, Loss: 92.129837
2025-10-24 23:18:22,087 - __main__ - INFO - Epoch 25, Batch 30/50, Loss: 78.207413
2025-10-24 23:18:22,233 - __main__ - INFO - Epoch 25, Batch 40/50, Loss: 69.491943
2025-10-24 23:18:22,616 - __main__ - INFO - Epoch 25: Train Loss: 71.955128, Val Loss: 18.453567, LR: 9.55e-06
2025-10-24 23:18:22,631 - __main__ - INFO - Epoch 26, Batch 0/50, Loss: 63.093307
2025-10-24 23:18:22,780 - __main__ - INFO - Epoch 26, Batch 10/50, Loss: 58.820122
2025-10-24 23:18:22,932 - __main__ - INFO - Epoch 26, Batch 20/50, Loss: 54.962662
2025-10-24 23:18:23,082 - __main__ - INFO - Epoch 26, Batch 30/50, Loss: 48.261742
2025-10-24 23:18:23,231 - __main__ - INFO - Epoch 26, Batch 40/50, Loss: 41.984367
2025-10-24 23:18:23,625 - __main__ - INFO - Epoch 26: Train Loss: 75.940876, Val Loss: 18.122562, LR: 5.45e-06
2025-10-24 23:18:23,634 - __main__ - INFO - Saved best model (Val Loss: 18.122562)
2025-10-24 23:18:23,650 - __main__ - INFO - Epoch 27, Batch 0/50, Loss: 52.945827
2025-10-24 23:18:23,811 - __main__ - INFO - Epoch 27, Batch 10/50, Loss: 57.278957
2025-10-24 23:18:23,967 - __main__ - INFO - Epoch 27, Batch 20/50, Loss: 37.623272
2025-10-24 23:18:24,122 - __main__ - INFO - Epoch 27, Batch 30/50, Loss: 76.701454
2025-10-24 23:18:24,273 - __main__ - INFO - Epoch 27, Batch 40/50, Loss: 73.431244
2025-10-24 23:18:24,657 - __main__ - INFO - Epoch 27: Train Loss: 67.599113, Val Loss: 17.989597, LR: 2.45e-06
2025-10-24 23:18:24,666 - __main__ - INFO - Saved best model (Val Loss: 17.989597)
2025-10-24 23:18:24,681 - __main__ - INFO - Epoch 28, Batch 0/50, Loss: 66.029480
2025-10-24 23:18:24,835 - __main__ - INFO - Epoch 28, Batch 10/50, Loss: 64.557800
2025-10-24 23:18:24,979 - __main__ - INFO - Epoch 28, Batch 20/50, Loss: 80.713188
2025-10-24 23:18:25,134 - __main__ - INFO - Epoch 28, Batch 30/50, Loss: 85.257660
2025-10-24 23:18:25,284 - __main__ - INFO - Epoch 28, Batch 40/50, Loss: 58.840000
2025-10-24 23:18:25,673 - __main__ - INFO - Epoch 28: Train Loss: 65.382571, Val Loss: 17.980000, LR: 6.16e-07
2025-10-24 23:18:25,682 - __main__ - INFO - Saved best model (Val Loss: 17.980000)
2025-10-24 23:18:25,700 - __main__ - INFO - Epoch 29, Batch 0/50, Loss: 64.926018
2025-10-24 23:18:25,866 - __main__ - INFO - Epoch 29, Batch 10/50, Loss: 55.789345
2025-10-24 23:18:26,022 - __main__ - INFO - Epoch 29, Batch 20/50, Loss: 52.267696
2025-10-24 23:18:26,172 - __main__ - INFO - Epoch 29, Batch 30/50, Loss: 81.117447
2025-10-24 23:18:26,321 - __main__ - INFO - Epoch 29, Batch 40/50, Loss: 61.415993
2025-10-24 23:18:26,707 - __main__ - INFO - Epoch 29: Train Loss: 64.944796, Val Loss: 18.039686, LR: 1.00e-04
2025-10-24 23:18:26,723 - __main__ - INFO - Epoch 30, Batch 0/50, Loss: 47.753960
2025-10-24 23:18:26,880 - __main__ - INFO - Epoch 30, Batch 10/50, Loss: 110.365150
2025-10-24 23:18:27,032 - __main__ - INFO - Epoch 30, Batch 20/50, Loss: 34.802189
2025-10-24 23:18:27,181 - __main__ - INFO - Epoch 30, Batch 30/50, Loss: 49.260818
2025-10-24 23:18:27,335 - __main__ - INFO - Epoch 30, Batch 40/50, Loss: 52.665108
2025-10-24 23:18:27,725 - __main__ - INFO - Epoch 30: Train Loss: 69.607999, Val Loss: 17.619294, LR: 9.98e-05
2025-10-24 23:18:27,734 - __main__ - INFO - Saved best model (Val Loss: 17.619294)
2025-10-24 23:18:27,748 - __main__ - INFO - Epoch 31, Batch 0/50, Loss: 89.628403
2025-10-24 23:18:27,902 - __main__ - INFO - Epoch 31, Batch 10/50, Loss: 40.966434
2025-10-24 23:18:28,062 - __main__ - INFO - Epoch 31, Batch 20/50, Loss: 57.613911
2025-10-24 23:18:28,210 - __main__ - INFO - Epoch 31, Batch 30/50, Loss: 100.163307
2025-10-24 23:18:28,360 - __main__ - INFO - Epoch 31, Batch 40/50, Loss: 75.512749
2025-10-24 23:18:28,748 - __main__ - INFO - Epoch 31: Train Loss: 70.511946, Val Loss: 17.589406, LR: 9.94e-05
2025-10-24 23:18:28,757 - __main__ - INFO - Saved best model (Val Loss: 17.589406)
2025-10-24 23:18:28,774 - __main__ - INFO - Epoch 32, Batch 0/50, Loss: 53.651669
2025-10-24 23:18:28,924 - __main__ - INFO - Epoch 32, Batch 10/50, Loss: 66.653976
2025-10-24 23:18:29,077 - __main__ - INFO - Epoch 32, Batch 20/50, Loss: 46.099808
2025-10-24 23:18:29,224 - __main__ - INFO - Epoch 32, Batch 30/50, Loss: 69.441284
2025-10-24 23:18:29,376 - __main__ - INFO - Epoch 32, Batch 40/50, Loss: 57.244068
2025-10-24 23:18:29,756 - __main__ - INFO - Epoch 32: Train Loss: 65.054015, Val Loss: 19.617607, LR: 9.86e-05
2025-10-24 23:18:29,771 - __main__ - INFO - Epoch 33, Batch 0/50, Loss: 49.636044
2025-10-24 23:18:29,922 - __main__ - INFO - Epoch 33, Batch 10/50, Loss: 60.693260
2025-10-24 23:18:30,085 - __main__ - INFO - Epoch 33, Batch 20/50, Loss: 46.431496
2025-10-24 23:18:30,250 - __main__ - INFO - Epoch 33, Batch 30/50, Loss: 49.464149
2025-10-24 23:18:30,407 - __main__ - INFO - Epoch 33, Batch 40/50, Loss: 68.004211
2025-10-24 23:18:30,832 - __main__ - INFO - Epoch 33: Train Loss: 68.283475, Val Loss: 18.031371, LR: 9.76e-05
2025-10-24 23:18:30,848 - __main__ - INFO - Epoch 34, Batch 0/50, Loss: 46.692776
2025-10-24 23:18:31,001 - __main__ - INFO - Epoch 34, Batch 10/50, Loss: 38.170467
2025-10-24 23:18:31,154 - __main__ - INFO - Epoch 34, Batch 20/50, Loss: 70.936401
2025-10-24 23:18:31,304 - __main__ - INFO - Epoch 34, Batch 30/50, Loss: 42.540321
2025-10-24 23:18:31,449 - __main__ - INFO - Epoch 34, Batch 40/50, Loss: 42.481518
2025-10-24 23:18:31,824 - __main__ - INFO - Epoch 34: Train Loss: 62.485258, Val Loss: 17.958571, LR: 9.62e-05
2025-10-24 23:18:31,838 - __main__ - INFO - Epoch 35, Batch 0/50, Loss: 71.819099
2025-10-24 23:18:31,986 - __main__ - INFO - Epoch 35, Batch 10/50, Loss: 58.267078
2025-10-24 23:18:32,141 - __main__ - INFO - Epoch 35, Batch 20/50, Loss: 73.274521
2025-10-24 23:18:32,300 - __main__ - INFO - Epoch 35, Batch 30/50, Loss: 57.511066
2025-10-24 23:18:32,456 - __main__ - INFO - Epoch 35, Batch 40/50, Loss: 66.185066
2025-10-24 23:18:32,837 - __main__ - INFO - Epoch 35: Train Loss: 66.802598, Val Loss: 18.401341, LR: 9.46e-05
2025-10-24 23:18:32,853 - __main__ - INFO - Epoch 36, Batch 0/50, Loss: 85.887543
2025-10-24 23:18:33,001 - __main__ - INFO - Epoch 36, Batch 10/50, Loss: 99.322266
2025-10-24 23:18:33,149 - __main__ - INFO - Epoch 36, Batch 20/50, Loss: 42.259033
2025-10-24 23:18:33,294 - __main__ - INFO - Epoch 36, Batch 30/50, Loss: 50.376575
2025-10-24 23:18:33,443 - __main__ - INFO - Epoch 36, Batch 40/50, Loss: 63.391525
2025-10-24 23:18:33,816 - __main__ - INFO - Epoch 36: Train Loss: 64.783573, Val Loss: 17.324576, LR: 9.26e-05
2025-10-24 23:18:33,825 - __main__ - INFO - Saved best model (Val Loss: 17.324576)
2025-10-24 23:18:33,839 - __main__ - INFO - Epoch 37, Batch 0/50, Loss: 57.604153
2025-10-24 23:18:33,986 - __main__ - INFO - Epoch 37, Batch 10/50, Loss: 60.731857
2025-10-24 23:18:34,136 - __main__ - INFO - Epoch 37, Batch 20/50, Loss: 54.067871
2025-10-24 23:18:34,283 - __main__ - INFO - Epoch 37, Batch 30/50, Loss: 76.923882
2025-10-24 23:18:34,464 - __main__ - INFO - Epoch 37, Batch 40/50, Loss: 62.455502
2025-10-24 23:18:34,860 - __main__ - INFO - Epoch 37: Train Loss: 64.561158, Val Loss: 22.887680, LR: 9.05e-05
2025-10-24 23:18:34,874 - __main__ - INFO - Epoch 38, Batch 0/50, Loss: 51.660198
2025-10-24 23:18:35,023 - __main__ - INFO - Epoch 38, Batch 10/50, Loss: 51.570324
2025-10-24 23:18:35,172 - __main__ - INFO - Epoch 38, Batch 20/50, Loss: 47.798901
2025-10-24 23:18:35,318 - __main__ - INFO - Epoch 38, Batch 30/50, Loss: 60.076843
2025-10-24 23:18:35,465 - __main__ - INFO - Epoch 38, Batch 40/50, Loss: 38.616783
2025-10-24 23:18:35,839 - __main__ - INFO - Epoch 38: Train Loss: 65.228649, Val Loss: 18.363887, LR: 8.80e-05
2025-10-24 23:18:35,855 - __main__ - INFO - Epoch 39, Batch 0/50, Loss: 35.262440
2025-10-24 23:18:36,000 - __main__ - INFO - Epoch 39, Batch 10/50, Loss: 34.059361
2025-10-24 23:18:36,149 - __main__ - INFO - Epoch 39, Batch 20/50, Loss: 480.121246
2025-10-24 23:18:36,292 - __main__ - INFO - Epoch 39, Batch 30/50, Loss: 67.807091
2025-10-24 23:18:36,443 - __main__ - INFO - Epoch 39, Batch 40/50, Loss: 48.930729
2025-10-24 23:18:36,862 - __main__ - INFO - Epoch 39: Train Loss: 62.617629, Val Loss: 17.465888, LR: 8.54e-05
2025-10-24 23:18:36,880 - __main__ - INFO - Epoch 40, Batch 0/50, Loss: 58.172112
2025-10-24 23:18:37,041 - __main__ - INFO - Epoch 40, Batch 10/50, Loss: 71.356209
2025-10-24 23:18:37,195 - __main__ - INFO - Epoch 40, Batch 20/50, Loss: 49.128990
2025-10-24 23:18:37,341 - __main__ - INFO - Epoch 40, Batch 30/50, Loss: 39.609173
2025-10-24 23:18:37,493 - __main__ - INFO - Epoch 40, Batch 40/50, Loss: 92.553986
2025-10-24 23:18:37,869 - __main__ - INFO - Epoch 40: Train Loss: 59.792687, Val Loss: 18.635984, LR: 8.25e-05
2025-10-24 23:18:37,885 - __main__ - INFO - Epoch 41, Batch 0/50, Loss: 48.069042
2025-10-24 23:18:38,033 - __main__ - INFO - Epoch 41, Batch 10/50, Loss: 32.496899
2025-10-24 23:18:38,183 - __main__ - INFO - Epoch 41, Batch 20/50, Loss: 40.998055
2025-10-24 23:18:38,331 - __main__ - INFO - Epoch 41, Batch 30/50, Loss: 45.616947
2025-10-24 23:18:38,492 - __main__ - INFO - Epoch 41, Batch 40/50, Loss: 80.803902
2025-10-24 23:18:38,886 - __main__ - INFO - Epoch 41: Train Loss: 63.010270, Val Loss: 18.283302, LR: 7.94e-05
2025-10-24 23:18:38,902 - __main__ - INFO - Epoch 42, Batch 0/50, Loss: 57.791676
2025-10-24 23:18:39,061 - __main__ - INFO - Epoch 42, Batch 10/50, Loss: 77.129326
2025-10-24 23:18:39,220 - __main__ - INFO - Epoch 42, Batch 20/50, Loss: 33.437302
2025-10-24 23:18:39,376 - __main__ - INFO - Epoch 42, Batch 30/50, Loss: 51.101990
2025-10-24 23:18:39,532 - __main__ - INFO - Epoch 42, Batch 40/50, Loss: 41.168430
2025-10-24 23:18:39,963 - __main__ - INFO - Epoch 42: Train Loss: 60.942494, Val Loss: 22.490267, LR: 7.61e-05
2025-10-24 23:18:39,979 - __main__ - INFO - Epoch 43, Batch 0/50, Loss: 29.776638
2025-10-24 23:18:40,125 - __main__ - INFO - Epoch 43, Batch 10/50, Loss: 67.441391
2025-10-24 23:18:40,270 - __main__ - INFO - Epoch 43, Batch 20/50, Loss: 46.276848
2025-10-24 23:18:40,416 - __main__ - INFO - Epoch 43, Batch 30/50, Loss: 38.861546
2025-10-24 23:18:40,563 - __main__ - INFO - Epoch 43, Batch 40/50, Loss: 42.595467
2025-10-24 23:18:40,939 - __main__ - INFO - Epoch 43: Train Loss: 58.230876, Val Loss: 17.583465, LR: 7.27e-05
2025-10-24 23:18:40,955 - __main__ - INFO - Epoch 44, Batch 0/50, Loss: 41.018734
2025-10-24 23:18:41,103 - __main__ - INFO - Epoch 44, Batch 10/50, Loss: 58.102455
2025-10-24 23:18:41,270 - __main__ - INFO - Epoch 44, Batch 20/50, Loss: 43.124729
2025-10-24 23:18:41,430 - __main__ - INFO - Epoch 44, Batch 30/50, Loss: 85.152794
2025-10-24 23:18:41,583 - __main__ - INFO - Epoch 44, Batch 40/50, Loss: 51.533783
2025-10-24 23:18:41,965 - __main__ - INFO - Epoch 44: Train Loss: 61.521211, Val Loss: 18.199900, LR: 6.91e-05
2025-10-24 23:18:41,982 - __main__ - INFO - Epoch 45, Batch 0/50, Loss: 63.596703
2025-10-24 23:18:42,126 - __main__ - INFO - Epoch 45, Batch 10/50, Loss: 79.223763
2025-10-24 23:18:42,277 - __main__ - INFO - Epoch 45, Batch 20/50, Loss: 46.474239
2025-10-24 23:18:42,423 - __main__ - INFO - Epoch 45, Batch 30/50, Loss: 406.558258
2025-10-24 23:18:42,570 - __main__ - INFO - Epoch 45, Batch 40/50, Loss: 40.405537
2025-10-24 23:18:42,961 - __main__ - INFO - Epoch 45: Train Loss: 56.530775, Val Loss: 18.438402, LR: 6.55e-05
2025-10-24 23:18:42,977 - __main__ - INFO - Epoch 46, Batch 0/50, Loss: 81.154526
2025-10-24 23:18:43,130 - __main__ - INFO - Epoch 46, Batch 10/50, Loss: 37.779499
2025-10-24 23:18:43,278 - __main__ - INFO - Epoch 46, Batch 20/50, Loss: 40.006435
2025-10-24 23:18:43,444 - __main__ - INFO - Epoch 46, Batch 30/50, Loss: 67.258606
2025-10-24 23:18:43,605 - __main__ - INFO - Epoch 46, Batch 40/50, Loss: 42.856655
2025-10-24 23:18:43,992 - __main__ - INFO - Epoch 46: Train Loss: 60.504809, Val Loss: 20.562436, LR: 6.17e-05
2025-10-24 23:18:43,992 - __main__ - INFO - Early stopping at epoch 46
2025-10-24 23:18:43,992 - __main__ - INFO - Training completed. Best validation loss: 17.324576
2025-10-24 23:18:43,996 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:18:44,132 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:18:44,132 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:18:44,132 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:18:44,263 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:18:44,263 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:18:44,263 - __main__ - INFO - Evaluating model...
2025-10-24 23:50:25,549 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:50:25,574 - __main__ - INFO - Using GPU: NVIDIA GeForce RTX 3070
2025-10-24 23:50:25,574 - __main__ - INFO - GPU Memory: 8.6 GB
2025-10-24 23:50:25,574 - __main__ - INFO - Collecting data for oil price prediction...
2025-10-24 23:50:25,581 - data.oil_data_pipeline - INFO - BigQuery client initialized successfully
2025-10-24 23:50:25,581 - data.oil_data_pipeline - INFO - Collecting data from 2020-10-25 to 2025-10-24
2025-10-24 23:50:25,581 - data.oil_data_pipeline - INFO - Collecting oil price data...
2025-10-24 23:50:26,264 - data.oil_data_pipeline - INFO - Collected 1257 records for CL=F
2025-10-24 23:50:26,342 - data.oil_data_pipeline - INFO - Collected 1258 records for BZ=F
2025-10-24 23:50:26,421 - data.oil_data_pipeline - INFO - Collected 1258 records for NG=F
2025-10-24 23:50:26,421 - data.oil_data_pipeline - INFO - Collecting financial market data...
2025-10-24 23:50:26,496 - data.oil_data_pipeline - INFO - Collected 1255 records for ^GSPC
2025-10-24 23:50:26,574 - data.oil_data_pipeline - INFO - Collected 1255 records for ^DJI
2025-10-24 23:50:26,647 - data.oil_data_pipeline - INFO - Collected 1255 records for ^IXIC
2025-10-24 23:50:26,733 - data.oil_data_pipeline - INFO - Collected 1301 records for EURUSD=X
2025-10-24 23:50:26,819 - data.oil_data_pipeline - INFO - Collected 1301 records for GBPUSD=X
2025-10-24 23:50:26,899 - data.oil_data_pipeline - INFO - Collected 1301 records for USDJPY=X
2025-10-24 23:50:27,026 - data.oil_data_pipeline - INFO - Collected 1255 records for XLE
2025-10-24 23:50:27,144 - data.oil_data_pipeline - INFO - Collected 1255 records for VDE
2025-10-24 23:50:27,263 - data.oil_data_pipeline - INFO - Collected 1255 records for IYE
2025-10-24 23:50:27,277 - data.oil_data_pipeline - INFO - Collecting GDELT news data from BigQuery...
2025-10-24 23:50:28,468 - data.oil_data_pipeline - ERROR - GDELT BigQuery error: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/outstanding-map-449312-a0/jobs?prettyPrint=false: Access Denied: Project outstanding-map-449312-a0: User does not have bigquery.jobs.create permission in project outstanding-map-449312-a0.

Location: None
Job ID: 543ea143-680c-486e-ab38-046272a18585

2025-10-24 23:50:28,468 - data.oil_data_pipeline - INFO - Falling back to local news data
2025-10-24 23:50:28,468 - data.oil_data_pipeline - WARNING - Creating comprehensive fallback news data
2025-10-24 23:50:28,473 - data.oil_data_pipeline - WARNING - Failed to load fallback news data: time data "Fri, 24 Oct 2025 06:00:00 -0400" doesn't match format "%a, %d %b %Y %H:%M:%S GMT", at position 5. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
2025-10-24 23:50:28,474 - data.oil_data_pipeline - INFO - Created 150 comprehensive news events
2025-10-24 23:50:28,475 - data.oil_data_pipeline - INFO - Creating news-to-price time mapping...
2025-10-24 23:50:33,353 - data.oil_data_pipeline - INFO - Created 787 news-to-price mappings
2025-10-24 23:50:33,353 - data.oil_data_pipeline - INFO - Data collection complete: 16143 total records
2025-10-24 23:50:33,353 - __main__ - INFO - Data collection complete: 16143 total records
2025-10-24 23:50:33,353 - __main__ - INFO - Starting GPU training...
2025-10-24 23:50:33,353 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:50:33,474 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:50:33,474 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:50:33,474 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:50:33,582 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:50:33,582 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:50:33,587 - models.oil_price_model - INFO - Oil Price Model initialized with 614,556 parameters
2025-10-24 23:50:33,674 - __main__ - INFO - Model initialized with 614,556 parameters
2025-10-24 23:50:35,231 - __main__ - INFO - Epoch 0, Batch 0/50, Loss: 3026.786621
2025-10-24 23:50:35,379 - __main__ - INFO - Epoch 0, Batch 10/50, Loss: 3482.515869
2025-10-24 23:50:35,518 - __main__ - INFO - Epoch 0, Batch 20/50, Loss: 3188.581543
2025-10-24 23:50:35,640 - __main__ - INFO - Epoch 0, Batch 30/50, Loss: 3555.319580
2025-10-24 23:50:35,768 - __main__ - INFO - Epoch 0, Batch 40/50, Loss: 3744.164307
2025-10-24 23:50:36,075 - __main__ - INFO - Epoch 0: Train Loss: 3365.409316, Val Loss: 3326.109478, LR: 9.76e-05
2025-10-24 23:50:36,083 - __main__ - INFO - Saved best model (Val Loss: 3326.109478)
2025-10-24 23:50:36,100 - __main__ - INFO - Epoch 1, Batch 0/50, Loss: 2700.517090
2025-10-24 23:50:36,229 - __main__ - INFO - Epoch 1, Batch 10/50, Loss: 3839.604736
2025-10-24 23:50:36,354 - __main__ - INFO - Epoch 1, Batch 20/50, Loss: 3363.417725
2025-10-24 23:50:36,480 - __main__ - INFO - Epoch 1, Batch 30/50, Loss: 3370.896484
2025-10-24 23:50:36,607 - __main__ - INFO - Epoch 1, Batch 40/50, Loss: 2831.516602
2025-10-24 23:50:36,937 - __main__ - INFO - Epoch 1: Train Loss: 3181.791841, Val Loss: 2592.473271, LR: 9.05e-05
2025-10-24 23:50:36,944 - __main__ - INFO - Saved best model (Val Loss: 2592.473271)
2025-10-24 23:50:36,961 - __main__ - INFO - Epoch 2, Batch 0/50, Loss: 2807.175781
2025-10-24 23:50:37,094 - __main__ - INFO - Epoch 2, Batch 10/50, Loss: 1916.219849
2025-10-24 23:50:37,221 - __main__ - INFO - Epoch 2, Batch 20/50, Loss: 1071.131470
2025-10-24 23:50:37,339 - __main__ - INFO - Epoch 2, Batch 30/50, Loss: 454.445831
2025-10-24 23:50:37,471 - __main__ - INFO - Epoch 2, Batch 40/50, Loss: 392.239502
2025-10-24 23:50:37,770 - __main__ - INFO - Epoch 2: Train Loss: 1106.025140, Val Loss: 210.483921, LR: 7.94e-05
2025-10-24 23:50:37,777 - __main__ - INFO - Saved best model (Val Loss: 210.483921)
2025-10-24 23:50:37,789 - __main__ - INFO - Epoch 3, Batch 0/50, Loss: 401.368378
2025-10-24 23:50:37,908 - __main__ - INFO - Epoch 3, Batch 10/50, Loss: 123.379143
2025-10-24 23:50:38,033 - __main__ - INFO - Epoch 3, Batch 20/50, Loss: 265.103363
2025-10-24 23:50:38,160 - __main__ - INFO - Epoch 3, Batch 30/50, Loss: 300.319885
2025-10-24 23:50:38,285 - __main__ - INFO - Epoch 3, Batch 40/50, Loss: 171.797302
2025-10-24 23:50:38,581 - __main__ - INFO - Epoch 3: Train Loss: 247.331923, Val Loss: 115.860884, LR: 6.55e-05
2025-10-24 23:50:38,588 - __main__ - INFO - Saved best model (Val Loss: 115.860884)
2025-10-24 23:50:38,601 - __main__ - INFO - Epoch 4, Batch 0/50, Loss: 252.775482
2025-10-24 23:50:38,725 - __main__ - INFO - Epoch 4, Batch 10/50, Loss: 270.894836
2025-10-24 23:50:38,854 - __main__ - INFO - Epoch 4, Batch 20/50, Loss: 130.468628
2025-10-24 23:50:38,983 - __main__ - INFO - Epoch 4, Batch 30/50, Loss: 224.008759
2025-10-24 23:50:39,110 - __main__ - INFO - Epoch 4, Batch 40/50, Loss: 145.638092
2025-10-24 23:50:39,408 - __main__ - INFO - Epoch 4: Train Loss: 196.385053, Val Loss: 90.488672, LR: 5.00e-05
2025-10-24 23:50:39,415 - __main__ - INFO - Saved best model (Val Loss: 90.488672)
2025-10-24 23:50:39,432 - __main__ - INFO - Epoch 5, Batch 0/50, Loss: 93.447716
2025-10-24 23:50:39,557 - __main__ - INFO - Epoch 5, Batch 10/50, Loss: 148.988373
2025-10-24 23:50:39,698 - __main__ - INFO - Epoch 5, Batch 20/50, Loss: 126.641457
2025-10-24 23:50:39,821 - __main__ - INFO - Epoch 5, Batch 30/50, Loss: 167.008789
2025-10-24 23:50:39,951 - __main__ - INFO - Epoch 5, Batch 40/50, Loss: 166.134827
2025-10-24 23:50:40,315 - __main__ - INFO - Epoch 5: Train Loss: 150.626587, Val Loss: 68.233930, LR: 3.45e-05
2025-10-24 23:50:40,323 - __main__ - INFO - Saved best model (Val Loss: 68.233930)
2025-10-24 23:50:40,337 - __main__ - INFO - Epoch 6, Batch 0/50, Loss: 119.326660
2025-10-24 23:50:40,472 - __main__ - INFO - Epoch 6, Batch 10/50, Loss: 209.280151
2025-10-24 23:50:40,617 - __main__ - INFO - Epoch 6, Batch 20/50, Loss: 257.778717
2025-10-24 23:50:40,760 - __main__ - INFO - Epoch 6, Batch 30/50, Loss: 149.615265
2025-10-24 23:50:40,899 - __main__ - INFO - Epoch 6, Batch 40/50, Loss: 106.105461
2025-10-24 23:50:41,263 - __main__ - INFO - Epoch 6: Train Loss: 152.902971, Val Loss: 62.290760, LR: 2.06e-05
2025-10-24 23:50:41,272 - __main__ - INFO - Saved best model (Val Loss: 62.290760)
2025-10-24 23:50:41,288 - __main__ - INFO - Epoch 7, Batch 0/50, Loss: 95.741150
2025-10-24 23:50:41,416 - __main__ - INFO - Epoch 7, Batch 10/50, Loss: 123.593491
2025-10-24 23:50:41,553 - __main__ - INFO - Epoch 7, Batch 20/50, Loss: 129.681931
2025-10-24 23:50:41,683 - __main__ - INFO - Epoch 7, Batch 30/50, Loss: 140.552872
2025-10-24 23:50:41,855 - __main__ - INFO - Epoch 7, Batch 40/50, Loss: 161.244431
2025-10-24 23:50:42,202 - __main__ - INFO - Epoch 7: Train Loss: 140.359856, Val Loss: 58.292359, LR: 9.55e-06
2025-10-24 23:50:42,210 - __main__ - INFO - Saved best model (Val Loss: 58.292359)
2025-10-24 23:50:42,227 - __main__ - INFO - Epoch 8, Batch 0/50, Loss: 63.008011
2025-10-24 23:50:42,354 - __main__ - INFO - Epoch 8, Batch 10/50, Loss: 221.833939
2025-10-24 23:50:42,492 - __main__ - INFO - Epoch 8, Batch 20/50, Loss: 164.581635
2025-10-24 23:50:42,642 - __main__ - INFO - Epoch 8, Batch 30/50, Loss: 106.514275
2025-10-24 23:50:42,770 - __main__ - INFO - Epoch 8, Batch 40/50, Loss: 149.587036
2025-10-24 23:50:43,113 - __main__ - INFO - Epoch 8: Train Loss: 142.323547, Val Loss: 57.251523, LR: 2.45e-06
2025-10-24 23:50:43,120 - __main__ - INFO - Saved best model (Val Loss: 57.251523)
2025-10-24 23:50:43,131 - __main__ - INFO - Epoch 9, Batch 0/50, Loss: 120.082260
2025-10-24 23:50:43,268 - __main__ - INFO - Epoch 9, Batch 10/50, Loss: 143.932877
2025-10-24 23:50:43,395 - __main__ - INFO - Epoch 9, Batch 20/50, Loss: 127.381409
2025-10-24 23:50:43,528 - __main__ - INFO - Epoch 9, Batch 30/50, Loss: 188.337189
2025-10-24 23:50:43,649 - __main__ - INFO - Epoch 9, Batch 40/50, Loss: 82.637978
2025-10-24 23:50:43,947 - __main__ - INFO - Epoch 9: Train Loss: 140.882903, Val Loss: 57.709948, LR: 1.00e-04
2025-10-24 23:50:43,962 - __main__ - INFO - Epoch 10, Batch 0/50, Loss: 183.721771
2025-10-24 23:50:44,103 - __main__ - INFO - Epoch 10, Batch 10/50, Loss: 140.874527
2025-10-24 23:50:44,241 - __main__ - INFO - Epoch 10, Batch 20/50, Loss: 85.938324
2025-10-24 23:50:44,378 - __main__ - INFO - Epoch 10, Batch 30/50, Loss: 110.395203
2025-10-24 23:50:44,512 - __main__ - INFO - Epoch 10, Batch 40/50, Loss: 98.263153
2025-10-24 23:50:44,826 - __main__ - INFO - Epoch 10: Train Loss: 132.190381, Val Loss: 46.561971, LR: 9.94e-05
2025-10-24 23:50:44,833 - __main__ - INFO - Saved best model (Val Loss: 46.561971)
2025-10-24 23:50:44,845 - __main__ - INFO - Epoch 11, Batch 0/50, Loss: 78.313324
2025-10-24 23:50:44,971 - __main__ - INFO - Epoch 11, Batch 10/50, Loss: 99.780708
2025-10-24 23:50:45,103 - __main__ - INFO - Epoch 11, Batch 20/50, Loss: 147.455811
2025-10-24 23:50:45,230 - __main__ - INFO - Epoch 11, Batch 30/50, Loss: 105.705589
2025-10-24 23:50:45,352 - __main__ - INFO - Epoch 11, Batch 40/50, Loss: 171.933929
2025-10-24 23:50:45,654 - __main__ - INFO - Epoch 11: Train Loss: 118.984263, Val Loss: 52.543405, LR: 9.76e-05
2025-10-24 23:50:45,666 - __main__ - INFO - Epoch 12, Batch 0/50, Loss: 117.250572
2025-10-24 23:50:45,800 - __main__ - INFO - Epoch 12, Batch 10/50, Loss: 86.562767
2025-10-24 23:50:45,921 - __main__ - INFO - Epoch 12, Batch 20/50, Loss: 71.862434
2025-10-24 23:50:46,044 - __main__ - INFO - Epoch 12, Batch 30/50, Loss: 102.358093
2025-10-24 23:50:46,174 - __main__ - INFO - Epoch 12, Batch 40/50, Loss: 96.034569
2025-10-24 23:50:46,524 - __main__ - INFO - Epoch 12: Train Loss: 111.637826, Val Loss: 35.411819, LR: 9.46e-05
2025-10-24 23:50:46,530 - __main__ - INFO - Saved best model (Val Loss: 35.411819)
2025-10-24 23:50:46,543 - __main__ - INFO - Epoch 13, Batch 0/50, Loss: 90.456047
2025-10-24 23:50:46,671 - __main__ - INFO - Epoch 13, Batch 10/50, Loss: 89.135284
2025-10-24 23:50:46,783 - __main__ - INFO - Epoch 13, Batch 20/50, Loss: 65.101677
2025-10-24 23:50:46,921 - __main__ - INFO - Epoch 13, Batch 30/50, Loss: 62.861954
2025-10-24 23:50:47,051 - __main__ - INFO - Epoch 13, Batch 40/50, Loss: 66.111427
2025-10-24 23:50:47,395 - __main__ - INFO - Epoch 13: Train Loss: 107.294081, Val Loss: 34.437955, LR: 9.05e-05
2025-10-24 23:50:47,403 - __main__ - INFO - Saved best model (Val Loss: 34.437955)
2025-10-24 23:50:47,420 - __main__ - INFO - Epoch 14, Batch 0/50, Loss: 166.486252
2025-10-24 23:50:47,544 - __main__ - INFO - Epoch 14, Batch 10/50, Loss: 86.468628
2025-10-24 23:50:47,667 - __main__ - INFO - Epoch 14, Batch 20/50, Loss: 68.693855
2025-10-24 23:50:47,779 - __main__ - INFO - Epoch 14, Batch 30/50, Loss: 98.647682
2025-10-24 23:50:47,901 - __main__ - INFO - Epoch 14, Batch 40/50, Loss: 109.590477
2025-10-24 23:50:48,187 - __main__ - INFO - Epoch 14: Train Loss: 102.519178, Val Loss: 27.540556, LR: 8.54e-05
2025-10-24 23:50:48,195 - __main__ - INFO - Saved best model (Val Loss: 27.540556)
2025-10-24 23:50:48,211 - __main__ - INFO - Epoch 15, Batch 0/50, Loss: 88.497955
2025-10-24 23:50:48,337 - __main__ - INFO - Epoch 15, Batch 10/50, Loss: 71.458908
2025-10-24 23:50:48,523 - __main__ - INFO - Epoch 15, Batch 20/50, Loss: 89.359261
2025-10-24 23:50:48,661 - __main__ - INFO - Epoch 15, Batch 30/50, Loss: 91.946045
2025-10-24 23:50:48,792 - __main__ - INFO - Epoch 15, Batch 40/50, Loss: 85.962662
2025-10-24 23:50:49,101 - __main__ - INFO - Epoch 15: Train Loss: 87.486641, Val Loss: 26.163640, LR: 7.94e-05
2025-10-24 23:50:49,109 - __main__ - INFO - Saved best model (Val Loss: 26.163640)
2025-10-24 23:50:49,124 - __main__ - INFO - Epoch 16, Batch 0/50, Loss: 59.583416
2025-10-24 23:50:49,263 - __main__ - INFO - Epoch 16, Batch 10/50, Loss: 67.386581
2025-10-24 23:50:49,394 - __main__ - INFO - Epoch 16, Batch 20/50, Loss: 77.886070
2025-10-24 23:50:49,515 - __main__ - INFO - Epoch 16, Batch 30/50, Loss: 86.891602
2025-10-24 23:50:49,637 - __main__ - INFO - Epoch 16, Batch 40/50, Loss: 48.139114
2025-10-24 23:50:49,952 - __main__ - INFO - Epoch 16: Train Loss: 98.176454, Val Loss: 29.731793, LR: 7.27e-05
2025-10-24 23:50:49,965 - __main__ - INFO - Epoch 17, Batch 0/50, Loss: 71.217613
2025-10-24 23:50:50,093 - __main__ - INFO - Epoch 17, Batch 10/50, Loss: 96.726379
2025-10-24 23:50:50,227 - __main__ - INFO - Epoch 17, Batch 20/50, Loss: 58.628220
2025-10-24 23:50:50,357 - __main__ - INFO - Epoch 17, Batch 30/50, Loss: 58.169590
2025-10-24 23:50:50,479 - __main__ - INFO - Epoch 17, Batch 40/50, Loss: 68.216545
2025-10-24 23:50:50,798 - __main__ - INFO - Epoch 17: Train Loss: 93.949910, Val Loss: 22.551993, LR: 6.55e-05
2025-10-24 23:50:50,805 - __main__ - INFO - Saved best model (Val Loss: 22.551993)
2025-10-24 23:50:50,818 - __main__ - INFO - Epoch 18, Batch 0/50, Loss: 78.888519
2025-10-24 23:50:50,952 - __main__ - INFO - Epoch 18, Batch 10/50, Loss: 529.829590
2025-10-24 23:50:51,080 - __main__ - INFO - Epoch 18, Batch 20/50, Loss: 103.394325
2025-10-24 23:50:51,204 - __main__ - INFO - Epoch 18, Batch 30/50, Loss: 34.329323
2025-10-24 23:50:51,339 - __main__ - INFO - Epoch 18, Batch 40/50, Loss: 93.090897
2025-10-24 23:50:51,651 - __main__ - INFO - Epoch 18: Train Loss: 85.760604, Val Loss: 21.157581, LR: 5.78e-05
2025-10-24 23:50:51,659 - __main__ - INFO - Saved best model (Val Loss: 21.157581)
2025-10-24 23:50:51,672 - __main__ - INFO - Epoch 19, Batch 0/50, Loss: 68.966789
2025-10-24 23:50:51,792 - __main__ - INFO - Epoch 19, Batch 10/50, Loss: 73.944908
2025-10-24 23:50:51,919 - __main__ - INFO - Epoch 19, Batch 20/50, Loss: 109.488205
2025-10-24 23:50:52,037 - __main__ - INFO - Epoch 19, Batch 30/50, Loss: 107.802887
2025-10-24 23:50:52,163 - __main__ - INFO - Epoch 19, Batch 40/50, Loss: 95.717079
2025-10-24 23:50:52,462 - __main__ - INFO - Epoch 19: Train Loss: 81.787348, Val Loss: 19.948108, LR: 5.00e-05
2025-10-24 23:50:52,469 - __main__ - INFO - Saved best model (Val Loss: 19.948108)
2025-10-24 23:50:52,481 - __main__ - INFO - Epoch 20, Batch 0/50, Loss: 57.474777
2025-10-24 23:50:52,606 - __main__ - INFO - Epoch 20, Batch 10/50, Loss: 65.301743
2025-10-24 23:50:52,728 - __main__ - INFO - Epoch 20, Batch 20/50, Loss: 65.140221
2025-10-24 23:50:52,846 - __main__ - INFO - Epoch 20, Batch 30/50, Loss: 48.347805
2025-10-24 23:50:52,965 - __main__ - INFO - Epoch 20, Batch 40/50, Loss: 53.164143
2025-10-24 23:50:53,270 - __main__ - INFO - Epoch 20: Train Loss: 78.661429, Val Loss: 19.287643, LR: 4.22e-05
2025-10-24 23:50:53,277 - __main__ - INFO - Saved best model (Val Loss: 19.287643)
2025-10-24 23:50:53,290 - __main__ - INFO - Epoch 21, Batch 0/50, Loss: 81.298103
2025-10-24 23:50:53,413 - __main__ - INFO - Epoch 21, Batch 10/50, Loss: 41.948456
2025-10-24 23:50:53,538 - __main__ - INFO - Epoch 21, Batch 20/50, Loss: 42.068172
2025-10-24 23:50:53,662 - __main__ - INFO - Epoch 21, Batch 30/50, Loss: 86.786102
2025-10-24 23:50:53,785 - __main__ - INFO - Epoch 21, Batch 40/50, Loss: 68.143250
2025-10-24 23:50:54,080 - __main__ - INFO - Epoch 21: Train Loss: 72.527589, Val Loss: 19.227028, LR: 3.45e-05
2025-10-24 23:50:54,087 - __main__ - INFO - Saved best model (Val Loss: 19.227028)
2025-10-24 23:50:54,099 - __main__ - INFO - Epoch 22, Batch 0/50, Loss: 51.081913
2025-10-24 23:50:54,227 - __main__ - INFO - Epoch 22, Batch 10/50, Loss: 72.489853
2025-10-24 23:50:54,367 - __main__ - INFO - Epoch 22, Batch 20/50, Loss: 91.662949
2025-10-24 23:50:54,513 - __main__ - INFO - Epoch 22, Batch 30/50, Loss: 70.318871
2025-10-24 23:50:54,630 - __main__ - INFO - Epoch 22, Batch 40/50, Loss: 81.175972
2025-10-24 23:50:55,014 - __main__ - INFO - Epoch 22: Train Loss: 75.372446, Val Loss: 19.325039, LR: 2.73e-05
2025-10-24 23:50:55,026 - __main__ - INFO - Epoch 23, Batch 0/50, Loss: 49.497677
2025-10-24 23:50:55,177 - __main__ - INFO - Epoch 23, Batch 10/50, Loss: 51.601513
2025-10-24 23:50:55,297 - __main__ - INFO - Epoch 23, Batch 20/50, Loss: 79.087952
2025-10-24 23:50:55,426 - __main__ - INFO - Epoch 23, Batch 30/50, Loss: 67.583450
2025-10-24 23:50:55,552 - __main__ - INFO - Epoch 23, Batch 40/50, Loss: 56.913242
2025-10-24 23:50:55,850 - __main__ - INFO - Epoch 23: Train Loss: 69.660941, Val Loss: 18.835974, LR: 2.06e-05
2025-10-24 23:50:55,857 - __main__ - INFO - Saved best model (Val Loss: 18.835974)
2025-10-24 23:50:55,869 - __main__ - INFO - Epoch 24, Batch 0/50, Loss: 58.434284
2025-10-24 23:50:55,997 - __main__ - INFO - Epoch 24, Batch 10/50, Loss: 52.313618
2025-10-24 23:50:56,119 - __main__ - INFO - Epoch 24, Batch 20/50, Loss: 72.928307
2025-10-24 23:50:56,239 - __main__ - INFO - Epoch 24, Batch 30/50, Loss: 72.808884
2025-10-24 23:50:56,378 - __main__ - INFO - Epoch 24, Batch 40/50, Loss: 60.074238
2025-10-24 23:50:56,705 - __main__ - INFO - Epoch 24: Train Loss: 75.475950, Val Loss: 20.011309, LR: 1.46e-05
2025-10-24 23:50:56,717 - __main__ - INFO - Epoch 25, Batch 0/50, Loss: 73.436386
2025-10-24 23:50:56,859 - __main__ - INFO - Epoch 25, Batch 10/50, Loss: 64.619621
2025-10-24 23:50:56,978 - __main__ - INFO - Epoch 25, Batch 20/50, Loss: 79.778549
2025-10-24 23:50:57,106 - __main__ - INFO - Epoch 25, Batch 30/50, Loss: 81.736732
2025-10-24 23:50:57,227 - __main__ - INFO - Epoch 25, Batch 40/50, Loss: 464.173157
2025-10-24 23:50:57,575 - __main__ - INFO - Epoch 25: Train Loss: 77.570096, Val Loss: 19.496469, LR: 9.55e-06
2025-10-24 23:50:57,589 - __main__ - INFO - Epoch 26, Batch 0/50, Loss: 61.463917
2025-10-24 23:50:57,718 - __main__ - INFO - Epoch 26, Batch 10/50, Loss: 62.104023
2025-10-24 23:50:57,841 - __main__ - INFO - Epoch 26, Batch 20/50, Loss: 61.088829
2025-10-24 23:50:57,970 - __main__ - INFO - Epoch 26, Batch 30/50, Loss: 77.472839
2025-10-24 23:50:58,099 - __main__ - INFO - Epoch 26, Batch 40/50, Loss: 62.007946
2025-10-24 23:50:58,451 - __main__ - INFO - Epoch 26: Train Loss: 76.337991, Val Loss: 19.059126, LR: 5.45e-06
2025-10-24 23:50:58,463 - __main__ - INFO - Epoch 27, Batch 0/50, Loss: 79.870979
2025-10-24 23:50:58,601 - __main__ - INFO - Epoch 27, Batch 10/50, Loss: 33.173206
2025-10-24 23:50:58,718 - __main__ - INFO - Epoch 27, Batch 20/50, Loss: 80.950264
2025-10-24 23:50:58,840 - __main__ - INFO - Epoch 27, Batch 30/50, Loss: 101.185570
2025-10-24 23:50:58,963 - __main__ - INFO - Epoch 27, Batch 40/50, Loss: 89.181664
2025-10-24 23:50:59,296 - __main__ - INFO - Epoch 27: Train Loss: 75.673022, Val Loss: 18.571372, LR: 2.45e-06
2025-10-24 23:50:59,304 - __main__ - INFO - Saved best model (Val Loss: 18.571372)
2025-10-24 23:50:59,319 - __main__ - INFO - Epoch 28, Batch 0/50, Loss: 39.642143
2025-10-24 23:50:59,464 - __main__ - INFO - Epoch 28, Batch 10/50, Loss: 68.206024
2025-10-24 23:50:59,595 - __main__ - INFO - Epoch 28, Batch 20/50, Loss: 52.060772
2025-10-24 23:50:59,725 - __main__ - INFO - Epoch 28, Batch 30/50, Loss: 42.984585
2025-10-24 23:50:59,855 - __main__ - INFO - Epoch 28, Batch 40/50, Loss: 60.606319
2025-10-24 23:51:00,183 - __main__ - INFO - Epoch 28: Train Loss: 74.488968, Val Loss: 18.555902, LR: 6.16e-07
2025-10-24 23:51:00,191 - __main__ - INFO - Saved best model (Val Loss: 18.555902)
2025-10-24 23:51:00,203 - __main__ - INFO - Epoch 29, Batch 0/50, Loss: 89.916397
2025-10-24 23:51:00,332 - __main__ - INFO - Epoch 29, Batch 10/50, Loss: 73.551750
2025-10-24 23:51:00,455 - __main__ - INFO - Epoch 29, Batch 20/50, Loss: 52.864059
2025-10-24 23:51:00,583 - __main__ - INFO - Epoch 29, Batch 30/50, Loss: 33.313023
2025-10-24 23:51:00,717 - __main__ - INFO - Epoch 29, Batch 40/50, Loss: 67.254166
2025-10-24 23:51:01,037 - __main__ - INFO - Epoch 29: Train Loss: 77.985810, Val Loss: 18.846487, LR: 1.00e-04
2025-10-24 23:51:01,052 - __main__ - INFO - Epoch 30, Batch 0/50, Loss: 46.268990
2025-10-24 23:51:01,178 - __main__ - INFO - Epoch 30, Batch 10/50, Loss: 39.222660
2025-10-24 23:51:01,296 - __main__ - INFO - Epoch 30, Batch 20/50, Loss: 104.480301
2025-10-24 23:51:01,417 - __main__ - INFO - Epoch 30, Batch 30/50, Loss: 52.103340
2025-10-24 23:51:01,547 - __main__ - INFO - Epoch 30, Batch 40/50, Loss: 65.982880
2025-10-24 23:51:01,857 - __main__ - INFO - Epoch 30: Train Loss: 70.263269, Val Loss: 24.468023, LR: 9.98e-05
2025-10-24 23:51:01,869 - __main__ - INFO - Epoch 31, Batch 0/50, Loss: 56.245850
2025-10-24 23:51:01,989 - __main__ - INFO - Epoch 31, Batch 10/50, Loss: 58.347836
2025-10-24 23:51:02,109 - __main__ - INFO - Epoch 31, Batch 20/50, Loss: 47.870022
2025-10-24 23:51:02,228 - __main__ - INFO - Epoch 31, Batch 30/50, Loss: 50.707836
2025-10-24 23:51:02,345 - __main__ - INFO - Epoch 31, Batch 40/50, Loss: 48.362682
2025-10-24 23:51:02,732 - __main__ - INFO - Epoch 31: Train Loss: 70.615629, Val Loss: 24.073487, LR: 9.94e-05
2025-10-24 23:51:02,744 - __main__ - INFO - Epoch 32, Batch 0/50, Loss: 73.935471
2025-10-24 23:51:02,863 - __main__ - INFO - Epoch 32, Batch 10/50, Loss: 73.075829
2025-10-24 23:51:02,990 - __main__ - INFO - Epoch 32, Batch 20/50, Loss: 44.770760
2025-10-24 23:51:03,115 - __main__ - INFO - Epoch 32, Batch 30/50, Loss: 49.377953
2025-10-24 23:51:03,248 - __main__ - INFO - Epoch 32, Batch 40/50, Loss: 56.448715
2025-10-24 23:51:03,549 - __main__ - INFO - Epoch 32: Train Loss: 74.263248, Val Loss: 18.614770, LR: 9.86e-05
2025-10-24 23:51:03,562 - __main__ - INFO - Epoch 33, Batch 0/50, Loss: 48.557529
2025-10-24 23:51:03,684 - __main__ - INFO - Epoch 33, Batch 10/50, Loss: 54.228157
2025-10-24 23:51:03,796 - __main__ - INFO - Epoch 33, Batch 20/50, Loss: 80.164276
2025-10-24 23:51:03,930 - __main__ - INFO - Epoch 33, Batch 30/50, Loss: 51.007576
2025-10-24 23:51:04,097 - __main__ - INFO - Epoch 33, Batch 40/50, Loss: 49.932899
2025-10-24 23:51:04,413 - __main__ - INFO - Epoch 33: Train Loss: 67.481234, Val Loss: 18.357541, LR: 9.76e-05
2025-10-24 23:51:04,421 - __main__ - INFO - Saved best model (Val Loss: 18.357541)
2025-10-24 23:51:04,433 - __main__ - INFO - Epoch 34, Batch 0/50, Loss: 46.608524
2025-10-24 23:51:04,568 - __main__ - INFO - Epoch 34, Batch 10/50, Loss: 52.450092
2025-10-24 23:51:04,705 - __main__ - INFO - Epoch 34, Batch 20/50, Loss: 99.895844
2025-10-24 23:51:04,823 - __main__ - INFO - Epoch 34, Batch 30/50, Loss: 43.376953
2025-10-24 23:51:04,944 - __main__ - INFO - Epoch 34, Batch 40/50, Loss: 49.464817
2025-10-24 23:51:05,236 - __main__ - INFO - Epoch 34: Train Loss: 74.737107, Val Loss: 18.282318, LR: 9.62e-05
2025-10-24 23:51:05,243 - __main__ - INFO - Saved best model (Val Loss: 18.282318)
2025-10-24 23:51:05,254 - __main__ - INFO - Epoch 35, Batch 0/50, Loss: 57.600777
2025-10-24 23:51:05,379 - __main__ - INFO - Epoch 35, Batch 10/50, Loss: 86.414909
2025-10-24 23:51:05,496 - __main__ - INFO - Epoch 35, Batch 20/50, Loss: 97.064018
2025-10-24 23:51:05,622 - __main__ - INFO - Epoch 35, Batch 30/50, Loss: 88.077492
2025-10-24 23:51:05,741 - __main__ - INFO - Epoch 35, Batch 40/50, Loss: 48.905220
2025-10-24 23:51:06,066 - __main__ - INFO - Epoch 35: Train Loss: 69.760560, Val Loss: 22.868311, LR: 9.46e-05
2025-10-24 23:51:06,079 - __main__ - INFO - Epoch 36, Batch 0/50, Loss: 147.918381
2025-10-24 23:51:06,200 - __main__ - INFO - Epoch 36, Batch 10/50, Loss: 72.259598
2025-10-24 23:51:06,322 - __main__ - INFO - Epoch 36, Batch 20/50, Loss: 44.246243
2025-10-24 23:51:06,440 - __main__ - INFO - Epoch 36, Batch 30/50, Loss: 50.935894
2025-10-24 23:51:06,566 - __main__ - INFO - Epoch 36, Batch 40/50, Loss: 39.335804
2025-10-24 23:51:06,865 - __main__ - INFO - Epoch 36: Train Loss: 67.729498, Val Loss: 22.026231, LR: 9.26e-05
2025-10-24 23:51:06,879 - __main__ - INFO - Epoch 37, Batch 0/50, Loss: 26.260548
2025-10-24 23:51:06,994 - __main__ - INFO - Epoch 37, Batch 10/50, Loss: 84.552368
2025-10-24 23:51:07,114 - __main__ - INFO - Epoch 37, Batch 20/50, Loss: 45.762863
2025-10-24 23:51:07,242 - __main__ - INFO - Epoch 37, Batch 30/50, Loss: 53.669041
2025-10-24 23:51:07,372 - __main__ - INFO - Epoch 37, Batch 40/50, Loss: 91.836380
2025-10-24 23:51:07,733 - __main__ - INFO - Epoch 37: Train Loss: 62.668716, Val Loss: 18.554064, LR: 9.05e-05
2025-10-24 23:51:07,746 - __main__ - INFO - Epoch 38, Batch 0/50, Loss: 61.300888
2025-10-24 23:51:07,872 - __main__ - INFO - Epoch 38, Batch 10/50, Loss: 49.082573
2025-10-24 23:51:08,002 - __main__ - INFO - Epoch 38, Batch 20/50, Loss: 58.045578
2025-10-24 23:51:08,135 - __main__ - INFO - Epoch 38, Batch 30/50, Loss: 473.626251
2025-10-24 23:51:08,272 - __main__ - INFO - Epoch 38, Batch 40/50, Loss: 53.153355
2025-10-24 23:51:08,642 - __main__ - INFO - Epoch 38: Train Loss: 65.022106, Val Loss: 17.661500, LR: 8.80e-05
2025-10-24 23:51:08,649 - __main__ - INFO - Saved best model (Val Loss: 17.661500)
2025-10-24 23:51:08,662 - __main__ - INFO - Epoch 39, Batch 0/50, Loss: 49.415676
2025-10-24 23:51:08,801 - __main__ - INFO - Epoch 39, Batch 10/50, Loss: 68.377190
2025-10-24 23:51:08,928 - __main__ - INFO - Epoch 39, Batch 20/50, Loss: 39.333874
2025-10-24 23:51:09,059 - __main__ - INFO - Epoch 39, Batch 30/50, Loss: 40.269039
2025-10-24 23:51:09,191 - __main__ - INFO - Epoch 39, Batch 40/50, Loss: 39.967079
2025-10-24 23:51:09,512 - __main__ - INFO - Epoch 39: Train Loss: 62.656812, Val Loss: 18.238152, LR: 8.54e-05
2025-10-24 23:51:09,527 - __main__ - INFO - Epoch 40, Batch 0/50, Loss: 32.081425
2025-10-24 23:51:09,666 - __main__ - INFO - Epoch 40, Batch 10/50, Loss: 78.561775
2025-10-24 23:51:09,800 - __main__ - INFO - Epoch 40, Batch 20/50, Loss: 59.533291
2025-10-24 23:51:09,933 - __main__ - INFO - Epoch 40, Batch 30/50, Loss: 38.420029
2025-10-24 23:51:10,069 - __main__ - INFO - Epoch 40, Batch 40/50, Loss: 43.490822
2025-10-24 23:51:10,393 - __main__ - INFO - Epoch 40: Train Loss: 63.941480, Val Loss: 17.562099, LR: 8.25e-05
2025-10-24 23:51:10,400 - __main__ - INFO - Saved best model (Val Loss: 17.562099)
2025-10-24 23:51:10,413 - __main__ - INFO - Epoch 41, Batch 0/50, Loss: 64.085129
2025-10-24 23:51:10,551 - __main__ - INFO - Epoch 41, Batch 10/50, Loss: 63.398785
2025-10-24 23:51:10,674 - __main__ - INFO - Epoch 41, Batch 20/50, Loss: 61.467373
2025-10-24 23:51:10,810 - __main__ - INFO - Epoch 41, Batch 30/50, Loss: 55.934692
2025-10-24 23:51:10,939 - __main__ - INFO - Epoch 41, Batch 40/50, Loss: 90.904648
2025-10-24 23:51:11,262 - __main__ - INFO - Epoch 41: Train Loss: 65.743174, Val Loss: 18.888246, LR: 7.94e-05
2025-10-24 23:51:11,275 - __main__ - INFO - Epoch 42, Batch 0/50, Loss: 48.168427
2025-10-24 23:51:11,392 - __main__ - INFO - Epoch 42, Batch 10/50, Loss: 44.844208
2025-10-24 23:51:11,524 - __main__ - INFO - Epoch 42, Batch 20/50, Loss: 71.152145
2025-10-24 23:51:11,668 - __main__ - INFO - Epoch 42, Batch 30/50, Loss: 48.110340
2025-10-24 23:51:11,828 - __main__ - INFO - Epoch 42, Batch 40/50, Loss: 71.450081
2025-10-24 23:51:12,142 - __main__ - INFO - Epoch 42: Train Loss: 62.502535, Val Loss: 18.158795, LR: 7.61e-05
2025-10-24 23:51:12,157 - __main__ - INFO - Epoch 43, Batch 0/50, Loss: 82.858139
2025-10-24 23:51:12,288 - __main__ - INFO - Epoch 43, Batch 10/50, Loss: 34.752979
2025-10-24 23:51:12,420 - __main__ - INFO - Epoch 43, Batch 20/50, Loss: 49.975994
2025-10-24 23:51:12,540 - __main__ - INFO - Epoch 43, Batch 30/50, Loss: 76.964859
2025-10-24 23:51:12,672 - __main__ - INFO - Epoch 43, Batch 40/50, Loss: 47.732113
2025-10-24 23:51:13,058 - __main__ - INFO - Epoch 43: Train Loss: 61.691503, Val Loss: 19.882299, LR: 7.27e-05
2025-10-24 23:51:13,070 - __main__ - INFO - Epoch 44, Batch 0/50, Loss: 68.909378
2025-10-24 23:51:13,214 - __main__ - INFO - Epoch 44, Batch 10/50, Loss: 40.888351
2025-10-24 23:51:13,336 - __main__ - INFO - Epoch 44, Batch 20/50, Loss: 41.589756
2025-10-24 23:51:13,467 - __main__ - INFO - Epoch 44, Batch 30/50, Loss: 43.415188
2025-10-24 23:51:13,600 - __main__ - INFO - Epoch 44, Batch 40/50, Loss: 59.727989
2025-10-24 23:51:13,903 - __main__ - INFO - Epoch 44: Train Loss: 64.337348, Val Loss: 17.606166, LR: 6.91e-05
2025-10-24 23:51:13,915 - __main__ - INFO - Epoch 45, Batch 0/50, Loss: 57.667446
2025-10-24 23:51:14,049 - __main__ - INFO - Epoch 45, Batch 10/50, Loss: 85.664009
2025-10-24 23:51:14,179 - __main__ - INFO - Epoch 45, Batch 20/50, Loss: 39.550770
2025-10-24 23:51:14,314 - __main__ - INFO - Epoch 45, Batch 30/50, Loss: 32.037083
2025-10-24 23:51:14,451 - __main__ - INFO - Epoch 45, Batch 40/50, Loss: 35.832474
2025-10-24 23:51:14,766 - __main__ - INFO - Epoch 45: Train Loss: 61.151095, Val Loss: 17.005889, LR: 6.55e-05
2025-10-24 23:51:14,774 - __main__ - INFO - Saved best model (Val Loss: 17.005889)
2025-10-24 23:51:14,791 - __main__ - INFO - Epoch 46, Batch 0/50, Loss: 55.292953
2025-10-24 23:51:14,948 - __main__ - INFO - Epoch 46, Batch 10/50, Loss: 37.475731
2025-10-24 23:51:15,067 - __main__ - INFO - Epoch 46, Batch 20/50, Loss: 44.498882
2025-10-24 23:51:15,189 - __main__ - INFO - Epoch 46, Batch 30/50, Loss: 59.110146
2025-10-24 23:51:15,307 - __main__ - INFO - Epoch 46, Batch 40/50, Loss: 56.464825
2025-10-24 23:51:15,608 - __main__ - INFO - Epoch 46: Train Loss: 58.595953, Val Loss: 17.219825, LR: 6.17e-05
2025-10-24 23:51:15,620 - __main__ - INFO - Epoch 47, Batch 0/50, Loss: 23.944700
2025-10-24 23:51:15,745 - __main__ - INFO - Epoch 47, Batch 10/50, Loss: 66.632645
2025-10-24 23:51:15,865 - __main__ - INFO - Epoch 47, Batch 20/50, Loss: 72.847305
2025-10-24 23:51:15,993 - __main__ - INFO - Epoch 47, Batch 30/50, Loss: 36.660294
2025-10-24 23:51:16,117 - __main__ - INFO - Epoch 47, Batch 40/50, Loss: 31.966156
2025-10-24 23:51:16,407 - __main__ - INFO - Epoch 47: Train Loss: 63.294930, Val Loss: 18.123836, LR: 5.78e-05
2025-10-24 23:51:16,419 - __main__ - INFO - Epoch 48, Batch 0/50, Loss: 44.364426
2025-10-24 23:51:16,552 - __main__ - INFO - Epoch 48, Batch 10/50, Loss: 55.335106
2025-10-24 23:51:16,675 - __main__ - INFO - Epoch 48, Batch 20/50, Loss: 78.651733
2025-10-24 23:51:16,819 - __main__ - INFO - Epoch 48, Batch 30/50, Loss: 34.701923
2025-10-24 23:51:16,955 - __main__ - INFO - Epoch 48, Batch 40/50, Loss: 52.165039
2025-10-24 23:51:17,256 - __main__ - INFO - Epoch 48: Train Loss: 66.725755, Val Loss: 18.351456, LR: 5.39e-05
2025-10-24 23:51:17,273 - __main__ - INFO - Epoch 49, Batch 0/50, Loss: 34.107193
2025-10-24 23:51:17,403 - __main__ - INFO - Epoch 49, Batch 10/50, Loss: 39.126705
2025-10-24 23:51:17,538 - __main__ - INFO - Epoch 49, Batch 20/50, Loss: 38.654266
2025-10-24 23:51:17,666 - __main__ - INFO - Epoch 49, Batch 30/50, Loss: 36.302608
2025-10-24 23:51:17,800 - __main__ - INFO - Epoch 49, Batch 40/50, Loss: 25.587914
2025-10-24 23:51:18,112 - __main__ - INFO - Epoch 49: Train Loss: 58.172820, Val Loss: 20.386531, LR: 5.00e-05
2025-10-24 23:51:18,112 - __main__ - INFO - Training completed. Best validation loss: 17.005889
2025-10-24 23:51:18,116 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:51:18,212 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:51:18,212 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:51:18,212 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:51:18,310 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:51:18,310 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:51:18,310 - __main__ - INFO - Evaluating model...
2025-10-24 23:53:20,655 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:53:20,679 - __main__ - INFO - Using GPU: NVIDIA GeForce RTX 3070
2025-10-24 23:53:20,679 - __main__ - INFO - GPU Memory: 8.6 GB
2025-10-24 23:53:20,679 - __main__ - INFO - Collecting data for oil price prediction...
2025-10-24 23:53:20,685 - data.oil_data_pipeline - INFO - BigQuery client initialized successfully
2025-10-24 23:53:20,685 - data.oil_data_pipeline - INFO - Collecting data from 2020-10-25 to 2025-10-24
2025-10-24 23:53:20,685 - data.oil_data_pipeline - INFO - Collecting oil price data...
2025-10-24 23:53:21,355 - data.oil_data_pipeline - INFO - Collected 1257 records for CL=F
2025-10-24 23:53:21,455 - data.oil_data_pipeline - INFO - Collected 1258 records for BZ=F
2025-10-24 23:53:21,541 - data.oil_data_pipeline - INFO - Collected 1258 records for NG=F
2025-10-24 23:53:21,542 - data.oil_data_pipeline - INFO - Collecting financial market data...
2025-10-24 23:53:21,622 - data.oil_data_pipeline - INFO - Collected 1255 records for ^GSPC
2025-10-24 23:53:21,707 - data.oil_data_pipeline - INFO - Collected 1255 records for ^DJI
2025-10-24 23:53:21,798 - data.oil_data_pipeline - INFO - Collected 1255 records for ^IXIC
2025-10-24 23:53:21,890 - data.oil_data_pipeline - INFO - Collected 1301 records for EURUSD=X
2025-10-24 23:53:21,983 - data.oil_data_pipeline - INFO - Collected 1301 records for GBPUSD=X
2025-10-24 23:53:22,068 - data.oil_data_pipeline - INFO - Collected 1301 records for USDJPY=X
2025-10-24 23:53:22,184 - data.oil_data_pipeline - INFO - Collected 1255 records for XLE
2025-10-24 23:53:22,305 - data.oil_data_pipeline - INFO - Collected 1255 records for VDE
2025-10-24 23:53:22,429 - data.oil_data_pipeline - INFO - Collected 1255 records for IYE
2025-10-24 23:53:22,440 - data.oil_data_pipeline - INFO - Collecting GDELT news data from BigQuery...
2025-10-24 23:53:23,472 - data.oil_data_pipeline - ERROR - GDELT BigQuery error: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/outstanding-map-449312-a0/jobs?prettyPrint=false: Access Denied: Project outstanding-map-449312-a0: User does not have bigquery.jobs.create permission in project outstanding-map-449312-a0.

Location: None
Job ID: 3afc98ef-5c56-4aac-8279-0861ab326de4

2025-10-24 23:53:23,472 - data.oil_data_pipeline - INFO - Falling back to local news data
2025-10-24 23:53:23,472 - data.oil_data_pipeline - WARNING - Creating comprehensive fallback news data
2025-10-24 23:53:23,478 - data.oil_data_pipeline - WARNING - Failed to load fallback news data: time data "Fri, 24 Oct 2025 06:00:00 -0400" doesn't match format "%a, %d %b %Y %H:%M:%S GMT", at position 5. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
2025-10-24 23:53:23,479 - data.oil_data_pipeline - INFO - Created 150 comprehensive news events
2025-10-24 23:53:23,479 - data.oil_data_pipeline - INFO - Creating news-to-price time mapping...
2025-10-24 23:53:28,320 - data.oil_data_pipeline - INFO - Created 787 news-to-price mappings
2025-10-24 23:53:28,320 - data.oil_data_pipeline - INFO - Data collection complete: 16143 total records
2025-10-24 23:53:28,320 - __main__ - INFO - Data collection complete: 16143 total records
2025-10-24 23:53:28,320 - __main__ - INFO - Starting GPU training...
2025-10-24 23:53:28,320 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:53:28,429 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:53:28,429 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:53:28,429 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:53:28,535 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:53:28,535 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:53:28,540 - models.oil_price_model - INFO - Oil Price Model initialized with 614,556 parameters
2025-10-24 23:53:28,633 - __main__ - INFO - Model initialized with 614,556 parameters
2025-10-24 23:53:30,219 - __main__ - INFO - Epoch 0, Batch 0/50, Loss: 3205.008789
2025-10-24 23:53:30,362 - __main__ - INFO - Epoch 0, Batch 10/50, Loss: 3345.559570
2025-10-24 23:53:30,493 - __main__ - INFO - Epoch 0, Batch 20/50, Loss: 3173.325195
2025-10-24 23:53:30,615 - __main__ - INFO - Epoch 0, Batch 30/50, Loss: 3674.000000
2025-10-24 23:53:30,748 - __main__ - INFO - Epoch 0, Batch 40/50, Loss: 3665.041748
2025-10-24 23:53:31,068 - __main__ - INFO - Epoch 0: Train Loss: 3357.071514, Val Loss: 3330.276147, LR: 9.76e-05
2025-10-24 23:53:31,077 - __main__ - INFO - Saved best model (Val Loss: 3330.276147)
2025-10-24 23:53:31,091 - __main__ - INFO - Epoch 1, Batch 0/50, Loss: 3142.162109
2025-10-24 23:53:31,229 - __main__ - INFO - Epoch 1, Batch 10/50, Loss: 3322.730469
2025-10-24 23:53:31,354 - __main__ - INFO - Epoch 1, Batch 20/50, Loss: 4027.980225
2025-10-24 23:53:31,471 - __main__ - INFO - Epoch 1, Batch 30/50, Loss: 3477.979492
2025-10-24 23:53:31,604 - __main__ - INFO - Epoch 1, Batch 40/50, Loss: 3333.939941
2025-10-24 23:53:31,924 - __main__ - INFO - Epoch 1: Train Loss: 3207.450239, Val Loss: 2666.974028, LR: 9.05e-05
2025-10-24 23:53:31,932 - __main__ - INFO - Saved best model (Val Loss: 2666.974028)
2025-10-24 23:53:31,946 - __main__ - INFO - Epoch 2, Batch 0/50, Loss: 2915.893311
2025-10-24 23:53:32,071 - __main__ - INFO - Epoch 2, Batch 10/50, Loss: 2305.160889
2025-10-24 23:53:32,189 - __main__ - INFO - Epoch 2, Batch 20/50, Loss: 1018.094116
2025-10-24 23:53:32,320 - __main__ - INFO - Epoch 2, Batch 30/50, Loss: 600.006165
2025-10-24 23:53:32,439 - __main__ - INFO - Epoch 2, Batch 40/50, Loss: 686.833374
2025-10-24 23:53:32,793 - __main__ - INFO - Epoch 2: Train Loss: 1193.616095, Val Loss: 254.526980, LR: 7.94e-05
2025-10-24 23:53:32,801 - __main__ - INFO - Saved best model (Val Loss: 254.526980)
2025-10-24 23:53:32,814 - __main__ - INFO - Epoch 3, Batch 0/50, Loss: 442.347656
2025-10-24 23:53:32,940 - __main__ - INFO - Epoch 3, Batch 10/50, Loss: 344.033295
2025-10-24 23:53:33,075 - __main__ - INFO - Epoch 3, Batch 20/50, Loss: 279.884583
2025-10-24 23:53:33,205 - __main__ - INFO - Epoch 3, Batch 30/50, Loss: 223.343155
2025-10-24 23:53:33,325 - __main__ - INFO - Epoch 3, Batch 40/50, Loss: 235.834961
2025-10-24 23:53:33,634 - __main__ - INFO - Epoch 3: Train Loss: 250.796960, Val Loss: 109.171314, LR: 6.55e-05
2025-10-24 23:53:33,641 - __main__ - INFO - Saved best model (Val Loss: 109.171314)
2025-10-24 23:53:33,658 - __main__ - INFO - Epoch 4, Batch 0/50, Loss: 160.708878
2025-10-24 23:53:33,787 - __main__ - INFO - Epoch 4, Batch 10/50, Loss: 174.385742
2025-10-24 23:53:33,918 - __main__ - INFO - Epoch 4, Batch 20/50, Loss: 89.299255
2025-10-24 23:53:34,046 - __main__ - INFO - Epoch 4, Batch 30/50, Loss: 140.627487
2025-10-24 23:53:34,173 - __main__ - INFO - Epoch 4, Batch 40/50, Loss: 263.517395
2025-10-24 23:53:34,481 - __main__ - INFO - Epoch 4: Train Loss: 190.562734, Val Loss: 87.543952, LR: 5.00e-05
2025-10-24 23:53:34,489 - __main__ - INFO - Saved best model (Val Loss: 87.543952)
2025-10-24 23:53:34,502 - __main__ - INFO - Epoch 5, Batch 0/50, Loss: 94.975716
2025-10-24 23:53:34,642 - __main__ - INFO - Epoch 5, Batch 10/50, Loss: 234.762009
2025-10-24 23:53:34,766 - __main__ - INFO - Epoch 5, Batch 20/50, Loss: 207.344864
2025-10-24 23:53:34,897 - __main__ - INFO - Epoch 5, Batch 30/50, Loss: 118.962875
2025-10-24 23:53:35,025 - __main__ - INFO - Epoch 5, Batch 40/50, Loss: 310.241669
2025-10-24 23:53:35,333 - __main__ - INFO - Epoch 5: Train Loss: 173.100870, Val Loss: 69.832325, LR: 3.45e-05
2025-10-24 23:53:35,341 - __main__ - INFO - Saved best model (Val Loss: 69.832325)
2025-10-24 23:53:35,356 - __main__ - INFO - Epoch 6, Batch 0/50, Loss: 233.344971
2025-10-24 23:53:35,487 - __main__ - INFO - Epoch 6, Batch 10/50, Loss: 201.060745
2025-10-24 23:53:35,615 - __main__ - INFO - Epoch 6, Batch 20/50, Loss: 118.659081
2025-10-24 23:53:35,774 - __main__ - INFO - Epoch 6, Batch 30/50, Loss: 129.161514
2025-10-24 23:53:35,949 - __main__ - INFO - Epoch 6, Batch 40/50, Loss: 88.437759
2025-10-24 23:53:36,259 - __main__ - INFO - Epoch 6: Train Loss: 161.351526, Val Loss: 63.213013, LR: 2.06e-05
2025-10-24 23:53:36,266 - __main__ - INFO - Saved best model (Val Loss: 63.213013)
2025-10-24 23:53:36,277 - __main__ - INFO - Epoch 7, Batch 0/50, Loss: 149.466217
2025-10-24 23:53:36,410 - __main__ - INFO - Epoch 7, Batch 10/50, Loss: 170.414261
2025-10-24 23:53:36,535 - __main__ - INFO - Epoch 7, Batch 20/50, Loss: 112.738770
2025-10-24 23:53:36,668 - __main__ - INFO - Epoch 7, Batch 30/50, Loss: 103.378426
2025-10-24 23:53:36,804 - __main__ - INFO - Epoch 7, Batch 40/50, Loss: 90.170822
2025-10-24 23:53:37,142 - __main__ - INFO - Epoch 7: Train Loss: 141.084568, Val Loss: 62.390067, LR: 9.55e-06
2025-10-24 23:53:37,149 - __main__ - INFO - Saved best model (Val Loss: 62.390067)
2025-10-24 23:53:37,162 - __main__ - INFO - Epoch 8, Batch 0/50, Loss: 139.691376
2025-10-24 23:53:37,289 - __main__ - INFO - Epoch 8, Batch 10/50, Loss: 135.051010
2025-10-24 23:53:37,420 - __main__ - INFO - Epoch 8, Batch 20/50, Loss: 92.969093
2025-10-24 23:53:37,555 - __main__ - INFO - Epoch 8, Batch 30/50, Loss: 101.798042
2025-10-24 23:53:37,688 - __main__ - INFO - Epoch 8, Batch 40/50, Loss: 217.296570
2025-10-24 23:53:38,009 - __main__ - INFO - Epoch 8: Train Loss: 147.307366, Val Loss: 61.317004, LR: 2.45e-06
2025-10-24 23:53:38,016 - __main__ - INFO - Saved best model (Val Loss: 61.317004)
2025-10-24 23:53:38,029 - __main__ - INFO - Epoch 9, Batch 0/50, Loss: 180.116257
2025-10-24 23:53:38,170 - __main__ - INFO - Epoch 9, Batch 10/50, Loss: 102.804466
2025-10-24 23:53:38,308 - __main__ - INFO - Epoch 9, Batch 20/50, Loss: 95.873291
2025-10-24 23:53:38,437 - __main__ - INFO - Epoch 9, Batch 30/50, Loss: 113.971107
2025-10-24 23:53:38,559 - __main__ - INFO - Epoch 9, Batch 40/50, Loss: 104.059616
2025-10-24 23:53:38,914 - __main__ - INFO - Epoch 9: Train Loss: 141.887820, Val Loss: 60.895353, LR: 1.00e-04
2025-10-24 23:53:38,922 - __main__ - INFO - Saved best model (Val Loss: 60.895353)
2025-10-24 23:53:38,936 - __main__ - INFO - Epoch 10, Batch 0/50, Loss: 197.521439
2025-10-24 23:53:39,071 - __main__ - INFO - Epoch 10, Batch 10/50, Loss: 244.661667
2025-10-24 23:53:39,207 - __main__ - INFO - Epoch 10, Batch 20/50, Loss: 77.136864
2025-10-24 23:53:39,344 - __main__ - INFO - Epoch 10, Batch 30/50, Loss: 223.451584
2025-10-24 23:53:39,480 - __main__ - INFO - Epoch 10, Batch 40/50, Loss: 154.722855
2025-10-24 23:53:39,839 - __main__ - INFO - Epoch 10: Train Loss: 138.786641, Val Loss: 48.361832, LR: 9.94e-05
2025-10-24 23:53:39,846 - __main__ - INFO - Saved best model (Val Loss: 48.361832)
2025-10-24 23:53:39,859 - __main__ - INFO - Epoch 11, Batch 0/50, Loss: 121.904640
2025-10-24 23:53:39,993 - __main__ - INFO - Epoch 11, Batch 10/50, Loss: 135.013840
2025-10-24 23:53:40,128 - __main__ - INFO - Epoch 11, Batch 20/50, Loss: 165.369720
2025-10-24 23:53:40,273 - __main__ - INFO - Epoch 11, Batch 30/50, Loss: 133.459549
2025-10-24 23:53:40,404 - __main__ - INFO - Epoch 11, Batch 40/50, Loss: 108.146645
2025-10-24 23:53:40,759 - __main__ - INFO - Epoch 11: Train Loss: 119.959275, Val Loss: 41.934493, LR: 9.76e-05
2025-10-24 23:53:40,767 - __main__ - INFO - Saved best model (Val Loss: 41.934493)
2025-10-24 23:53:40,784 - __main__ - INFO - Epoch 12, Batch 0/50, Loss: 71.029160
2025-10-24 23:53:40,922 - __main__ - INFO - Epoch 12, Batch 10/50, Loss: 75.502739
2025-10-24 23:53:41,052 - __main__ - INFO - Epoch 12, Batch 20/50, Loss: 105.392349
2025-10-24 23:53:41,191 - __main__ - INFO - Epoch 12, Batch 30/50, Loss: 81.685623
2025-10-24 23:53:41,332 - __main__ - INFO - Epoch 12, Batch 40/50, Loss: 120.318573
2025-10-24 23:53:41,642 - __main__ - INFO - Epoch 12: Train Loss: 115.383954, Val Loss: 37.221061, LR: 9.46e-05
2025-10-24 23:53:41,649 - __main__ - INFO - Saved best model (Val Loss: 37.221061)
2025-10-24 23:53:41,661 - __main__ - INFO - Epoch 13, Batch 0/50, Loss: 113.843285
2025-10-24 23:53:41,790 - __main__ - INFO - Epoch 13, Batch 10/50, Loss: 149.169479
2025-10-24 23:53:41,916 - __main__ - INFO - Epoch 13, Batch 20/50, Loss: 75.551109
2025-10-24 23:53:42,036 - __main__ - INFO - Epoch 13, Batch 30/50, Loss: 84.527634
2025-10-24 23:53:42,182 - __main__ - INFO - Epoch 13, Batch 40/50, Loss: 125.762947
2025-10-24 23:53:42,520 - __main__ - INFO - Epoch 13: Train Loss: 108.200270, Val Loss: 31.236311, LR: 9.05e-05
2025-10-24 23:53:42,527 - __main__ - INFO - Saved best model (Val Loss: 31.236311)
2025-10-24 23:53:42,544 - __main__ - INFO - Epoch 14, Batch 0/50, Loss: 105.458450
2025-10-24 23:53:42,665 - __main__ - INFO - Epoch 14, Batch 10/50, Loss: 100.104462
2025-10-24 23:53:42,780 - __main__ - INFO - Epoch 14, Batch 20/50, Loss: 106.652695
2025-10-24 23:53:42,896 - __main__ - INFO - Epoch 14, Batch 30/50, Loss: 123.659340
2025-10-24 23:53:43,025 - __main__ - INFO - Epoch 14, Batch 40/50, Loss: 49.517845
2025-10-24 23:53:43,319 - __main__ - INFO - Epoch 14: Train Loss: 96.927314, Val Loss: 26.395987, LR: 8.54e-05
2025-10-24 23:53:43,327 - __main__ - INFO - Saved best model (Val Loss: 26.395987)
2025-10-24 23:53:43,339 - __main__ - INFO - Epoch 15, Batch 0/50, Loss: 81.905800
2025-10-24 23:53:43,462 - __main__ - INFO - Epoch 15, Batch 10/50, Loss: 72.974350
2025-10-24 23:53:43,586 - __main__ - INFO - Epoch 15, Batch 20/50, Loss: 99.126068
2025-10-24 23:53:43,705 - __main__ - INFO - Epoch 15, Batch 30/50, Loss: 124.091522
2025-10-24 23:53:43,825 - __main__ - INFO - Epoch 15, Batch 40/50, Loss: 57.996250
2025-10-24 23:53:44,154 - __main__ - INFO - Epoch 15: Train Loss: 94.273462, Val Loss: 26.399384, LR: 7.94e-05
2025-10-24 23:53:44,170 - __main__ - INFO - Epoch 16, Batch 0/50, Loss: 48.881569
2025-10-24 23:53:44,314 - __main__ - INFO - Epoch 16, Batch 10/50, Loss: 87.115128
2025-10-24 23:53:44,446 - __main__ - INFO - Epoch 16, Batch 20/50, Loss: 79.218224
2025-10-24 23:53:44,568 - __main__ - INFO - Epoch 16, Batch 30/50, Loss: 49.438065
2025-10-24 23:53:44,692 - __main__ - INFO - Epoch 16, Batch 40/50, Loss: 112.092796
2025-10-24 23:53:45,064 - __main__ - INFO - Epoch 16: Train Loss: 85.516505, Val Loss: 21.992316, LR: 7.27e-05
2025-10-24 23:53:45,075 - __main__ - INFO - Saved best model (Val Loss: 21.992316)
2025-10-24 23:53:45,099 - __main__ - INFO - Epoch 17, Batch 0/50, Loss: 73.281303
2025-10-24 23:53:45,229 - __main__ - INFO - Epoch 17, Batch 10/50, Loss: 89.636658
2025-10-24 23:53:45,367 - __main__ - INFO - Epoch 17, Batch 20/50, Loss: 72.045822
2025-10-24 23:53:45,497 - __main__ - INFO - Epoch 17, Batch 30/50, Loss: 59.896568
2025-10-24 23:53:45,621 - __main__ - INFO - Epoch 17, Batch 40/50, Loss: 98.023666
2025-10-24 23:53:45,924 - __main__ - INFO - Epoch 17: Train Loss: 81.236036, Val Loss: 25.896672, LR: 6.55e-05
2025-10-24 23:53:45,938 - __main__ - INFO - Epoch 18, Batch 0/50, Loss: 55.404205
2025-10-24 23:53:46,067 - __main__ - INFO - Epoch 18, Batch 10/50, Loss: 72.561348
2025-10-24 23:53:46,190 - __main__ - INFO - Epoch 18, Batch 20/50, Loss: 45.382458
2025-10-24 23:53:46,316 - __main__ - INFO - Epoch 18, Batch 30/50, Loss: 56.063339
2025-10-24 23:53:46,445 - __main__ - INFO - Epoch 18, Batch 40/50, Loss: 33.791481
2025-10-24 23:53:46,751 - __main__ - INFO - Epoch 18: Train Loss: 80.903623, Val Loss: 20.804805, LR: 5.78e-05
2025-10-24 23:53:46,758 - __main__ - INFO - Saved best model (Val Loss: 20.804805)
2025-10-24 23:53:46,772 - __main__ - INFO - Epoch 19, Batch 0/50, Loss: 56.518322
2025-10-24 23:53:46,890 - __main__ - INFO - Epoch 19, Batch 10/50, Loss: 55.442932
2025-10-24 23:53:47,011 - __main__ - INFO - Epoch 19, Batch 20/50, Loss: 49.776329
2025-10-24 23:53:47,148 - __main__ - INFO - Epoch 19, Batch 30/50, Loss: 56.910954
2025-10-24 23:53:47,281 - __main__ - INFO - Epoch 19, Batch 40/50, Loss: 65.674828
2025-10-24 23:53:47,593 - __main__ - INFO - Epoch 19: Train Loss: 77.273932, Val Loss: 19.122030, LR: 5.00e-05
2025-10-24 23:53:47,600 - __main__ - INFO - Saved best model (Val Loss: 19.122030)
2025-10-24 23:53:47,612 - __main__ - INFO - Epoch 20, Batch 0/50, Loss: 41.777714
2025-10-24 23:53:47,735 - __main__ - INFO - Epoch 20, Batch 10/50, Loss: 50.232231
2025-10-24 23:53:47,859 - __main__ - INFO - Epoch 20, Batch 20/50, Loss: 63.089603
2025-10-24 23:53:47,981 - __main__ - INFO - Epoch 20, Batch 30/50, Loss: 71.143715
2025-10-24 23:53:48,106 - __main__ - INFO - Epoch 20, Batch 40/50, Loss: 45.263752
2025-10-24 23:53:48,406 - __main__ - INFO - Epoch 20: Train Loss: 85.445170, Val Loss: 18.865186, LR: 4.22e-05
2025-10-24 23:53:48,414 - __main__ - INFO - Saved best model (Val Loss: 18.865186)
2025-10-24 23:53:48,427 - __main__ - INFO - Epoch 21, Batch 0/50, Loss: 67.378090
2025-10-24 23:53:48,548 - __main__ - INFO - Epoch 21, Batch 10/50, Loss: 70.479103
2025-10-24 23:53:48,674 - __main__ - INFO - Epoch 21, Batch 20/50, Loss: 71.807632
2025-10-24 23:53:48,798 - __main__ - INFO - Epoch 21, Batch 30/50, Loss: 50.881939
2025-10-24 23:53:48,914 - __main__ - INFO - Epoch 21, Batch 40/50, Loss: 116.220909
2025-10-24 23:53:49,209 - __main__ - INFO - Epoch 21: Train Loss: 76.985249, Val Loss: 20.850891, LR: 3.45e-05
2025-10-24 23:53:49,221 - __main__ - INFO - Epoch 22, Batch 0/50, Loss: 53.971069
2025-10-24 23:53:49,351 - __main__ - INFO - Epoch 22, Batch 10/50, Loss: 59.616665
2025-10-24 23:53:49,485 - __main__ - INFO - Epoch 22, Batch 20/50, Loss: 80.901085
2025-10-24 23:53:49,610 - __main__ - INFO - Epoch 22, Batch 30/50, Loss: 89.703941
2025-10-24 23:53:49,745 - __main__ - INFO - Epoch 22, Batch 40/50, Loss: 56.430256
2025-10-24 23:53:50,087 - __main__ - INFO - Epoch 22: Train Loss: 75.342747, Val Loss: 20.970674, LR: 2.73e-05
2025-10-24 23:53:50,101 - __main__ - INFO - Epoch 23, Batch 0/50, Loss: 48.233074
2025-10-24 23:53:50,253 - __main__ - INFO - Epoch 23, Batch 10/50, Loss: 70.443443
2025-10-24 23:53:50,424 - __main__ - INFO - Epoch 23, Batch 20/50, Loss: 71.091972
2025-10-24 23:53:50,548 - __main__ - INFO - Epoch 23, Batch 30/50, Loss: 68.042252
2025-10-24 23:53:50,677 - __main__ - INFO - Epoch 23, Batch 40/50, Loss: 50.057426
2025-10-24 23:53:51,018 - __main__ - INFO - Epoch 23: Train Loss: 72.817756, Val Loss: 20.158169, LR: 2.06e-05
2025-10-24 23:53:51,030 - __main__ - INFO - Epoch 24, Batch 0/50, Loss: 48.294353
2025-10-24 23:53:51,156 - __main__ - INFO - Epoch 24, Batch 10/50, Loss: 56.059227
2025-10-24 23:53:51,279 - __main__ - INFO - Epoch 24, Batch 20/50, Loss: 72.756058
2025-10-24 23:53:51,397 - __main__ - INFO - Epoch 24, Batch 30/50, Loss: 68.303452
2025-10-24 23:53:51,527 - __main__ - INFO - Epoch 24, Batch 40/50, Loss: 75.481758
2025-10-24 23:53:51,861 - __main__ - INFO - Epoch 24: Train Loss: 73.737959, Val Loss: 18.328816, LR: 1.46e-05
2025-10-24 23:53:51,870 - __main__ - INFO - Saved best model (Val Loss: 18.328816)
2025-10-24 23:53:51,884 - __main__ - INFO - Epoch 25, Batch 0/50, Loss: 441.013519
2025-10-24 23:53:52,011 - __main__ - INFO - Epoch 25, Batch 10/50, Loss: 67.225540
2025-10-24 23:53:52,132 - __main__ - INFO - Epoch 25, Batch 20/50, Loss: 43.432335
2025-10-24 23:53:52,263 - __main__ - INFO - Epoch 25, Batch 30/50, Loss: 74.951218
2025-10-24 23:53:52,394 - __main__ - INFO - Epoch 25, Batch 40/50, Loss: 56.389538
2025-10-24 23:53:52,710 - __main__ - INFO - Epoch 25: Train Loss: 71.635812, Val Loss: 18.368209, LR: 9.55e-06
2025-10-24 23:53:52,722 - __main__ - INFO - Epoch 26, Batch 0/50, Loss: 56.615139
2025-10-24 23:53:52,849 - __main__ - INFO - Epoch 26, Batch 10/50, Loss: 56.199333
2025-10-24 23:53:52,987 - __main__ - INFO - Epoch 26, Batch 20/50, Loss: 71.672653
2025-10-24 23:53:53,121 - __main__ - INFO - Epoch 26, Batch 30/50, Loss: 478.218140
2025-10-24 23:53:53,259 - __main__ - INFO - Epoch 26, Batch 40/50, Loss: 51.375591
2025-10-24 23:53:53,584 - __main__ - INFO - Epoch 26: Train Loss: 70.750316, Val Loss: 19.676704, LR: 5.45e-06
2025-10-24 23:53:53,596 - __main__ - INFO - Epoch 27, Batch 0/50, Loss: 79.494682
2025-10-24 23:53:53,736 - __main__ - INFO - Epoch 27, Batch 10/50, Loss: 80.112381
2025-10-24 23:53:53,867 - __main__ - INFO - Epoch 27, Batch 20/50, Loss: 62.958492
2025-10-24 23:53:53,996 - __main__ - INFO - Epoch 27, Batch 30/50, Loss: 55.854900
2025-10-24 23:53:54,128 - __main__ - INFO - Epoch 27, Batch 40/50, Loss: 52.578880
2025-10-24 23:53:54,464 - __main__ - INFO - Epoch 27: Train Loss: 72.091578, Val Loss: 20.014354, LR: 2.45e-06
2025-10-24 23:53:54,475 - __main__ - INFO - Epoch 28, Batch 0/50, Loss: 70.946358
2025-10-24 23:53:54,600 - __main__ - INFO - Epoch 28, Batch 10/50, Loss: 66.554985
2025-10-24 23:53:54,733 - __main__ - INFO - Epoch 28, Batch 20/50, Loss: 93.123695
2025-10-24 23:53:54,866 - __main__ - INFO - Epoch 28, Batch 30/50, Loss: 53.036400
2025-10-24 23:53:55,006 - __main__ - INFO - Epoch 28, Batch 40/50, Loss: 53.516350
2025-10-24 23:53:55,333 - __main__ - INFO - Epoch 28: Train Loss: 76.879827, Val Loss: 19.421731, LR: 6.16e-07
2025-10-24 23:53:55,348 - __main__ - INFO - Epoch 29, Batch 0/50, Loss: 91.151703
2025-10-24 23:53:55,477 - __main__ - INFO - Epoch 29, Batch 10/50, Loss: 40.342560
2025-10-24 23:53:55,604 - __main__ - INFO - Epoch 29, Batch 20/50, Loss: 72.091042
2025-10-24 23:53:55,734 - __main__ - INFO - Epoch 29, Batch 30/50, Loss: 91.489540
2025-10-24 23:53:55,858 - __main__ - INFO - Epoch 29, Batch 40/50, Loss: 57.648228
2025-10-24 23:53:56,206 - __main__ - INFO - Epoch 29: Train Loss: 76.222284, Val Loss: 19.384104, LR: 1.00e-04
2025-10-24 23:53:56,222 - __main__ - INFO - Epoch 30, Batch 0/50, Loss: 51.529163
2025-10-24 23:53:56,348 - __main__ - INFO - Epoch 30, Batch 10/50, Loss: 105.482399
2025-10-24 23:53:56,467 - __main__ - INFO - Epoch 30, Batch 20/50, Loss: 82.429817
2025-10-24 23:53:56,585 - __main__ - INFO - Epoch 30, Batch 30/50, Loss: 56.953911
2025-10-24 23:53:56,703 - __main__ - INFO - Epoch 30, Batch 40/50, Loss: 44.884392
2025-10-24 23:53:57,007 - __main__ - INFO - Epoch 30: Train Loss: 68.858364, Val Loss: 19.757826, LR: 9.98e-05
2025-10-24 23:53:57,020 - __main__ - INFO - Epoch 31, Batch 0/50, Loss: 88.933907
2025-10-24 23:53:57,142 - __main__ - INFO - Epoch 31, Batch 10/50, Loss: 489.480560
2025-10-24 23:53:57,256 - __main__ - INFO - Epoch 31, Batch 20/50, Loss: 38.727318
2025-10-24 23:53:57,376 - __main__ - INFO - Epoch 31, Batch 30/50, Loss: 57.311516
2025-10-24 23:53:57,495 - __main__ - INFO - Epoch 31, Batch 40/50, Loss: 51.942818
2025-10-24 23:53:57,798 - __main__ - INFO - Epoch 31: Train Loss: 75.118637, Val Loss: 19.067370, LR: 9.94e-05
2025-10-24 23:53:57,812 - __main__ - INFO - Epoch 32, Batch 0/50, Loss: 78.726959
2025-10-24 23:53:57,937 - __main__ - INFO - Epoch 32, Batch 10/50, Loss: 52.632240
2025-10-24 23:53:58,053 - __main__ - INFO - Epoch 32, Batch 20/50, Loss: 32.884762
2025-10-24 23:53:58,189 - __main__ - INFO - Epoch 32, Batch 30/50, Loss: 69.202301
2025-10-24 23:53:58,315 - __main__ - INFO - Epoch 32, Batch 40/50, Loss: 97.180847
2025-10-24 23:53:58,609 - __main__ - INFO - Epoch 32: Train Loss: 71.402334, Val Loss: 17.708019, LR: 9.86e-05
2025-10-24 23:53:58,617 - __main__ - INFO - Saved best model (Val Loss: 17.708019)
2025-10-24 23:53:58,629 - __main__ - INFO - Epoch 33, Batch 0/50, Loss: 35.648262
2025-10-24 23:53:58,754 - __main__ - INFO - Epoch 33, Batch 10/50, Loss: 42.952209
2025-10-24 23:53:58,877 - __main__ - INFO - Epoch 33, Batch 20/50, Loss: 48.158455
2025-10-24 23:53:58,998 - __main__ - INFO - Epoch 33, Batch 30/50, Loss: 36.618576
2025-10-24 23:53:59,117 - __main__ - INFO - Epoch 33, Batch 40/50, Loss: 56.991310
2025-10-24 23:53:59,432 - __main__ - INFO - Epoch 33: Train Loss: 69.078328, Val Loss: 20.722386, LR: 9.76e-05
2025-10-24 23:53:59,444 - __main__ - INFO - Epoch 34, Batch 0/50, Loss: 74.356514
2025-10-24 23:53:59,562 - __main__ - INFO - Epoch 34, Batch 10/50, Loss: 508.570496
2025-10-24 23:53:59,684 - __main__ - INFO - Epoch 34, Batch 20/50, Loss: 53.054676
2025-10-24 23:53:59,822 - __main__ - INFO - Epoch 34, Batch 30/50, Loss: 83.155327
2025-10-24 23:53:59,995 - __main__ - INFO - Epoch 34, Batch 40/50, Loss: 73.783516
2025-10-24 23:54:00,312 - __main__ - INFO - Epoch 34: Train Loss: 73.897183, Val Loss: 22.207253, LR: 9.62e-05
2025-10-24 23:54:00,325 - __main__ - INFO - Epoch 35, Batch 0/50, Loss: 36.027420
2025-10-24 23:54:00,441 - __main__ - INFO - Epoch 35, Batch 10/50, Loss: 73.379478
2025-10-24 23:54:00,560 - __main__ - INFO - Epoch 35, Batch 20/50, Loss: 55.286140
2025-10-24 23:54:00,681 - __main__ - INFO - Epoch 35, Batch 30/50, Loss: 60.540573
2025-10-24 23:54:00,800 - __main__ - INFO - Epoch 35, Batch 40/50, Loss: 72.731056
2025-10-24 23:54:01,138 - __main__ - INFO - Epoch 35: Train Loss: 75.229296, Val Loss: 24.856455, LR: 9.46e-05
2025-10-24 23:54:01,149 - __main__ - INFO - Epoch 36, Batch 0/50, Loss: 46.999924
2025-10-24 23:54:01,270 - __main__ - INFO - Epoch 36, Batch 10/50, Loss: 57.971794
2025-10-24 23:54:01,394 - __main__ - INFO - Epoch 36, Batch 20/50, Loss: 57.714043
2025-10-24 23:54:01,515 - __main__ - INFO - Epoch 36, Batch 30/50, Loss: 98.216042
2025-10-24 23:54:01,636 - __main__ - INFO - Epoch 36, Batch 40/50, Loss: 60.372036
2025-10-24 23:54:01,940 - __main__ - INFO - Epoch 36: Train Loss: 68.688952, Val Loss: 23.738808, LR: 9.26e-05
2025-10-24 23:54:01,952 - __main__ - INFO - Epoch 37, Batch 0/50, Loss: 29.990902
2025-10-24 23:54:02,077 - __main__ - INFO - Epoch 37, Batch 10/50, Loss: 45.591560
2025-10-24 23:54:02,193 - __main__ - INFO - Epoch 37, Batch 20/50, Loss: 48.853584
2025-10-24 23:54:02,321 - __main__ - INFO - Epoch 37, Batch 30/50, Loss: 55.062412
2025-10-24 23:54:02,452 - __main__ - INFO - Epoch 37, Batch 40/50, Loss: 49.999413
2025-10-24 23:54:02,761 - __main__ - INFO - Epoch 37: Train Loss: 67.955036, Val Loss: 26.069675, LR: 9.05e-05
2025-10-24 23:54:02,777 - __main__ - INFO - Epoch 38, Batch 0/50, Loss: 46.080685
2025-10-24 23:54:02,903 - __main__ - INFO - Epoch 38, Batch 10/50, Loss: 39.675930
2025-10-24 23:54:03,036 - __main__ - INFO - Epoch 38, Batch 20/50, Loss: 58.957447
2025-10-24 23:54:03,167 - __main__ - INFO - Epoch 38, Batch 30/50, Loss: 61.266788
2025-10-24 23:54:03,297 - __main__ - INFO - Epoch 38, Batch 40/50, Loss: 36.104843
2025-10-24 23:54:03,598 - __main__ - INFO - Epoch 38: Train Loss: 63.628739, Val Loss: 17.721880, LR: 8.80e-05
2025-10-24 23:54:03,611 - __main__ - INFO - Epoch 39, Batch 0/50, Loss: 50.019119
2025-10-24 23:54:03,742 - __main__ - INFO - Epoch 39, Batch 10/50, Loss: 72.580452
2025-10-24 23:54:03,884 - __main__ - INFO - Epoch 39, Batch 20/50, Loss: 47.961132
2025-10-24 23:54:04,034 - __main__ - INFO - Epoch 39, Batch 30/50, Loss: 50.084309
2025-10-24 23:54:04,201 - __main__ - INFO - Epoch 39, Batch 40/50, Loss: 69.313911
2025-10-24 23:54:04,539 - __main__ - INFO - Epoch 39: Train Loss: 63.490947, Val Loss: 17.633056, LR: 8.54e-05
2025-10-24 23:54:04,547 - __main__ - INFO - Saved best model (Val Loss: 17.633056)
2025-10-24 23:54:04,561 - __main__ - INFO - Epoch 40, Batch 0/50, Loss: 53.277245
2025-10-24 23:54:04,692 - __main__ - INFO - Epoch 40, Batch 10/50, Loss: 538.150940
2025-10-24 23:54:04,825 - __main__ - INFO - Epoch 40, Batch 20/50, Loss: 47.668293
2025-10-24 23:54:04,959 - __main__ - INFO - Epoch 40, Batch 30/50, Loss: 132.366440
2025-10-24 23:54:05,103 - __main__ - INFO - Epoch 40, Batch 40/50, Loss: 58.881527
2025-10-24 23:54:05,423 - __main__ - INFO - Epoch 40: Train Loss: 66.979815, Val Loss: 18.780890, LR: 8.25e-05
2025-10-24 23:54:05,434 - __main__ - INFO - Epoch 41, Batch 0/50, Loss: 39.078976
2025-10-24 23:54:05,563 - __main__ - INFO - Epoch 41, Batch 10/50, Loss: 39.212070
2025-10-24 23:54:05,690 - __main__ - INFO - Epoch 41, Batch 20/50, Loss: 34.485386
2025-10-24 23:54:05,817 - __main__ - INFO - Epoch 41, Batch 30/50, Loss: 47.981339
2025-10-24 23:54:05,943 - __main__ - INFO - Epoch 41, Batch 40/50, Loss: 70.633331
2025-10-24 23:54:06,287 - __main__ - INFO - Epoch 41: Train Loss: 64.229588, Val Loss: 18.181208, LR: 7.94e-05
2025-10-24 23:54:06,299 - __main__ - INFO - Epoch 42, Batch 0/50, Loss: 51.242851
2025-10-24 23:54:06,435 - __main__ - INFO - Epoch 42, Batch 10/50, Loss: 43.552528
2025-10-24 23:54:06,574 - __main__ - INFO - Epoch 42, Batch 20/50, Loss: 104.854126
2025-10-24 23:54:06,706 - __main__ - INFO - Epoch 42, Batch 30/50, Loss: 52.067493
2025-10-24 23:54:06,842 - __main__ - INFO - Epoch 42, Batch 40/50, Loss: 45.607109
2025-10-24 23:54:07,198 - __main__ - INFO - Epoch 42: Train Loss: 61.349225, Val Loss: 20.269700, LR: 7.61e-05
2025-10-24 23:54:07,211 - __main__ - INFO - Epoch 43, Batch 0/50, Loss: 60.271759
2025-10-24 23:54:07,343 - __main__ - INFO - Epoch 43, Batch 10/50, Loss: 28.883545
2025-10-24 23:54:07,493 - __main__ - INFO - Epoch 43, Batch 20/50, Loss: 52.217861
2025-10-24 23:54:07,619 - __main__ - INFO - Epoch 43, Batch 30/50, Loss: 43.565189
2025-10-24 23:54:07,751 - __main__ - INFO - Epoch 43, Batch 40/50, Loss: 27.557243
2025-10-24 23:54:08,076 - __main__ - INFO - Epoch 43: Train Loss: 61.525560, Val Loss: 17.656875, LR: 7.27e-05
2025-10-24 23:54:08,089 - __main__ - INFO - Epoch 44, Batch 0/50, Loss: 75.889236
2025-10-24 23:54:08,221 - __main__ - INFO - Epoch 44, Batch 10/50, Loss: 59.604393
2025-10-24 23:54:08,351 - __main__ - INFO - Epoch 44, Batch 20/50, Loss: 81.443863
2025-10-24 23:54:08,481 - __main__ - INFO - Epoch 44, Batch 30/50, Loss: 49.532196
2025-10-24 23:54:08,613 - __main__ - INFO - Epoch 44, Batch 40/50, Loss: 36.315857
2025-10-24 23:54:08,917 - __main__ - INFO - Epoch 44: Train Loss: 62.834719, Val Loss: 21.541476, LR: 6.91e-05
2025-10-24 23:54:08,928 - __main__ - INFO - Epoch 45, Batch 0/50, Loss: 48.725758
2025-10-24 23:54:09,055 - __main__ - INFO - Epoch 45, Batch 10/50, Loss: 53.481503
2025-10-24 23:54:09,191 - __main__ - INFO - Epoch 45, Batch 20/50, Loss: 39.456505
2025-10-24 23:54:09,317 - __main__ - INFO - Epoch 45, Batch 30/50, Loss: 44.109222
2025-10-24 23:54:09,449 - __main__ - INFO - Epoch 45, Batch 40/50, Loss: 48.927849
2025-10-24 23:54:09,768 - __main__ - INFO - Epoch 45: Train Loss: 55.761711, Val Loss: 17.055928, LR: 6.55e-05
2025-10-24 23:54:09,776 - __main__ - INFO - Saved best model (Val Loss: 17.055928)
2025-10-24 23:54:09,792 - __main__ - INFO - Epoch 46, Batch 0/50, Loss: 56.153057
2025-10-24 23:54:09,933 - __main__ - INFO - Epoch 46, Batch 10/50, Loss: 62.256050
2025-10-24 23:54:10,074 - __main__ - INFO - Epoch 46, Batch 20/50, Loss: 43.601440
2025-10-24 23:54:10,209 - __main__ - INFO - Epoch 46, Batch 30/50, Loss: 60.148323
2025-10-24 23:54:10,337 - __main__ - INFO - Epoch 46, Batch 40/50, Loss: 26.761652
2025-10-24 23:54:10,635 - __main__ - INFO - Epoch 46: Train Loss: 60.324471, Val Loss: 16.950132, LR: 6.17e-05
2025-10-24 23:54:10,642 - __main__ - INFO - Saved best model (Val Loss: 16.950132)
2025-10-24 23:54:10,657 - __main__ - INFO - Epoch 47, Batch 0/50, Loss: 42.977947
2025-10-24 23:54:10,777 - __main__ - INFO - Epoch 47, Batch 10/50, Loss: 63.879578
2025-10-24 23:54:10,906 - __main__ - INFO - Epoch 47, Batch 20/50, Loss: 57.359924
2025-10-24 23:54:11,036 - __main__ - INFO - Epoch 47, Batch 30/50, Loss: 42.723972
2025-10-24 23:54:11,157 - __main__ - INFO - Epoch 47, Batch 40/50, Loss: 45.973652
2025-10-24 23:54:11,466 - __main__ - INFO - Epoch 47: Train Loss: 60.954677, Val Loss: 19.962326, LR: 5.78e-05
2025-10-24 23:54:11,481 - __main__ - INFO - Epoch 48, Batch 0/50, Loss: 46.051037
2025-10-24 23:54:11,603 - __main__ - INFO - Epoch 48, Batch 10/50, Loss: 43.627625
2025-10-24 23:54:11,732 - __main__ - INFO - Epoch 48, Batch 20/50, Loss: 31.143314
2025-10-24 23:54:11,866 - __main__ - INFO - Epoch 48, Batch 30/50, Loss: 34.988983
2025-10-24 23:54:11,992 - __main__ - INFO - Epoch 48, Batch 40/50, Loss: 111.391930
2025-10-24 23:54:12,308 - __main__ - INFO - Epoch 48: Train Loss: 59.135107, Val Loss: 18.429803, LR: 5.39e-05
2025-10-24 23:54:12,324 - __main__ - INFO - Epoch 49, Batch 0/50, Loss: 57.026535
2025-10-24 23:54:12,492 - __main__ - INFO - Epoch 49, Batch 10/50, Loss: 67.623795
2025-10-24 23:54:12,633 - __main__ - INFO - Epoch 49, Batch 20/50, Loss: 31.122654
2025-10-24 23:54:12,754 - __main__ - INFO - Epoch 49, Batch 30/50, Loss: 68.641960
2025-10-24 23:54:12,897 - __main__ - INFO - Epoch 49, Batch 40/50, Loss: 68.540710
2025-10-24 23:54:13,214 - __main__ - INFO - Epoch 49: Train Loss: 61.666051, Val Loss: 17.222602, LR: 5.00e-05
2025-10-24 23:54:13,214 - __main__ - INFO - Training completed. Best validation loss: 16.950132
2025-10-24 23:54:13,218 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:54:13,315 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:54:13,315 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:54:13,315 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:54:13,410 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:54:13,411 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:54:13,411 - __main__ - INFO - Evaluating model...
2025-10-24 23:54:13,612 - utils.metrics - INFO - Computed 20 metrics
2025-10-24 23:54:13,612 - utils.visualization - INFO - Creating training history plots...
2025-10-24 23:54:14,919 - utils.visualization - INFO - Training history plot saved to plots/training_history.png
2025-10-24 23:54:14,919 - utils.visualization - INFO - Creating prediction plots...
2025-10-24 23:54:29,012 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:54:29,044 - __main__ - INFO - Using GPU: NVIDIA GeForce RTX 3070
2025-10-24 23:54:29,044 - __main__ - INFO - GPU Memory: 8.6 GB
2025-10-24 23:54:29,044 - __main__ - INFO - Collecting data for oil price prediction...
2025-10-24 23:54:29,050 - data.oil_data_pipeline - INFO - BigQuery client initialized successfully
2025-10-24 23:54:29,050 - data.oil_data_pipeline - INFO - Collecting data from 2020-10-25 to 2025-10-24
2025-10-24 23:54:29,050 - data.oil_data_pipeline - INFO - Collecting oil price data...
2025-10-24 23:54:30,860 - data.oil_data_pipeline - INFO - Collected 1257 records for CL=F
2025-10-24 23:54:31,776 - data.oil_data_pipeline - INFO - Collected 1258 records for BZ=F
2025-10-24 23:54:32,627 - data.oil_data_pipeline - INFO - Collected 1258 records for NG=F
2025-10-24 23:54:32,628 - data.oil_data_pipeline - INFO - Collecting financial market data...
2025-10-24 23:54:33,444 - data.oil_data_pipeline - INFO - Collected 1255 records for ^GSPC
2025-10-24 23:54:34,215 - data.oil_data_pipeline - INFO - Collected 1255 records for ^DJI
2025-10-24 23:54:36,154 - data.oil_data_pipeline - INFO - Collected 1255 records for ^IXIC
2025-10-24 23:54:39,815 - data.oil_data_pipeline - INFO - Collected 1301 records for EURUSD=X
2025-10-24 23:54:42,838 - data.oil_data_pipeline - INFO - Collected 1301 records for GBPUSD=X
2025-10-24 23:54:45,526 - data.oil_data_pipeline - INFO - Collected 1301 records for USDJPY=X
2025-10-24 23:54:48,071 - data.oil_data_pipeline - INFO - Collected 1255 records for XLE
2025-10-24 23:54:50,509 - data.oil_data_pipeline - INFO - Collected 1255 records for VDE
2025-10-24 23:54:52,733 - data.oil_data_pipeline - INFO - Collected 1255 records for IYE
2025-10-24 23:54:52,750 - data.oil_data_pipeline - INFO - Collecting GDELT news data from BigQuery...
2025-10-24 23:54:54,074 - data.oil_data_pipeline - ERROR - GDELT BigQuery error: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/outstanding-map-449312-a0/jobs?prettyPrint=false: Access Denied: Project outstanding-map-449312-a0: User does not have bigquery.jobs.create permission in project outstanding-map-449312-a0.

Location: None
Job ID: ad170a93-1213-4be6-9306-7f27a0d2ae08

2025-10-24 23:54:54,074 - data.oil_data_pipeline - INFO - Falling back to local news data
2025-10-24 23:54:54,074 - data.oil_data_pipeline - WARNING - Creating comprehensive fallback news data
2025-10-24 23:54:54,080 - data.oil_data_pipeline - WARNING - Failed to load fallback news data: time data "Fri, 24 Oct 2025 06:00:00 -0400" doesn't match format "%a, %d %b %Y %H:%M:%S GMT", at position 5. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
2025-10-24 23:54:54,081 - data.oil_data_pipeline - INFO - Created 150 comprehensive news events
2025-10-24 23:54:54,082 - data.oil_data_pipeline - INFO - Creating news-to-price time mapping...
2025-10-24 23:55:00,131 - data.oil_data_pipeline - INFO - Created 787 news-to-price mappings
2025-10-24 23:55:00,131 - data.oil_data_pipeline - INFO - Data collection complete: 16143 total records
2025-10-24 23:55:00,131 - __main__ - INFO - Data collection complete: 16143 total records
2025-10-24 23:55:00,131 - __main__ - INFO - Starting GPU training...
2025-10-24 23:55:00,131 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:55:00,263 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:55:00,263 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:55:00,263 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:55:00,394 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:55:00,394 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:55:00,400 - models.oil_price_model - INFO - Oil Price Model initialized with 614,556 parameters
2025-10-24 23:55:00,497 - __main__ - INFO - Model initialized with 614,556 parameters
2025-10-24 23:55:02,348 - __main__ - INFO - Epoch 0, Batch 0/50, Loss: 3190.437500
2025-10-24 23:55:02,503 - __main__ - INFO - Epoch 0, Batch 10/50, Loss: 3650.033447
2025-10-24 23:55:02,644 - __main__ - INFO - Epoch 0, Batch 20/50, Loss: 3408.324219
2025-10-24 23:55:02,791 - __main__ - INFO - Epoch 0, Batch 30/50, Loss: 3567.552979
2025-10-24 23:55:02,932 - __main__ - INFO - Epoch 0, Batch 40/50, Loss: 2677.767578
2025-10-24 23:55:03,338 - __main__ - INFO - Epoch 0: Train Loss: 3343.834263, Val Loss: 3331.257635, LR: 9.76e-05
2025-10-24 23:55:03,350 - __main__ - INFO - Saved best model (Val Loss: 3331.257635)
2025-10-24 23:55:03,365 - __main__ - INFO - Epoch 1, Batch 0/50, Loss: 3691.524170
2025-10-24 23:55:03,514 - __main__ - INFO - Epoch 1, Batch 10/50, Loss: 3553.826660
2025-10-24 23:55:03,658 - __main__ - INFO - Epoch 1, Batch 20/50, Loss: 3911.513428
2025-10-24 23:55:03,799 - __main__ - INFO - Epoch 1, Batch 30/50, Loss: 2600.187256
2025-10-24 23:55:03,927 - __main__ - INFO - Epoch 1, Batch 40/50, Loss: 3199.600098
2025-10-24 23:55:04,266 - __main__ - INFO - Epoch 1: Train Loss: 3170.971877, Val Loss: 2590.598311, LR: 9.05e-05
2025-10-24 23:55:04,275 - __main__ - INFO - Saved best model (Val Loss: 2590.598311)
2025-10-24 23:55:04,289 - __main__ - INFO - Epoch 2, Batch 0/50, Loss: 3061.715576
2025-10-24 23:55:04,429 - __main__ - INFO - Epoch 2, Batch 10/50, Loss: 1811.037109
2025-10-24 23:55:04,574 - __main__ - INFO - Epoch 2, Batch 20/50, Loss: 1224.415771
2025-10-24 23:55:04,731 - __main__ - INFO - Epoch 2, Batch 30/50, Loss: 384.453888
2025-10-24 23:55:04,871 - __main__ - INFO - Epoch 2, Batch 40/50, Loss: 548.333862
2025-10-24 23:55:05,215 - __main__ - INFO - Epoch 2: Train Loss: 1105.064305, Val Loss: 207.987229, LR: 7.94e-05
2025-10-24 23:55:05,224 - __main__ - INFO - Saved best model (Val Loss: 207.987229)
2025-10-24 23:55:05,240 - __main__ - INFO - Epoch 3, Batch 0/50, Loss: 258.057678
2025-10-24 23:55:05,382 - __main__ - INFO - Epoch 3, Batch 10/50, Loss: 177.164917
2025-10-24 23:55:05,525 - __main__ - INFO - Epoch 3, Batch 20/50, Loss: 231.032837
2025-10-24 23:55:05,662 - __main__ - INFO - Epoch 3, Batch 30/50, Loss: 229.481384
2025-10-24 23:55:05,787 - __main__ - INFO - Epoch 3, Batch 40/50, Loss: 175.545013
2025-10-24 23:55:06,120 - __main__ - INFO - Epoch 3: Train Loss: 248.903925, Val Loss: 111.496723, LR: 6.55e-05
2025-10-24 23:55:06,128 - __main__ - INFO - Saved best model (Val Loss: 111.496723)
2025-10-24 23:55:06,143 - __main__ - INFO - Epoch 4, Batch 0/50, Loss: 150.353699
2025-10-24 23:55:06,286 - __main__ - INFO - Epoch 4, Batch 10/50, Loss: 291.394226
2025-10-24 23:55:06,405 - __main__ - INFO - Epoch 4, Batch 20/50, Loss: 167.893021
2025-10-24 23:55:06,520 - __main__ - INFO - Epoch 4, Batch 30/50, Loss: 120.420151
2025-10-24 23:55:06,637 - __main__ - INFO - Epoch 4, Batch 40/50, Loss: 142.166016
2025-10-24 23:55:06,957 - __main__ - INFO - Epoch 4: Train Loss: 189.800941, Val Loss: 79.649535, LR: 5.00e-05
2025-10-24 23:55:06,966 - __main__ - INFO - Saved best model (Val Loss: 79.649535)
2025-10-24 23:55:06,981 - __main__ - INFO - Epoch 5, Batch 0/50, Loss: 152.467758
2025-10-24 23:55:07,117 - __main__ - INFO - Epoch 5, Batch 10/50, Loss: 200.298615
2025-10-24 23:55:07,263 - __main__ - INFO - Epoch 5, Batch 20/50, Loss: 198.305634
2025-10-24 23:55:07,394 - __main__ - INFO - Epoch 5, Batch 30/50, Loss: 88.023315
2025-10-24 23:55:07,537 - __main__ - INFO - Epoch 5, Batch 40/50, Loss: 114.229813
2025-10-24 23:55:07,865 - __main__ - INFO - Epoch 5: Train Loss: 171.842405, Val Loss: 74.906746, LR: 3.45e-05
2025-10-24 23:55:07,875 - __main__ - INFO - Saved best model (Val Loss: 74.906746)
2025-10-24 23:55:07,893 - __main__ - INFO - Epoch 6, Batch 0/50, Loss: 97.913818
2025-10-24 23:55:08,028 - __main__ - INFO - Epoch 6, Batch 10/50, Loss: 145.955429
2025-10-24 23:55:08,168 - __main__ - INFO - Epoch 6, Batch 20/50, Loss: 78.878464
2025-10-24 23:55:08,292 - __main__ - INFO - Epoch 6, Batch 30/50, Loss: 131.454666
2025-10-24 23:55:08,425 - __main__ - INFO - Epoch 6, Batch 40/50, Loss: 583.545715
2025-10-24 23:55:08,737 - __main__ - INFO - Epoch 6: Train Loss: 152.986576, Val Loss: 62.442525, LR: 2.06e-05
2025-10-24 23:55:08,746 - __main__ - INFO - Saved best model (Val Loss: 62.442525)
2025-10-24 23:55:08,765 - __main__ - INFO - Epoch 7, Batch 0/50, Loss: 200.952057
2025-10-24 23:55:08,917 - __main__ - INFO - Epoch 7, Batch 10/50, Loss: 104.446762
2025-10-24 23:55:09,045 - __main__ - INFO - Epoch 7, Batch 20/50, Loss: 98.130745
2025-10-24 23:55:09,186 - __main__ - INFO - Epoch 7, Batch 30/50, Loss: 92.069839
2025-10-24 23:55:09,317 - __main__ - INFO - Epoch 7, Batch 40/50, Loss: 102.841156
2025-10-24 23:55:09,644 - __main__ - INFO - Epoch 7: Train Loss: 145.243699, Val Loss: 60.021544, LR: 9.55e-06
2025-10-24 23:55:09,652 - __main__ - INFO - Saved best model (Val Loss: 60.021544)
2025-10-24 23:55:09,669 - __main__ - INFO - Epoch 8, Batch 0/50, Loss: 208.945587
2025-10-24 23:55:09,801 - __main__ - INFO - Epoch 8, Batch 10/50, Loss: 111.068939
2025-10-24 23:55:09,934 - __main__ - INFO - Epoch 8, Batch 20/50, Loss: 110.097878
2025-10-24 23:55:10,059 - __main__ - INFO - Epoch 8, Batch 30/50, Loss: 177.341599
2025-10-24 23:55:10,185 - __main__ - INFO - Epoch 8, Batch 40/50, Loss: 166.320190
2025-10-24 23:55:10,465 - __main__ - INFO - Epoch 8: Train Loss: 146.348909, Val Loss: 62.068046, LR: 2.45e-06
2025-10-24 23:55:10,482 - __main__ - INFO - Epoch 9, Batch 0/50, Loss: 171.245636
2025-10-24 23:55:10,607 - __main__ - INFO - Epoch 9, Batch 10/50, Loss: 102.190613
2025-10-24 23:55:10,736 - __main__ - INFO - Epoch 9, Batch 20/50, Loss: 116.538780
2025-10-24 23:55:10,857 - __main__ - INFO - Epoch 9, Batch 30/50, Loss: 169.204681
2025-10-24 23:55:10,979 - __main__ - INFO - Epoch 9, Batch 40/50, Loss: 69.649910
2025-10-24 23:55:11,286 - __main__ - INFO - Epoch 9: Train Loss: 140.737199, Val Loss: 59.754370, LR: 1.00e-04
2025-10-24 23:55:11,294 - __main__ - INFO - Saved best model (Val Loss: 59.754370)
2025-10-24 23:55:11,310 - __main__ - INFO - Epoch 10, Batch 0/50, Loss: 139.322372
2025-10-24 23:55:11,437 - __main__ - INFO - Epoch 10, Batch 10/50, Loss: 153.779343
2025-10-24 23:55:11,560 - __main__ - INFO - Epoch 10, Batch 20/50, Loss: 118.205170
2025-10-24 23:55:11,694 - __main__ - INFO - Epoch 10, Batch 30/50, Loss: 510.437378
2025-10-24 23:55:11,820 - __main__ - INFO - Epoch 10, Batch 40/50, Loss: 139.778946
2025-10-24 23:55:12,106 - __main__ - INFO - Epoch 10: Train Loss: 144.062144, Val Loss: 48.040890, LR: 9.94e-05
2025-10-24 23:55:12,114 - __main__ - INFO - Saved best model (Val Loss: 48.040890)
2025-10-24 23:55:12,127 - __main__ - INFO - Epoch 11, Batch 0/50, Loss: 139.374802
2025-10-24 23:55:12,271 - __main__ - INFO - Epoch 11, Batch 10/50, Loss: 118.040894
2025-10-24 23:55:12,428 - __main__ - INFO - Epoch 11, Batch 20/50, Loss: 115.967773
2025-10-24 23:55:12,559 - __main__ - INFO - Epoch 11, Batch 30/50, Loss: 82.062469
2025-10-24 23:55:12,691 - __main__ - INFO - Epoch 11, Batch 40/50, Loss: 121.085831
2025-10-24 23:55:12,990 - __main__ - INFO - Epoch 11: Train Loss: 121.853755, Val Loss: 38.963886, LR: 9.76e-05
2025-10-24 23:55:12,998 - __main__ - INFO - Saved best model (Val Loss: 38.963886)
2025-10-24 23:55:13,010 - __main__ - INFO - Epoch 12, Batch 0/50, Loss: 134.372589
2025-10-24 23:55:13,139 - __main__ - INFO - Epoch 12, Batch 10/50, Loss: 102.569939
2025-10-24 23:55:13,273 - __main__ - INFO - Epoch 12, Batch 20/50, Loss: 114.296669
2025-10-24 23:55:13,395 - __main__ - INFO - Epoch 12, Batch 30/50, Loss: 103.741631
2025-10-24 23:55:13,520 - __main__ - INFO - Epoch 12, Batch 40/50, Loss: 85.696877
2025-10-24 23:55:13,827 - __main__ - INFO - Epoch 12: Train Loss: 118.232257, Val Loss: 34.788135, LR: 9.46e-05
2025-10-24 23:55:13,835 - __main__ - INFO - Saved best model (Val Loss: 34.788135)
2025-10-24 23:55:13,853 - __main__ - INFO - Epoch 13, Batch 0/50, Loss: 82.095757
2025-10-24 23:55:13,972 - __main__ - INFO - Epoch 13, Batch 10/50, Loss: 65.954315
2025-10-24 23:55:14,090 - __main__ - INFO - Epoch 13, Batch 20/50, Loss: 152.582840
2025-10-24 23:55:14,223 - __main__ - INFO - Epoch 13, Batch 30/50, Loss: 113.444847
2025-10-24 23:55:14,352 - __main__ - INFO - Epoch 13, Batch 40/50, Loss: 137.870621
2025-10-24 23:55:14,624 - __main__ - INFO - Epoch 13: Train Loss: 100.243743, Val Loss: 31.167295, LR: 9.05e-05
2025-10-24 23:55:14,632 - __main__ - INFO - Saved best model (Val Loss: 31.167295)
2025-10-24 23:55:14,650 - __main__ - INFO - Epoch 14, Batch 0/50, Loss: 84.262016
2025-10-24 23:55:14,781 - __main__ - INFO - Epoch 14, Batch 10/50, Loss: 70.650368
2025-10-24 23:55:14,905 - __main__ - INFO - Epoch 14, Batch 20/50, Loss: 83.094810
2025-10-24 23:55:15,030 - __main__ - INFO - Epoch 14, Batch 30/50, Loss: 62.927624
2025-10-24 23:55:15,154 - __main__ - INFO - Epoch 14, Batch 40/50, Loss: 84.027092
2025-10-24 23:55:15,449 - __main__ - INFO - Epoch 14: Train Loss: 92.981438, Val Loss: 32.376707, LR: 8.54e-05
2025-10-24 23:55:15,468 - __main__ - INFO - Epoch 15, Batch 0/50, Loss: 47.633736
2025-10-24 23:55:15,607 - __main__ - INFO - Epoch 15, Batch 10/50, Loss: 69.009148
2025-10-24 23:55:15,737 - __main__ - INFO - Epoch 15, Batch 20/50, Loss: 83.874191
2025-10-24 23:55:15,857 - __main__ - INFO - Epoch 15, Batch 30/50, Loss: 106.847176
2025-10-24 23:55:15,985 - __main__ - INFO - Epoch 15, Batch 40/50, Loss: 111.076088
2025-10-24 23:55:16,295 - __main__ - INFO - Epoch 15: Train Loss: 85.748317, Val Loss: 23.724061, LR: 7.94e-05
2025-10-24 23:55:16,302 - __main__ - INFO - Saved best model (Val Loss: 23.724061)
2025-10-24 23:55:16,315 - __main__ - INFO - Epoch 16, Batch 0/50, Loss: 70.256424
2025-10-24 23:55:16,446 - __main__ - INFO - Epoch 16, Batch 10/50, Loss: 56.974812
2025-10-24 23:55:16,573 - __main__ - INFO - Epoch 16, Batch 20/50, Loss: 93.999542
2025-10-24 23:55:16,710 - __main__ - INFO - Epoch 16, Batch 30/50, Loss: 69.048332
2025-10-24 23:55:16,839 - __main__ - INFO - Epoch 16, Batch 40/50, Loss: 65.344208
2025-10-24 23:55:17,191 - __main__ - INFO - Epoch 16: Train Loss: 84.925431, Val Loss: 27.932547, LR: 7.27e-05
2025-10-24 23:55:17,203 - __main__ - INFO - Epoch 17, Batch 0/50, Loss: 67.902237
2025-10-24 23:55:17,323 - __main__ - INFO - Epoch 17, Batch 10/50, Loss: 90.382576
2025-10-24 23:55:17,448 - __main__ - INFO - Epoch 17, Batch 20/50, Loss: 65.918076
2025-10-24 23:55:17,573 - __main__ - INFO - Epoch 17, Batch 30/50, Loss: 48.602654
2025-10-24 23:55:17,698 - __main__ - INFO - Epoch 17, Batch 40/50, Loss: 79.773331
2025-10-24 23:55:18,003 - __main__ - INFO - Epoch 17: Train Loss: 81.536012, Val Loss: 24.465296, LR: 6.55e-05
2025-10-24 23:55:18,018 - __main__ - INFO - Epoch 18, Batch 0/50, Loss: 56.878086
2025-10-24 23:55:18,161 - __main__ - INFO - Epoch 18, Batch 10/50, Loss: 79.074524
2025-10-24 23:55:18,286 - __main__ - INFO - Epoch 18, Batch 20/50, Loss: 46.934479
2025-10-24 23:55:18,411 - __main__ - INFO - Epoch 18, Batch 30/50, Loss: 128.218628
2025-10-24 23:55:18,547 - __main__ - INFO - Epoch 18, Batch 40/50, Loss: 118.819389
2025-10-24 23:55:18,842 - __main__ - INFO - Epoch 18: Train Loss: 80.482040, Val Loss: 19.665846, LR: 5.78e-05
2025-10-24 23:55:18,850 - __main__ - INFO - Saved best model (Val Loss: 19.665846)
2025-10-24 23:55:18,866 - __main__ - INFO - Epoch 19, Batch 0/50, Loss: 60.848225
2025-10-24 23:55:18,991 - __main__ - INFO - Epoch 19, Batch 10/50, Loss: 85.708015
2025-10-24 23:55:19,129 - __main__ - INFO - Epoch 19, Batch 20/50, Loss: 52.067204
2025-10-24 23:55:19,257 - __main__ - INFO - Epoch 19, Batch 30/50, Loss: 79.125793
2025-10-24 23:55:19,402 - __main__ - INFO - Epoch 19, Batch 40/50, Loss: 102.629425
2025-10-24 23:55:19,675 - __main__ - INFO - Epoch 19: Train Loss: 75.470246, Val Loss: 19.709184, LR: 5.00e-05
2025-10-24 23:55:19,687 - __main__ - INFO - Epoch 20, Batch 0/50, Loss: 57.619411
2025-10-24 23:55:19,804 - __main__ - INFO - Epoch 20, Batch 10/50, Loss: 48.337078
2025-10-24 23:55:19,931 - __main__ - INFO - Epoch 20, Batch 20/50, Loss: 54.740021
2025-10-24 23:55:20,060 - __main__ - INFO - Epoch 20, Batch 30/50, Loss: 72.825760
2025-10-24 23:55:20,179 - __main__ - INFO - Epoch 20, Batch 40/50, Loss: 65.846130
2025-10-24 23:55:20,479 - __main__ - INFO - Epoch 20: Train Loss: 78.776380, Val Loss: 18.904388, LR: 4.22e-05
2025-10-24 23:55:20,486 - __main__ - INFO - Saved best model (Val Loss: 18.904388)
2025-10-24 23:55:20,501 - __main__ - INFO - Epoch 21, Batch 0/50, Loss: 63.033733
2025-10-24 23:55:20,630 - __main__ - INFO - Epoch 21, Batch 10/50, Loss: 68.725746
2025-10-24 23:55:20,751 - __main__ - INFO - Epoch 21, Batch 20/50, Loss: 81.049423
2025-10-24 23:55:20,871 - __main__ - INFO - Epoch 21, Batch 30/50, Loss: 63.432228
2025-10-24 23:55:20,990 - __main__ - INFO - Epoch 21, Batch 40/50, Loss: 43.370827
2025-10-24 23:55:21,268 - __main__ - INFO - Epoch 21: Train Loss: 75.622293, Val Loss: 18.453732, LR: 3.45e-05
2025-10-24 23:55:21,277 - __main__ - INFO - Saved best model (Val Loss: 18.453732)
2025-10-24 23:55:21,290 - __main__ - INFO - Epoch 22, Batch 0/50, Loss: 68.492554
2025-10-24 23:55:21,419 - __main__ - INFO - Epoch 22, Batch 10/50, Loss: 104.966423
2025-10-24 23:55:21,541 - __main__ - INFO - Epoch 22, Batch 20/50, Loss: 89.962585
2025-10-24 23:55:21,662 - __main__ - INFO - Epoch 22, Batch 30/50, Loss: 64.190926
2025-10-24 23:55:21,791 - __main__ - INFO - Epoch 22, Batch 40/50, Loss: 54.593334
2025-10-24 23:55:22,090 - __main__ - INFO - Epoch 22: Train Loss: 76.815133, Val Loss: 18.728595, LR: 2.73e-05
2025-10-24 23:55:22,103 - __main__ - INFO - Epoch 23, Batch 0/50, Loss: 51.107975
2025-10-24 23:55:22,227 - __main__ - INFO - Epoch 23, Batch 10/50, Loss: 54.198524
2025-10-24 23:55:22,349 - __main__ - INFO - Epoch 23, Batch 20/50, Loss: 49.409908
2025-10-24 23:55:22,470 - __main__ - INFO - Epoch 23, Batch 30/50, Loss: 73.394043
2025-10-24 23:55:22,595 - __main__ - INFO - Epoch 23, Batch 40/50, Loss: 89.598106
2025-10-24 23:55:22,869 - __main__ - INFO - Epoch 23: Train Loss: 72.581567, Val Loss: 17.968506, LR: 2.06e-05
2025-10-24 23:55:22,877 - __main__ - INFO - Saved best model (Val Loss: 17.968506)
2025-10-24 23:55:22,893 - __main__ - INFO - Epoch 24, Batch 0/50, Loss: 61.048538
2025-10-24 23:55:23,020 - __main__ - INFO - Epoch 24, Batch 10/50, Loss: 51.425308
2025-10-24 23:55:23,141 - __main__ - INFO - Epoch 24, Batch 20/50, Loss: 81.295135
2025-10-24 23:55:23,277 - __main__ - INFO - Epoch 24, Batch 30/50, Loss: 56.741070
2025-10-24 23:55:23,407 - __main__ - INFO - Epoch 24, Batch 40/50, Loss: 45.489769
2025-10-24 23:55:23,719 - __main__ - INFO - Epoch 24: Train Loss: 68.267865, Val Loss: 19.143086, LR: 1.46e-05
2025-10-24 23:55:23,731 - __main__ - INFO - Epoch 25, Batch 0/50, Loss: 42.379013
2025-10-24 23:55:23,874 - __main__ - INFO - Epoch 25, Batch 10/50, Loss: 49.711098
2025-10-24 23:55:24,009 - __main__ - INFO - Epoch 25, Batch 20/50, Loss: 75.003876
2025-10-24 23:55:24,174 - __main__ - INFO - Epoch 25, Batch 30/50, Loss: 45.236237
2025-10-24 23:55:24,332 - __main__ - INFO - Epoch 25, Batch 40/50, Loss: 63.813293
2025-10-24 23:55:24,648 - __main__ - INFO - Epoch 25: Train Loss: 73.874806, Val Loss: 18.691630, LR: 9.55e-06
2025-10-24 23:55:24,661 - __main__ - INFO - Epoch 26, Batch 0/50, Loss: 107.969254
2025-10-24 23:55:24,789 - __main__ - INFO - Epoch 26, Batch 10/50, Loss: 64.247826
2025-10-24 23:55:24,923 - __main__ - INFO - Epoch 26, Batch 20/50, Loss: 46.255424
2025-10-24 23:55:25,054 - __main__ - INFO - Epoch 26, Batch 30/50, Loss: 72.202553
2025-10-24 23:55:25,188 - __main__ - INFO - Epoch 26, Batch 40/50, Loss: 49.660236
2025-10-24 23:55:25,546 - __main__ - INFO - Epoch 26: Train Loss: 74.524546, Val Loss: 18.097910, LR: 5.45e-06
2025-10-24 23:55:25,559 - __main__ - INFO - Epoch 27, Batch 0/50, Loss: 48.726124
2025-10-24 23:55:25,684 - __main__ - INFO - Epoch 27, Batch 10/50, Loss: 40.952927
2025-10-24 23:55:25,804 - __main__ - INFO - Epoch 27, Batch 20/50, Loss: 79.675278
2025-10-24 23:55:25,922 - __main__ - INFO - Epoch 27, Batch 30/50, Loss: 69.749542
2025-10-24 23:55:26,044 - __main__ - INFO - Epoch 27, Batch 40/50, Loss: 79.826485
2025-10-24 23:55:26,332 - __main__ - INFO - Epoch 27: Train Loss: 71.587606, Val Loss: 19.145444, LR: 2.45e-06
2025-10-24 23:55:26,345 - __main__ - INFO - Epoch 28, Batch 0/50, Loss: 88.255768
2025-10-24 23:55:26,469 - __main__ - INFO - Epoch 28, Batch 10/50, Loss: 63.509212
2025-10-24 23:55:26,592 - __main__ - INFO - Epoch 28, Batch 20/50, Loss: 53.624416
2025-10-24 23:55:26,714 - __main__ - INFO - Epoch 28, Batch 30/50, Loss: 67.821815
2025-10-24 23:55:26,842 - __main__ - INFO - Epoch 28, Batch 40/50, Loss: 54.333397
2025-10-24 23:55:27,147 - __main__ - INFO - Epoch 28: Train Loss: 70.616405, Val Loss: 18.391002, LR: 6.16e-07
2025-10-24 23:55:27,160 - __main__ - INFO - Epoch 29, Batch 0/50, Loss: 64.066284
2025-10-24 23:55:27,283 - __main__ - INFO - Epoch 29, Batch 10/50, Loss: 417.999359
2025-10-24 23:55:27,408 - __main__ - INFO - Epoch 29, Batch 20/50, Loss: 64.814758
2025-10-24 23:55:27,533 - __main__ - INFO - Epoch 29, Batch 30/50, Loss: 54.147717
2025-10-24 23:55:27,653 - __main__ - INFO - Epoch 29, Batch 40/50, Loss: 45.708591
2025-10-24 23:55:27,944 - __main__ - INFO - Epoch 29: Train Loss: 68.328413, Val Loss: 18.611102, LR: 1.00e-04
2025-10-24 23:55:27,956 - __main__ - INFO - Epoch 30, Batch 0/50, Loss: 25.628246
2025-10-24 23:55:28,079 - __main__ - INFO - Epoch 30, Batch 10/50, Loss: 49.050316
2025-10-24 23:55:28,200 - __main__ - INFO - Epoch 30, Batch 20/50, Loss: 52.294682
2025-10-24 23:55:28,328 - __main__ - INFO - Epoch 30, Batch 30/50, Loss: 54.772121
2025-10-24 23:55:28,447 - __main__ - INFO - Epoch 30, Batch 40/50, Loss: 84.898109
2025-10-24 23:55:28,738 - __main__ - INFO - Epoch 30: Train Loss: 72.438117, Val Loss: 18.439562, LR: 9.98e-05
2025-10-24 23:55:28,749 - __main__ - INFO - Epoch 31, Batch 0/50, Loss: 41.371220
2025-10-24 23:55:28,877 - __main__ - INFO - Epoch 31, Batch 10/50, Loss: 71.620293
2025-10-24 23:55:28,998 - __main__ - INFO - Epoch 31, Batch 20/50, Loss: 75.685562
2025-10-24 23:55:29,122 - __main__ - INFO - Epoch 31, Batch 30/50, Loss: 75.644806
2025-10-24 23:55:29,251 - __main__ - INFO - Epoch 31, Batch 40/50, Loss: 47.479927
2025-10-24 23:55:29,537 - __main__ - INFO - Epoch 31: Train Loss: 67.936962, Val Loss: 20.158656, LR: 9.94e-05
2025-10-24 23:55:29,549 - __main__ - INFO - Epoch 32, Batch 0/50, Loss: 37.428745
2025-10-24 23:55:29,679 - __main__ - INFO - Epoch 32, Batch 10/50, Loss: 85.528549
2025-10-24 23:55:29,805 - __main__ - INFO - Epoch 32, Batch 20/50, Loss: 25.881741
2025-10-24 23:55:29,927 - __main__ - INFO - Epoch 32, Batch 30/50, Loss: 83.423973
2025-10-24 23:55:30,048 - __main__ - INFO - Epoch 32, Batch 40/50, Loss: 64.752655
2025-10-24 23:55:30,333 - __main__ - INFO - Epoch 32: Train Loss: 73.512111, Val Loss: 17.554358, LR: 9.86e-05
2025-10-24 23:55:30,341 - __main__ - INFO - Saved best model (Val Loss: 17.554358)
2025-10-24 23:55:30,355 - __main__ - INFO - Epoch 33, Batch 0/50, Loss: 52.857075
2025-10-24 23:55:30,483 - __main__ - INFO - Epoch 33, Batch 10/50, Loss: 425.186340
2025-10-24 23:55:30,605 - __main__ - INFO - Epoch 33, Batch 20/50, Loss: 68.197174
2025-10-24 23:55:30,766 - __main__ - INFO - Epoch 33, Batch 30/50, Loss: 61.101364
2025-10-24 23:55:30,898 - __main__ - INFO - Epoch 33, Batch 40/50, Loss: 52.125877
2025-10-24 23:55:31,187 - __main__ - INFO - Epoch 33: Train Loss: 68.778252, Val Loss: 18.330273, LR: 9.76e-05
2025-10-24 23:55:31,199 - __main__ - INFO - Epoch 34, Batch 0/50, Loss: 79.134987
2025-10-24 23:55:31,323 - __main__ - INFO - Epoch 34, Batch 10/50, Loss: 42.612099
2025-10-24 23:55:31,438 - __main__ - INFO - Epoch 34, Batch 20/50, Loss: 53.478596
2025-10-24 23:55:31,559 - __main__ - INFO - Epoch 34, Batch 30/50, Loss: 53.414371
2025-10-24 23:55:31,684 - __main__ - INFO - Epoch 34, Batch 40/50, Loss: 58.075844
2025-10-24 23:55:31,959 - __main__ - INFO - Epoch 34: Train Loss: 67.140953, Val Loss: 17.852168, LR: 9.62e-05
2025-10-24 23:55:31,971 - __main__ - INFO - Epoch 35, Batch 0/50, Loss: 47.022064
2025-10-24 23:55:32,094 - __main__ - INFO - Epoch 35, Batch 10/50, Loss: 65.162437
2025-10-24 23:55:32,210 - __main__ - INFO - Epoch 35, Batch 20/50, Loss: 45.539108
2025-10-24 23:55:32,333 - __main__ - INFO - Epoch 35, Batch 30/50, Loss: 533.409180
2025-10-24 23:55:32,460 - __main__ - INFO - Epoch 35, Batch 40/50, Loss: 58.154415
2025-10-24 23:55:32,765 - __main__ - INFO - Epoch 35: Train Loss: 69.841701, Val Loss: 18.824437, LR: 9.46e-05
2025-10-24 23:55:32,780 - __main__ - INFO - Epoch 36, Batch 0/50, Loss: 50.923328
2025-10-24 23:55:32,909 - __main__ - INFO - Epoch 36, Batch 10/50, Loss: 42.429287
2025-10-24 23:55:33,029 - __main__ - INFO - Epoch 36, Batch 20/50, Loss: 43.039894
2025-10-24 23:55:33,152 - __main__ - INFO - Epoch 36, Batch 30/50, Loss: 45.538723
2025-10-24 23:55:33,271 - __main__ - INFO - Epoch 36, Batch 40/50, Loss: 55.606693
2025-10-24 23:55:33,550 - __main__ - INFO - Epoch 36: Train Loss: 64.951299, Val Loss: 17.312559, LR: 9.26e-05
2025-10-24 23:55:33,558 - __main__ - INFO - Saved best model (Val Loss: 17.312559)
2025-10-24 23:55:33,570 - __main__ - INFO - Epoch 37, Batch 0/50, Loss: 34.687534
2025-10-24 23:55:33,691 - __main__ - INFO - Epoch 37, Batch 10/50, Loss: 71.412277
2025-10-24 23:55:33,810 - __main__ - INFO - Epoch 37, Batch 20/50, Loss: 58.446072
2025-10-24 23:55:33,931 - __main__ - INFO - Epoch 37, Batch 30/50, Loss: 74.573174
2025-10-24 23:55:34,053 - __main__ - INFO - Epoch 37, Batch 40/50, Loss: 54.334793
2025-10-24 23:55:34,352 - __main__ - INFO - Epoch 37: Train Loss: 64.275745, Val Loss: 19.142090, LR: 9.05e-05
2025-10-24 23:55:34,364 - __main__ - INFO - Epoch 38, Batch 0/50, Loss: 42.144112
2025-10-24 23:55:34,490 - __main__ - INFO - Epoch 38, Batch 10/50, Loss: 103.999680
2025-10-24 23:55:34,612 - __main__ - INFO - Epoch 38, Batch 20/50, Loss: 66.300201
2025-10-24 23:55:34,735 - __main__ - INFO - Epoch 38, Batch 30/50, Loss: 67.302589
2025-10-24 23:55:34,862 - __main__ - INFO - Epoch 38, Batch 40/50, Loss: 42.359577
2025-10-24 23:55:35,150 - __main__ - INFO - Epoch 38: Train Loss: 62.029423, Val Loss: 23.741613, LR: 8.80e-05
2025-10-24 23:55:35,162 - __main__ - INFO - Epoch 39, Batch 0/50, Loss: 40.583378
2025-10-24 23:55:35,288 - __main__ - INFO - Epoch 39, Batch 10/50, Loss: 34.011654
2025-10-24 23:55:35,405 - __main__ - INFO - Epoch 39, Batch 20/50, Loss: 33.457352
2025-10-24 23:55:35,537 - __main__ - INFO - Epoch 39, Batch 30/50, Loss: 43.599281
2025-10-24 23:55:35,660 - __main__ - INFO - Epoch 39, Batch 40/50, Loss: 40.520428
2025-10-24 23:55:35,943 - __main__ - INFO - Epoch 39: Train Loss: 63.463490, Val Loss: 17.022726, LR: 8.54e-05
2025-10-24 23:55:35,951 - __main__ - INFO - Saved best model (Val Loss: 17.022726)
2025-10-24 23:55:35,969 - __main__ - INFO - Epoch 40, Batch 0/50, Loss: 33.030319
2025-10-24 23:55:36,098 - __main__ - INFO - Epoch 40, Batch 10/50, Loss: 57.930473
2025-10-24 23:55:36,222 - __main__ - INFO - Epoch 40, Batch 20/50, Loss: 41.797588
2025-10-24 23:55:36,343 - __main__ - INFO - Epoch 40, Batch 30/50, Loss: 39.303783
2025-10-24 23:55:36,478 - __main__ - INFO - Epoch 40, Batch 40/50, Loss: 32.422230
2025-10-24 23:55:36,752 - __main__ - INFO - Epoch 40: Train Loss: 58.004346, Val Loss: 17.641528, LR: 8.25e-05
2025-10-24 23:55:36,764 - __main__ - INFO - Epoch 41, Batch 0/50, Loss: 57.438816
2025-10-24 23:55:36,891 - __main__ - INFO - Epoch 41, Batch 10/50, Loss: 91.738480
2025-10-24 23:55:37,020 - __main__ - INFO - Epoch 41, Batch 20/50, Loss: 78.306015
2025-10-24 23:55:37,150 - __main__ - INFO - Epoch 41, Batch 30/50, Loss: 36.812771
2025-10-24 23:55:37,276 - __main__ - INFO - Epoch 41, Batch 40/50, Loss: 63.345821
2025-10-24 23:55:37,580 - __main__ - INFO - Epoch 41: Train Loss: 62.237616, Val Loss: 17.447757, LR: 7.94e-05
2025-10-24 23:55:37,592 - __main__ - INFO - Epoch 42, Batch 0/50, Loss: 88.560020
2025-10-24 23:55:37,714 - __main__ - INFO - Epoch 42, Batch 10/50, Loss: 29.535196
2025-10-24 23:55:37,836 - __main__ - INFO - Epoch 42, Batch 20/50, Loss: 69.764053
2025-10-24 23:55:37,978 - __main__ - INFO - Epoch 42, Batch 30/50, Loss: 46.679073
2025-10-24 23:55:38,104 - __main__ - INFO - Epoch 42, Batch 40/50, Loss: 51.979786
2025-10-24 23:55:38,398 - __main__ - INFO - Epoch 42: Train Loss: 58.869040, Val Loss: 17.798784, LR: 7.61e-05
2025-10-24 23:55:38,413 - __main__ - INFO - Epoch 43, Batch 0/50, Loss: 49.538231
2025-10-24 23:55:38,538 - __main__ - INFO - Epoch 43, Batch 10/50, Loss: 90.026794
2025-10-24 23:55:38,661 - __main__ - INFO - Epoch 43, Batch 20/50, Loss: 59.820095
2025-10-24 23:55:38,782 - __main__ - INFO - Epoch 43, Batch 30/50, Loss: 50.581116
2025-10-24 23:55:38,911 - __main__ - INFO - Epoch 43, Batch 40/50, Loss: 52.005253
2025-10-24 23:55:39,202 - __main__ - INFO - Epoch 43: Train Loss: 59.684445, Val Loss: 17.187313, LR: 7.27e-05
2025-10-24 23:55:39,214 - __main__ - INFO - Epoch 44, Batch 0/50, Loss: 42.872932
2025-10-24 23:55:39,345 - __main__ - INFO - Epoch 44, Batch 10/50, Loss: 75.344055
2025-10-24 23:55:39,479 - __main__ - INFO - Epoch 44, Batch 20/50, Loss: 50.946220
2025-10-24 23:55:39,600 - __main__ - INFO - Epoch 44, Batch 30/50, Loss: 40.027111
2025-10-24 23:55:39,737 - __main__ - INFO - Epoch 44, Batch 40/50, Loss: 55.860283
2025-10-24 23:55:40,036 - __main__ - INFO - Epoch 44: Train Loss: 56.715463, Val Loss: 18.067095, LR: 6.91e-05
2025-10-24 23:55:40,048 - __main__ - INFO - Epoch 45, Batch 0/50, Loss: 38.912949
2025-10-24 23:55:40,172 - __main__ - INFO - Epoch 45, Batch 10/50, Loss: 28.470051
2025-10-24 23:55:40,294 - __main__ - INFO - Epoch 45, Batch 20/50, Loss: 48.711227
2025-10-24 23:55:40,422 - __main__ - INFO - Epoch 45, Batch 30/50, Loss: 37.522602
2025-10-24 23:55:40,592 - __main__ - INFO - Epoch 45, Batch 40/50, Loss: 43.534924
2025-10-24 23:55:40,911 - __main__ - INFO - Epoch 45: Train Loss: 58.465417, Val Loss: 26.914849, LR: 6.55e-05
2025-10-24 23:55:40,929 - __main__ - INFO - Epoch 46, Batch 0/50, Loss: 35.539284
2025-10-24 23:55:41,062 - __main__ - INFO - Epoch 46, Batch 10/50, Loss: 37.186954
2025-10-24 23:55:41,183 - __main__ - INFO - Epoch 46, Batch 20/50, Loss: 34.105858
2025-10-24 23:55:41,312 - __main__ - INFO - Epoch 46, Batch 30/50, Loss: 41.111050
2025-10-24 23:55:41,447 - __main__ - INFO - Epoch 46, Batch 40/50, Loss: 34.813194
2025-10-24 23:55:41,730 - __main__ - INFO - Epoch 46: Train Loss: 58.939626, Val Loss: 18.773289, LR: 6.17e-05
2025-10-24 23:55:41,742 - __main__ - INFO - Epoch 47, Batch 0/50, Loss: 54.173527
2025-10-24 23:55:41,863 - __main__ - INFO - Epoch 47, Batch 10/50, Loss: 33.732471
2025-10-24 23:55:41,986 - __main__ - INFO - Epoch 47, Batch 20/50, Loss: 42.114174
2025-10-24 23:55:42,109 - __main__ - INFO - Epoch 47, Batch 30/50, Loss: 39.064445
2025-10-24 23:55:42,233 - __main__ - INFO - Epoch 47, Batch 40/50, Loss: 111.177254
2025-10-24 23:55:42,521 - __main__ - INFO - Epoch 47: Train Loss: 61.298118, Val Loss: 19.946354, LR: 5.78e-05
2025-10-24 23:55:42,535 - __main__ - INFO - Epoch 48, Batch 0/50, Loss: 46.871979
2025-10-24 23:55:42,672 - __main__ - INFO - Epoch 48, Batch 10/50, Loss: 53.904022
2025-10-24 23:55:42,803 - __main__ - INFO - Epoch 48, Batch 20/50, Loss: 37.069405
2025-10-24 23:55:42,930 - __main__ - INFO - Epoch 48, Batch 30/50, Loss: 57.628918
2025-10-24 23:55:43,052 - __main__ - INFO - Epoch 48, Batch 40/50, Loss: 39.593788
2025-10-24 23:55:43,343 - __main__ - INFO - Epoch 48: Train Loss: 56.734820, Val Loss: 17.080680, LR: 5.39e-05
2025-10-24 23:55:43,355 - __main__ - INFO - Epoch 49, Batch 0/50, Loss: 34.827358
2025-10-24 23:55:43,479 - __main__ - INFO - Epoch 49, Batch 10/50, Loss: 47.129807
2025-10-24 23:55:43,600 - __main__ - INFO - Epoch 49, Batch 20/50, Loss: 44.812202
2025-10-24 23:55:43,727 - __main__ - INFO - Epoch 49, Batch 30/50, Loss: 32.039028
2025-10-24 23:55:43,848 - __main__ - INFO - Epoch 49, Batch 40/50, Loss: 54.435982
2025-10-24 23:55:44,131 - __main__ - INFO - Epoch 49: Train Loss: 59.482477, Val Loss: 16.970739, LR: 5.00e-05
2025-10-24 23:55:44,138 - __main__ - INFO - Saved best model (Val Loss: 16.970739)
2025-10-24 23:55:44,139 - __main__ - INFO - Training completed. Best validation loss: 16.970739
2025-10-24 23:55:44,142 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:55:44,237 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:55:44,237 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:55:44,237 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:55:44,338 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:55:44,338 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:55:44,338 - __main__ - INFO - Evaluating model...
2025-10-24 23:55:44,540 - utils.metrics - INFO - Computed 20 metrics
2025-10-24 23:55:44,540 - utils.visualization - INFO - Creating training history plots...
2025-10-24 23:55:45,313 - utils.visualization - INFO - Training history plot saved to plots/training_history.png
2025-10-24 23:55:45,313 - utils.visualization - INFO - Creating prediction plots...
2025-10-24 23:55:59,674 - __main__ - INFO - Starting GPU training for oil price prediction...
2025-10-24 23:55:59,698 - __main__ - INFO - Using GPU: NVIDIA GeForce RTX 3070
2025-10-24 23:55:59,698 - __main__ - INFO - GPU Memory: 8.6 GB
2025-10-24 23:55:59,698 - __main__ - INFO - Collecting data for oil price prediction...
2025-10-24 23:55:59,705 - data.oil_data_pipeline - INFO - BigQuery client initialized successfully
2025-10-24 23:55:59,705 - data.oil_data_pipeline - INFO - Collecting data from 2020-10-25 to 2025-10-24
2025-10-24 23:55:59,705 - data.oil_data_pipeline - INFO - Collecting oil price data...
2025-10-24 23:56:00,301 - data.oil_data_pipeline - INFO - Collected 1257 records for CL=F
2025-10-24 23:56:00,474 - data.oil_data_pipeline - INFO - Collected 1258 records for BZ=F
2025-10-24 23:56:00,592 - data.oil_data_pipeline - INFO - Collected 1258 records for NG=F
2025-10-24 23:56:00,593 - data.oil_data_pipeline - INFO - Collecting financial market data...
2025-10-24 23:56:00,709 - data.oil_data_pipeline - INFO - Collected 1255 records for ^GSPC
2025-10-24 23:56:00,881 - data.oil_data_pipeline - INFO - Collected 1255 records for ^DJI
2025-10-24 23:56:01,063 - data.oil_data_pipeline - INFO - Collected 1255 records for ^IXIC
2025-10-24 23:56:01,199 - data.oil_data_pipeline - INFO - Collected 1301 records for EURUSD=X
2025-10-24 23:56:01,435 - data.oil_data_pipeline - INFO - Collected 1301 records for GBPUSD=X
2025-10-24 23:56:01,561 - data.oil_data_pipeline - INFO - Collected 1301 records for USDJPY=X
2025-10-24 23:56:01,734 - data.oil_data_pipeline - INFO - Collected 1255 records for XLE
2025-10-24 23:56:01,886 - data.oil_data_pipeline - INFO - Collected 1255 records for VDE
2025-10-24 23:56:02,096 - data.oil_data_pipeline - INFO - Collected 1255 records for IYE
2025-10-24 23:56:02,107 - data.oil_data_pipeline - INFO - Collecting GDELT news data from BigQuery...
2025-10-24 23:56:03,176 - data.oil_data_pipeline - ERROR - GDELT BigQuery error: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/outstanding-map-449312-a0/jobs?prettyPrint=false: Access Denied: Project outstanding-map-449312-a0: User does not have bigquery.jobs.create permission in project outstanding-map-449312-a0.

Location: None
Job ID: e38ece2a-9265-4cd2-bfe4-4ac162bfa2a6

2025-10-24 23:56:03,176 - data.oil_data_pipeline - INFO - Falling back to local news data
2025-10-24 23:56:03,176 - data.oil_data_pipeline - WARNING - Creating comprehensive fallback news data
2025-10-24 23:56:03,182 - data.oil_data_pipeline - WARNING - Failed to load fallback news data: time data "Fri, 24 Oct 2025 06:00:00 -0400" doesn't match format "%a, %d %b %Y %H:%M:%S GMT", at position 5. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
2025-10-24 23:56:03,182 - data.oil_data_pipeline - INFO - Created 150 comprehensive news events
2025-10-24 23:56:03,183 - data.oil_data_pipeline - INFO - Creating news-to-price time mapping...
2025-10-24 23:56:07,648 - data.oil_data_pipeline - INFO - Created 787 news-to-price mappings
2025-10-24 23:56:07,649 - data.oil_data_pipeline - INFO - Data collection complete: 16143 total records
2025-10-24 23:56:07,649 - __main__ - INFO - Data collection complete: 16143 total records
2025-10-24 23:56:07,649 - __main__ - INFO - Starting GPU training...
2025-10-24 23:56:07,649 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:56:07,778 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:56:07,778 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:56:07,778 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:56:07,874 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:56:07,874 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:56:07,879 - models.oil_price_model - INFO - Oil Price Model initialized with 614,556 parameters
2025-10-24 23:56:07,974 - __main__ - INFO - Model initialized with 614,556 parameters
2025-10-24 23:56:09,482 - __main__ - INFO - Epoch 0, Batch 0/50, Loss: 3543.799561
2025-10-24 23:56:09,630 - __main__ - INFO - Epoch 0, Batch 10/50, Loss: 3162.656006
2025-10-24 23:56:09,760 - __main__ - INFO - Epoch 0, Batch 20/50, Loss: 3274.394775
2025-10-24 23:56:09,878 - __main__ - INFO - Epoch 0, Batch 30/50, Loss: 3921.182373
2025-10-24 23:56:10,008 - __main__ - INFO - Epoch 0, Batch 40/50, Loss: 3195.089844
2025-10-24 23:56:10,287 - __main__ - INFO - Epoch 0: Train Loss: 3383.999780, Val Loss: 3332.767161, LR: 9.76e-05
2025-10-24 23:56:10,296 - __main__ - INFO - Saved best model (Val Loss: 3332.767161)
2025-10-24 23:56:10,308 - __main__ - INFO - Epoch 1, Batch 0/50, Loss: 3253.177002
2025-10-24 23:56:10,415 - __main__ - INFO - Epoch 1, Batch 10/50, Loss: 3113.863525
2025-10-24 23:56:10,543 - __main__ - INFO - Epoch 1, Batch 20/50, Loss: 3595.073730
2025-10-24 23:56:10,661 - __main__ - INFO - Epoch 1, Batch 30/50, Loss: 2981.545654
2025-10-24 23:56:10,776 - __main__ - INFO - Epoch 1, Batch 40/50, Loss: 2837.894531
2025-10-24 23:56:11,076 - __main__ - INFO - Epoch 1: Train Loss: 3168.686528, Val Loss: 2523.497864, LR: 9.05e-05
2025-10-24 23:56:11,082 - __main__ - INFO - Saved best model (Val Loss: 2523.497864)
2025-10-24 23:56:11,094 - __main__ - INFO - Epoch 2, Batch 0/50, Loss: 2939.308350
2025-10-24 23:56:11,217 - __main__ - INFO - Epoch 2, Batch 10/50, Loss: 1654.728638
2025-10-24 23:56:11,326 - __main__ - INFO - Epoch 2, Batch 20/50, Loss: 912.298523
2025-10-24 23:56:11,437 - __main__ - INFO - Epoch 2, Batch 30/50, Loss: 593.217224
2025-10-24 23:56:11,560 - __main__ - INFO - Epoch 2, Batch 40/50, Loss: 657.756775
2025-10-24 23:56:11,837 - __main__ - INFO - Epoch 2: Train Loss: 1087.193849, Val Loss: 265.389446, LR: 7.94e-05
2025-10-24 23:56:11,844 - __main__ - INFO - Saved best model (Val Loss: 265.389446)
2025-10-24 23:56:11,856 - __main__ - INFO - Epoch 3, Batch 0/50, Loss: 470.382385
2025-10-24 23:56:11,986 - __main__ - INFO - Epoch 3, Batch 10/50, Loss: 181.378281
2025-10-24 23:56:12,118 - __main__ - INFO - Epoch 3, Batch 20/50, Loss: 261.081482
2025-10-24 23:56:12,252 - __main__ - INFO - Epoch 3, Batch 30/50, Loss: 222.469864
2025-10-24 23:56:12,375 - __main__ - INFO - Epoch 3, Batch 40/50, Loss: 211.935806
2025-10-24 23:56:12,672 - __main__ - INFO - Epoch 3: Train Loss: 264.279128, Val Loss: 109.183194, LR: 6.55e-05
2025-10-24 23:56:12,679 - __main__ - INFO - Saved best model (Val Loss: 109.183194)
2025-10-24 23:56:12,696 - __main__ - INFO - Epoch 4, Batch 0/50, Loss: 98.363365
2025-10-24 23:56:12,813 - __main__ - INFO - Epoch 4, Batch 10/50, Loss: 172.324600
2025-10-24 23:56:12,929 - __main__ - INFO - Epoch 4, Batch 20/50, Loss: 151.267609
2025-10-24 23:56:13,047 - __main__ - INFO - Epoch 4, Batch 30/50, Loss: 202.099625
2025-10-24 23:56:13,161 - __main__ - INFO - Epoch 4, Batch 40/50, Loss: 130.357910
2025-10-24 23:56:13,452 - __main__ - INFO - Epoch 4: Train Loss: 185.618357, Val Loss: 85.054006, LR: 5.00e-05
2025-10-24 23:56:13,458 - __main__ - INFO - Saved best model (Val Loss: 85.054006)
2025-10-24 23:56:13,474 - __main__ - INFO - Epoch 5, Batch 0/50, Loss: 152.893509
2025-10-24 23:56:13,598 - __main__ - INFO - Epoch 5, Batch 10/50, Loss: 254.631927
2025-10-24 23:56:13,725 - __main__ - INFO - Epoch 5, Batch 20/50, Loss: 163.631012
2025-10-24 23:56:13,844 - __main__ - INFO - Epoch 5, Batch 30/50, Loss: 87.031982
2025-10-24 23:56:13,968 - __main__ - INFO - Epoch 5, Batch 40/50, Loss: 177.059402
2025-10-24 23:56:14,263 - __main__ - INFO - Epoch 5: Train Loss: 169.569056, Val Loss: 80.886866, LR: 3.45e-05
2025-10-24 23:56:14,270 - __main__ - INFO - Saved best model (Val Loss: 80.886866)
2025-10-24 23:56:14,286 - __main__ - INFO - Epoch 6, Batch 0/50, Loss: 120.342644
2025-10-24 23:56:14,405 - __main__ - INFO - Epoch 6, Batch 10/50, Loss: 194.121536
2025-10-24 23:56:14,541 - __main__ - INFO - Epoch 6, Batch 20/50, Loss: 157.958206
2025-10-24 23:56:14,653 - __main__ - INFO - Epoch 6, Batch 30/50, Loss: 98.009659
2025-10-24 23:56:14,780 - __main__ - INFO - Epoch 6, Batch 40/50, Loss: 102.616837
2025-10-24 23:56:15,054 - __main__ - INFO - Epoch 6: Train Loss: 151.430115, Val Loss: 64.348454, LR: 2.06e-05
2025-10-24 23:56:15,062 - __main__ - INFO - Saved best model (Val Loss: 64.348454)
2025-10-24 23:56:15,078 - __main__ - INFO - Epoch 7, Batch 0/50, Loss: 475.762726
2025-10-24 23:56:15,228 - __main__ - INFO - Epoch 7, Batch 10/50, Loss: 141.504852
2025-10-24 23:56:15,376 - __main__ - INFO - Epoch 7, Batch 20/50, Loss: 56.671108
2025-10-24 23:56:15,509 - __main__ - INFO - Epoch 7, Batch 30/50, Loss: 72.287758
2025-10-24 23:56:15,641 - __main__ - INFO - Epoch 7, Batch 40/50, Loss: 146.472046
2025-10-24 23:56:15,923 - __main__ - INFO - Epoch 7: Train Loss: 140.096074, Val Loss: 60.397130, LR: 9.55e-06
2025-10-24 23:56:15,931 - __main__ - INFO - Saved best model (Val Loss: 60.397130)
2025-10-24 23:56:15,944 - __main__ - INFO - Epoch 8, Batch 0/50, Loss: 88.243935
2025-10-24 23:56:16,069 - __main__ - INFO - Epoch 8, Batch 10/50, Loss: 138.269638
2025-10-24 23:56:16,197 - __main__ - INFO - Epoch 8, Batch 20/50, Loss: 175.412659
2025-10-24 23:56:16,326 - __main__ - INFO - Epoch 8, Batch 30/50, Loss: 88.853271
2025-10-24 23:56:16,458 - __main__ - INFO - Epoch 8, Batch 40/50, Loss: 85.993515
2025-10-24 23:56:16,735 - __main__ - INFO - Epoch 8: Train Loss: 133.585105, Val Loss: 60.611488, LR: 2.45e-06
2025-10-24 23:56:16,747 - __main__ - INFO - Epoch 9, Batch 0/50, Loss: 207.563354
2025-10-24 23:56:16,880 - __main__ - INFO - Epoch 9, Batch 10/50, Loss: 84.921684
2025-10-24 23:56:17,019 - __main__ - INFO - Epoch 9, Batch 20/50, Loss: 128.356979
2025-10-24 23:56:17,135 - __main__ - INFO - Epoch 9, Batch 30/50, Loss: 137.085434
2025-10-24 23:56:17,258 - __main__ - INFO - Epoch 9, Batch 40/50, Loss: 195.726654
2025-10-24 23:56:17,563 - __main__ - INFO - Epoch 9: Train Loss: 138.282193, Val Loss: 60.460858, LR: 1.00e-04
2025-10-24 23:56:17,577 - __main__ - INFO - Epoch 10, Batch 0/50, Loss: 76.187508
2025-10-24 23:56:17,711 - __main__ - INFO - Epoch 10, Batch 10/50, Loss: 105.193558
2025-10-24 23:56:17,837 - __main__ - INFO - Epoch 10, Batch 20/50, Loss: 113.478409
2025-10-24 23:56:17,963 - __main__ - INFO - Epoch 10, Batch 30/50, Loss: 162.182068
2025-10-24 23:56:18,094 - __main__ - INFO - Epoch 10, Batch 40/50, Loss: 86.894020
2025-10-24 23:56:18,388 - __main__ - INFO - Epoch 10: Train Loss: 133.672236, Val Loss: 46.822383, LR: 9.94e-05
2025-10-24 23:56:18,398 - __main__ - INFO - Saved best model (Val Loss: 46.822383)
2025-10-24 23:56:18,417 - __main__ - INFO - Epoch 11, Batch 0/50, Loss: 91.069016
2025-10-24 23:56:18,544 - __main__ - INFO - Epoch 11, Batch 10/50, Loss: 173.572113
2025-10-24 23:56:18,666 - __main__ - INFO - Epoch 11, Batch 20/50, Loss: 195.461945
2025-10-24 23:56:18,787 - __main__ - INFO - Epoch 11, Batch 30/50, Loss: 72.744164
2025-10-24 23:56:18,914 - __main__ - INFO - Epoch 11, Batch 40/50, Loss: 135.418396
2025-10-24 23:56:19,191 - __main__ - INFO - Epoch 11: Train Loss: 127.855678, Val Loss: 44.894605, LR: 9.76e-05
2025-10-24 23:56:19,199 - __main__ - INFO - Saved best model (Val Loss: 44.894605)
2025-10-24 23:56:19,215 - __main__ - INFO - Epoch 12, Batch 0/50, Loss: 129.139679
2025-10-24 23:56:19,339 - __main__ - INFO - Epoch 12, Batch 10/50, Loss: 105.578461
2025-10-24 23:56:19,464 - __main__ - INFO - Epoch 12, Batch 20/50, Loss: 117.066254
2025-10-24 23:56:19,580 - __main__ - INFO - Epoch 12, Batch 30/50, Loss: 96.620430
2025-10-24 23:56:19,705 - __main__ - INFO - Epoch 12, Batch 40/50, Loss: 76.162704
2025-10-24 23:56:19,986 - __main__ - INFO - Epoch 12: Train Loss: 114.149613, Val Loss: 34.104380, LR: 9.46e-05
2025-10-24 23:56:19,993 - __main__ - INFO - Saved best model (Val Loss: 34.104380)
2025-10-24 23:56:20,009 - __main__ - INFO - Epoch 13, Batch 0/50, Loss: 101.037659
2025-10-24 23:56:20,139 - __main__ - INFO - Epoch 13, Batch 10/50, Loss: 90.769157
2025-10-24 23:56:20,257 - __main__ - INFO - Epoch 13, Batch 20/50, Loss: 104.320671
2025-10-24 23:56:20,387 - __main__ - INFO - Epoch 13, Batch 30/50, Loss: 95.580757
2025-10-24 23:56:20,510 - __main__ - INFO - Epoch 13, Batch 40/50, Loss: 100.884781
2025-10-24 23:56:20,815 - __main__ - INFO - Epoch 13: Train Loss: 102.606176, Val Loss: 40.268443, LR: 9.05e-05
2025-10-24 23:56:20,827 - __main__ - INFO - Epoch 14, Batch 0/50, Loss: 68.902466
2025-10-24 23:56:20,953 - __main__ - INFO - Epoch 14, Batch 10/50, Loss: 76.878563
2025-10-24 23:56:21,078 - __main__ - INFO - Epoch 14, Batch 20/50, Loss: 64.298828
2025-10-24 23:56:21,205 - __main__ - INFO - Epoch 14, Batch 30/50, Loss: 109.540726
2025-10-24 23:56:21,337 - __main__ - INFO - Epoch 14, Batch 40/50, Loss: 73.398903
2025-10-24 23:56:21,613 - __main__ - INFO - Epoch 14: Train Loss: 96.444634, Val Loss: 28.546798, LR: 8.54e-05
2025-10-24 23:56:21,620 - __main__ - INFO - Saved best model (Val Loss: 28.546798)
2025-10-24 23:56:21,636 - __main__ - INFO - Epoch 15, Batch 0/50, Loss: 89.157867
2025-10-24 23:56:21,762 - __main__ - INFO - Epoch 15, Batch 10/50, Loss: 100.616035
2025-10-24 23:56:21,882 - __main__ - INFO - Epoch 15, Batch 20/50, Loss: 71.632423
2025-10-24 23:56:22,002 - __main__ - INFO - Epoch 15, Batch 30/50, Loss: 118.750336
2025-10-24 23:56:22,126 - __main__ - INFO - Epoch 15, Batch 40/50, Loss: 80.464638
2025-10-24 23:56:22,420 - __main__ - INFO - Epoch 15: Train Loss: 89.472875, Val Loss: 25.155818, LR: 7.94e-05
2025-10-24 23:56:22,427 - __main__ - INFO - Saved best model (Val Loss: 25.155818)
2025-10-24 23:56:22,442 - __main__ - INFO - Epoch 16, Batch 0/50, Loss: 83.438530
2025-10-24 23:56:22,569 - __main__ - INFO - Epoch 16, Batch 10/50, Loss: 130.401108
2025-10-24 23:56:22,698 - __main__ - INFO - Epoch 16, Batch 20/50, Loss: 56.633736
2025-10-24 23:56:22,820 - __main__ - INFO - Epoch 16, Batch 30/50, Loss: 121.049194
2025-10-24 23:56:22,979 - __main__ - INFO - Epoch 16, Batch 40/50, Loss: 132.875259
2025-10-24 23:56:23,282 - __main__ - INFO - Epoch 16: Train Loss: 87.501480, Val Loss: 29.404526, LR: 7.27e-05
2025-10-24 23:56:23,294 - __main__ - INFO - Epoch 17, Batch 0/50, Loss: 45.039341
2025-10-24 23:56:23,423 - __main__ - INFO - Epoch 17, Batch 10/50, Loss: 119.439743
2025-10-24 23:56:23,543 - __main__ - INFO - Epoch 17, Batch 20/50, Loss: 48.517586
2025-10-24 23:56:23,667 - __main__ - INFO - Epoch 17, Batch 30/50, Loss: 66.176643
2025-10-24 23:56:23,792 - __main__ - INFO - Epoch 17, Batch 40/50, Loss: 125.231483
2025-10-24 23:56:24,089 - __main__ - INFO - Epoch 17: Train Loss: 86.834528, Val Loss: 20.675769, LR: 6.55e-05
2025-10-24 23:56:24,097 - __main__ - INFO - Saved best model (Val Loss: 20.675769)
2025-10-24 23:56:24,116 - __main__ - INFO - Epoch 18, Batch 0/50, Loss: 70.086403
2025-10-24 23:56:24,247 - __main__ - INFO - Epoch 18, Batch 10/50, Loss: 72.727837
2025-10-24 23:56:24,372 - __main__ - INFO - Epoch 18, Batch 20/50, Loss: 50.578712
2025-10-24 23:56:24,502 - __main__ - INFO - Epoch 18, Batch 30/50, Loss: 63.894978
2025-10-24 23:56:24,622 - __main__ - INFO - Epoch 18, Batch 40/50, Loss: 81.605972
2025-10-24 23:56:24,905 - __main__ - INFO - Epoch 18: Train Loss: 79.500599, Val Loss: 21.417153, LR: 5.78e-05
2025-10-24 23:56:24,917 - __main__ - INFO - Epoch 19, Batch 0/50, Loss: 71.775772
2025-10-24 23:56:25,042 - __main__ - INFO - Epoch 19, Batch 10/50, Loss: 58.267395
2025-10-24 23:56:25,160 - __main__ - INFO - Epoch 19, Batch 20/50, Loss: 51.270641
2025-10-24 23:56:25,287 - __main__ - INFO - Epoch 19, Batch 30/50, Loss: 89.642639
2025-10-24 23:56:25,418 - __main__ - INFO - Epoch 19, Batch 40/50, Loss: 73.009117
2025-10-24 23:56:25,706 - __main__ - INFO - Epoch 19: Train Loss: 79.209371, Val Loss: 21.498988, LR: 5.00e-05
2025-10-24 23:56:25,717 - __main__ - INFO - Epoch 20, Batch 0/50, Loss: 87.190735
2025-10-24 23:56:25,854 - __main__ - INFO - Epoch 20, Batch 10/50, Loss: 51.284878
2025-10-24 23:56:25,981 - __main__ - INFO - Epoch 20, Batch 20/50, Loss: 57.710182
2025-10-24 23:56:26,100 - __main__ - INFO - Epoch 20, Batch 30/50, Loss: 48.891499
2025-10-24 23:56:26,225 - __main__ - INFO - Epoch 20, Batch 40/50, Loss: 127.187408
2025-10-24 23:56:26,504 - __main__ - INFO - Epoch 20: Train Loss: 81.906909, Val Loss: 19.015076, LR: 4.22e-05
2025-10-24 23:56:26,512 - __main__ - INFO - Saved best model (Val Loss: 19.015076)
2025-10-24 23:56:26,526 - __main__ - INFO - Epoch 21, Batch 0/50, Loss: 75.307556
2025-10-24 23:56:26,654 - __main__ - INFO - Epoch 21, Batch 10/50, Loss: 90.721115
2025-10-24 23:56:26,774 - __main__ - INFO - Epoch 21, Batch 20/50, Loss: 77.607765
2025-10-24 23:56:26,896 - __main__ - INFO - Epoch 21, Batch 30/50, Loss: 64.038185
2025-10-24 23:56:27,019 - __main__ - INFO - Epoch 21, Batch 40/50, Loss: 42.635002
2025-10-24 23:56:27,303 - __main__ - INFO - Epoch 21: Train Loss: 76.891583, Val Loss: 20.047426, LR: 3.45e-05
2025-10-24 23:56:27,315 - __main__ - INFO - Epoch 22, Batch 0/50, Loss: 84.074387
2025-10-24 23:56:27,443 - __main__ - INFO - Epoch 22, Batch 10/50, Loss: 58.401302
2025-10-24 23:56:27,567 - __main__ - INFO - Epoch 22, Batch 20/50, Loss: 46.570286
2025-10-24 23:56:27,692 - __main__ - INFO - Epoch 22, Batch 30/50, Loss: 62.484177
2025-10-24 23:56:27,813 - __main__ - INFO - Epoch 22, Batch 40/50, Loss: 47.605518
2025-10-24 23:56:28,103 - __main__ - INFO - Epoch 22: Train Loss: 74.105751, Val Loss: 21.183913, LR: 2.73e-05
2025-10-24 23:56:28,118 - __main__ - INFO - Epoch 23, Batch 0/50, Loss: 48.065788
2025-10-24 23:56:28,246 - __main__ - INFO - Epoch 23, Batch 10/50, Loss: 502.846222
2025-10-24 23:56:28,370 - __main__ - INFO - Epoch 23, Batch 20/50, Loss: 82.105316
2025-10-24 23:56:28,490 - __main__ - INFO - Epoch 23, Batch 30/50, Loss: 105.652565
2025-10-24 23:56:28,619 - __main__ - INFO - Epoch 23, Batch 40/50, Loss: 45.641968
2025-10-24 23:56:28,904 - __main__ - INFO - Epoch 23: Train Loss: 75.094336, Val Loss: 18.343433, LR: 2.06e-05
2025-10-24 23:56:28,912 - __main__ - INFO - Saved best model (Val Loss: 18.343433)
2025-10-24 23:56:28,929 - __main__ - INFO - Epoch 24, Batch 0/50, Loss: 34.133892
2025-10-24 23:56:29,057 - __main__ - INFO - Epoch 24, Batch 10/50, Loss: 53.681919
2025-10-24 23:56:29,185 - __main__ - INFO - Epoch 24, Batch 20/50, Loss: 73.021988
2025-10-24 23:56:29,312 - __main__ - INFO - Epoch 24, Batch 30/50, Loss: 37.922527
2025-10-24 23:56:29,442 - __main__ - INFO - Epoch 24, Batch 40/50, Loss: 71.543015
2025-10-24 23:56:29,720 - __main__ - INFO - Epoch 24: Train Loss: 70.027299, Val Loss: 22.228056, LR: 1.46e-05
2025-10-24 23:56:29,732 - __main__ - INFO - Epoch 25, Batch 0/50, Loss: 59.840649
2025-10-24 23:56:29,859 - __main__ - INFO - Epoch 25, Batch 10/50, Loss: 64.803276
2025-10-24 23:56:29,988 - __main__ - INFO - Epoch 25, Batch 20/50, Loss: 68.362762
2025-10-24 23:56:30,122 - __main__ - INFO - Epoch 25, Batch 30/50, Loss: 39.725559
2025-10-24 23:56:30,280 - __main__ - INFO - Epoch 25, Batch 40/50, Loss: 48.653240
2025-10-24 23:56:30,571 - __main__ - INFO - Epoch 25: Train Loss: 73.475161, Val Loss: 19.388253, LR: 9.55e-06
2025-10-24 23:56:30,583 - __main__ - INFO - Epoch 26, Batch 0/50, Loss: 68.270111
2025-10-24 23:56:30,719 - __main__ - INFO - Epoch 26, Batch 10/50, Loss: 92.333038
2025-10-24 23:56:30,850 - __main__ - INFO - Epoch 26, Batch 20/50, Loss: 39.500061
2025-10-24 23:56:30,974 - __main__ - INFO - Epoch 26, Batch 30/50, Loss: 45.256821
2025-10-24 23:56:31,091 - __main__ - INFO - Epoch 26, Batch 40/50, Loss: 55.607285
2025-10-24 23:56:31,365 - __main__ - INFO - Epoch 26: Train Loss: 71.696811, Val Loss: 18.972926, LR: 5.45e-06
2025-10-24 23:56:31,378 - __main__ - INFO - Epoch 27, Batch 0/50, Loss: 58.149120
2025-10-24 23:56:31,500 - __main__ - INFO - Epoch 27, Batch 10/50, Loss: 50.318710
2025-10-24 23:56:31,618 - __main__ - INFO - Epoch 27, Batch 20/50, Loss: 82.427147
2025-10-24 23:56:31,740 - __main__ - INFO - Epoch 27, Batch 30/50, Loss: 65.369644
2025-10-24 23:56:31,864 - __main__ - INFO - Epoch 27, Batch 40/50, Loss: 70.091927
2025-10-24 23:56:32,155 - __main__ - INFO - Epoch 27: Train Loss: 74.248405, Val Loss: 17.813340, LR: 2.45e-06
2025-10-24 23:56:32,163 - __main__ - INFO - Saved best model (Val Loss: 17.813340)
2025-10-24 23:56:32,175 - __main__ - INFO - Epoch 28, Batch 0/50, Loss: 476.444061
2025-10-24 23:56:32,298 - __main__ - INFO - Epoch 28, Batch 10/50, Loss: 67.939941
2025-10-24 23:56:32,419 - __main__ - INFO - Epoch 28, Batch 20/50, Loss: 62.196426
2025-10-24 23:56:32,544 - __main__ - INFO - Epoch 28, Batch 30/50, Loss: 45.940136
2025-10-24 23:56:32,662 - __main__ - INFO - Epoch 28, Batch 40/50, Loss: 78.732803
2025-10-24 23:56:32,929 - __main__ - INFO - Epoch 28: Train Loss: 70.189832, Val Loss: 18.011115, LR: 6.16e-07
2025-10-24 23:56:32,942 - __main__ - INFO - Epoch 29, Batch 0/50, Loss: 57.958031
2025-10-24 23:56:33,063 - __main__ - INFO - Epoch 29, Batch 10/50, Loss: 70.514465
2025-10-24 23:56:33,176 - __main__ - INFO - Epoch 29, Batch 20/50, Loss: 152.438995
2025-10-24 23:56:33,301 - __main__ - INFO - Epoch 29, Batch 30/50, Loss: 91.936989
2025-10-24 23:56:33,423 - __main__ - INFO - Epoch 29, Batch 40/50, Loss: 81.722549
2025-10-24 23:56:33,693 - __main__ - INFO - Epoch 29: Train Loss: 69.619213, Val Loss: 18.241036, LR: 1.00e-04
2025-10-24 23:56:33,705 - __main__ - INFO - Epoch 30, Batch 0/50, Loss: 69.551437
2025-10-24 23:56:33,823 - __main__ - INFO - Epoch 30, Batch 10/50, Loss: 64.102005
2025-10-24 23:56:33,946 - __main__ - INFO - Epoch 30, Batch 20/50, Loss: 56.514450
2025-10-24 23:56:34,072 - __main__ - INFO - Epoch 30, Batch 30/50, Loss: 73.852943
2025-10-24 23:56:34,188 - __main__ - INFO - Epoch 30, Batch 40/50, Loss: 64.323685
2025-10-24 23:56:34,457 - __main__ - INFO - Epoch 30: Train Loss: 74.402812, Val Loss: 28.374104, LR: 9.98e-05
2025-10-24 23:56:34,468 - __main__ - INFO - Epoch 31, Batch 0/50, Loss: 49.385838
2025-10-24 23:56:34,590 - __main__ - INFO - Epoch 31, Batch 10/50, Loss: 41.833836
2025-10-24 23:56:34,712 - __main__ - INFO - Epoch 31, Batch 20/50, Loss: 54.573822
2025-10-24 23:56:34,832 - __main__ - INFO - Epoch 31, Batch 30/50, Loss: 69.954620
2025-10-24 23:56:34,954 - __main__ - INFO - Epoch 31, Batch 40/50, Loss: 39.862930
2025-10-24 23:56:35,285 - __main__ - INFO - Epoch 31: Train Loss: 68.952189, Val Loss: 20.726978, LR: 9.94e-05
2025-10-24 23:56:35,300 - __main__ - INFO - Epoch 32, Batch 0/50, Loss: 60.570560
2025-10-24 23:56:35,421 - __main__ - INFO - Epoch 32, Batch 10/50, Loss: 63.665539
2025-10-24 23:56:35,536 - __main__ - INFO - Epoch 32, Batch 20/50, Loss: 60.778080
2025-10-24 23:56:35,659 - __main__ - INFO - Epoch 32, Batch 30/50, Loss: 80.397591
2025-10-24 23:56:35,781 - __main__ - INFO - Epoch 32, Batch 40/50, Loss: 45.455841
2025-10-24 23:56:36,058 - __main__ - INFO - Epoch 32: Train Loss: 71.362689, Val Loss: 17.840533, LR: 9.86e-05
2025-10-24 23:56:36,071 - __main__ - INFO - Epoch 33, Batch 0/50, Loss: 60.340851
2025-10-24 23:56:36,196 - __main__ - INFO - Epoch 33, Batch 10/50, Loss: 64.009346
2025-10-24 23:56:36,309 - __main__ - INFO - Epoch 33, Batch 20/50, Loss: 87.712486
2025-10-24 23:56:36,424 - __main__ - INFO - Epoch 33, Batch 30/50, Loss: 55.194279
2025-10-24 23:56:36,542 - __main__ - INFO - Epoch 33, Batch 40/50, Loss: 63.812588
2025-10-24 23:56:36,814 - __main__ - INFO - Epoch 33: Train Loss: 70.935041, Val Loss: 17.367089, LR: 9.76e-05
2025-10-24 23:56:36,822 - __main__ - INFO - Saved best model (Val Loss: 17.367089)
2025-10-24 23:56:36,834 - __main__ - INFO - Epoch 34, Batch 0/50, Loss: 54.415863
2025-10-24 23:56:36,951 - __main__ - INFO - Epoch 34, Batch 10/50, Loss: 56.961250
2025-10-24 23:56:37,073 - __main__ - INFO - Epoch 34, Batch 20/50, Loss: 62.974640
2025-10-24 23:56:37,187 - __main__ - INFO - Epoch 34, Batch 30/50, Loss: 29.100237
2025-10-24 23:56:37,300 - __main__ - INFO - Epoch 34, Batch 40/50, Loss: 78.899635
2025-10-24 23:56:37,575 - __main__ - INFO - Epoch 34: Train Loss: 66.249756, Val Loss: 17.020673, LR: 9.62e-05
2025-10-24 23:56:37,582 - __main__ - INFO - Saved best model (Val Loss: 17.020673)
2025-10-24 23:56:37,594 - __main__ - INFO - Epoch 35, Batch 0/50, Loss: 44.956879
2025-10-24 23:56:37,712 - __main__ - INFO - Epoch 35, Batch 10/50, Loss: 67.443939
2025-10-24 23:56:37,830 - __main__ - INFO - Epoch 35, Batch 20/50, Loss: 53.159534
2025-10-24 23:56:37,950 - __main__ - INFO - Epoch 35, Batch 30/50, Loss: 46.521420
2025-10-24 23:56:38,070 - __main__ - INFO - Epoch 35, Batch 40/50, Loss: 55.656277
2025-10-24 23:56:38,345 - __main__ - INFO - Epoch 35: Train Loss: 66.987140, Val Loss: 18.780302, LR: 9.46e-05
2025-10-24 23:56:38,358 - __main__ - INFO - Epoch 36, Batch 0/50, Loss: 49.052586
2025-10-24 23:56:38,478 - __main__ - INFO - Epoch 36, Batch 10/50, Loss: 50.199356
2025-10-24 23:56:38,598 - __main__ - INFO - Epoch 36, Batch 20/50, Loss: 51.180946
2025-10-24 23:56:38,720 - __main__ - INFO - Epoch 36, Batch 30/50, Loss: 58.635387
2025-10-24 23:56:38,833 - __main__ - INFO - Epoch 36, Batch 40/50, Loss: 76.465126
2025-10-24 23:56:39,106 - __main__ - INFO - Epoch 36: Train Loss: 64.944188, Val Loss: 18.809996, LR: 9.26e-05
2025-10-24 23:56:39,120 - __main__ - INFO - Epoch 37, Batch 0/50, Loss: 49.266434
2025-10-24 23:56:39,242 - __main__ - INFO - Epoch 37, Batch 10/50, Loss: 71.119568
2025-10-24 23:56:39,361 - __main__ - INFO - Epoch 37, Batch 20/50, Loss: 92.026070
2025-10-24 23:56:39,479 - __main__ - INFO - Epoch 37, Batch 30/50, Loss: 57.647228
2025-10-24 23:56:39,600 - __main__ - INFO - Epoch 37, Batch 40/50, Loss: 49.549347
2025-10-24 23:56:39,874 - __main__ - INFO - Epoch 37: Train Loss: 65.474898, Val Loss: 17.498436, LR: 9.05e-05
2025-10-24 23:56:39,887 - __main__ - INFO - Epoch 38, Batch 0/50, Loss: 67.099312
2025-10-24 23:56:40,008 - __main__ - INFO - Epoch 38, Batch 10/50, Loss: 65.050110
2025-10-24 23:56:40,135 - __main__ - INFO - Epoch 38, Batch 20/50, Loss: 31.476545
2025-10-24 23:56:40,254 - __main__ - INFO - Epoch 38, Batch 30/50, Loss: 59.005428
2025-10-24 23:56:40,372 - __main__ - INFO - Epoch 38, Batch 40/50, Loss: 44.849365
2025-10-24 23:56:40,702 - __main__ - INFO - Epoch 38: Train Loss: 65.278646, Val Loss: 19.896066, LR: 8.80e-05
2025-10-24 23:56:40,718 - __main__ - INFO - Epoch 39, Batch 0/50, Loss: 47.462322
2025-10-24 23:56:40,860 - __main__ - INFO - Epoch 39, Batch 10/50, Loss: 101.721779
2025-10-24 23:56:41,015 - __main__ - INFO - Epoch 39, Batch 20/50, Loss: 109.528656
2025-10-24 23:56:41,156 - __main__ - INFO - Epoch 39, Batch 30/50, Loss: 135.376450
2025-10-24 23:56:41,307 - __main__ - INFO - Epoch 39, Batch 40/50, Loss: 56.414482
2025-10-24 23:56:41,664 - __main__ - INFO - Epoch 39: Train Loss: 69.263796, Val Loss: 26.625144, LR: 8.54e-05
2025-10-24 23:56:41,678 - __main__ - INFO - Epoch 40, Batch 0/50, Loss: 76.664299
2025-10-24 23:56:41,827 - __main__ - INFO - Epoch 40, Batch 10/50, Loss: 66.697693
2025-10-24 23:56:41,971 - __main__ - INFO - Epoch 40, Batch 20/50, Loss: 91.148270
2025-10-24 23:56:42,111 - __main__ - INFO - Epoch 40, Batch 30/50, Loss: 38.886463
2025-10-24 23:56:42,258 - __main__ - INFO - Epoch 40, Batch 40/50, Loss: 40.422062
2025-10-24 23:56:42,633 - __main__ - INFO - Epoch 40: Train Loss: 66.282129, Val Loss: 28.825984, LR: 8.25e-05
2025-10-24 23:56:42,648 - __main__ - INFO - Epoch 41, Batch 0/50, Loss: 59.819389
2025-10-24 23:56:42,785 - __main__ - INFO - Epoch 41, Batch 10/50, Loss: 62.497002
2025-10-24 23:56:42,937 - __main__ - INFO - Epoch 41, Batch 20/50, Loss: 39.143269
2025-10-24 23:56:43,082 - __main__ - INFO - Epoch 41, Batch 30/50, Loss: 67.816833
2025-10-24 23:56:43,235 - __main__ - INFO - Epoch 41, Batch 40/50, Loss: 468.442261
2025-10-24 23:56:43,631 - __main__ - INFO - Epoch 41: Train Loss: 66.478785, Val Loss: 17.445187, LR: 7.94e-05
2025-10-24 23:56:43,646 - __main__ - INFO - Epoch 42, Batch 0/50, Loss: 53.285942
2025-10-24 23:56:43,801 - __main__ - INFO - Epoch 42, Batch 10/50, Loss: 59.651154
2025-10-24 23:56:43,955 - __main__ - INFO - Epoch 42, Batch 20/50, Loss: 44.296909
2025-10-24 23:56:44,099 - __main__ - INFO - Epoch 42, Batch 30/50, Loss: 46.981365
2025-10-24 23:56:44,250 - __main__ - INFO - Epoch 42, Batch 40/50, Loss: 41.102531
2025-10-24 23:56:44,612 - __main__ - INFO - Epoch 42: Train Loss: 62.927200, Val Loss: 21.738358, LR: 7.61e-05
2025-10-24 23:56:44,635 - __main__ - INFO - Epoch 43, Batch 0/50, Loss: 50.928413
2025-10-24 23:56:44,791 - __main__ - INFO - Epoch 43, Batch 10/50, Loss: 72.215569
2025-10-24 23:56:44,941 - __main__ - INFO - Epoch 43, Batch 20/50, Loss: 118.468391
2025-10-24 23:56:45,088 - __main__ - INFO - Epoch 43, Batch 30/50, Loss: 38.018764
2025-10-24 23:56:45,242 - __main__ - INFO - Epoch 43, Batch 40/50, Loss: 32.916321
2025-10-24 23:56:45,602 - __main__ - INFO - Epoch 43: Train Loss: 64.399012, Val Loss: 17.217104, LR: 7.27e-05
2025-10-24 23:56:45,616 - __main__ - INFO - Epoch 44, Batch 0/50, Loss: 80.005165
2025-10-24 23:56:45,768 - __main__ - INFO - Epoch 44, Batch 10/50, Loss: 48.660866
2025-10-24 23:56:45,912 - __main__ - INFO - Epoch 44, Batch 20/50, Loss: 48.683224
2025-10-24 23:56:46,059 - __main__ - INFO - Epoch 44, Batch 30/50, Loss: 41.022675
2025-10-24 23:56:46,201 - __main__ - INFO - Epoch 44, Batch 40/50, Loss: 54.481358
2025-10-24 23:56:46,553 - __main__ - INFO - Epoch 44: Train Loss: 60.848877, Val Loss: 21.950451, LR: 6.91e-05
2025-10-24 23:56:46,553 - __main__ - INFO - Early stopping at epoch 44
2025-10-24 23:56:46,553 - __main__ - INFO - Training completed. Best validation loss: 17.020673
2025-10-24 23:56:46,557 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:56:46,691 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:56:46,692 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:56:46,692 - data.oil_data_pipeline - INFO - Processing 787 mapped news events
2025-10-24 23:56:46,824 - data.oil_data_pipeline - INFO - Processed 787 training samples from mapped events
2025-10-24 23:56:46,824 - data.oil_data_pipeline - INFO - Oil price dataset created with 787 samples
2025-10-24 23:56:46,825 - __main__ - INFO - Evaluating model...
2025-10-24 23:56:47,072 - utils.metrics - INFO - Computed 20 metrics
2025-10-24 23:56:47,072 - utils.visualization - INFO - Creating training history plots...
2025-10-24 23:56:48,060 - utils.visualization - INFO - Training history plot saved to plots/training_history.png
2025-10-24 23:56:48,061 - utils.visualization - INFO - Creating prediction plots...
2025-10-24 23:56:49,380 - utils.visualization - INFO - Prediction plots saved to plots/prediction_results.png
2025-10-24 23:56:49,382 - __main__ - INFO - GPU training and evaluation completed successfully!
2025-10-24 23:56:49,383 - __main__ - INFO - Final metrics: {'source_mse': 12.453923225402832, 'source_mae': 1.391610026359558, 'source_rmse': 3.5290117263793945, 'ripple_mse': 12.301117897033691, 'ripple_mae': 1.5748469829559326, 'ripple_rmse': 3.5072948932647705, 'confidence_mse': 0.023925717920064926, 'confidence_mae': 0.12811219692230225, 'source_direction_accuracy': 0.3333333432674408, 'wti_mse': 28.951030731201172, 'wti_mae': 3.974912166595459, 'wti_direction_acc': 0.9987292885780334, 'brent_mse': 8.407556533813477, 'brent_mae': 0.14356383681297302, 'brent_direction_acc': 0.001270647975616157, 'gas_mse': 0.003181127132847905, 'gas_mae': 0.05635394528508186, 'gas_direction_acc': 0.0, 'overall_mse': 8.259655613452196, 'overall_mae': 1.031523068745931}
